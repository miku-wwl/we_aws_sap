这 10 道题目涵盖了 **EC2 性能故障排查 (CloudWatch Logs + X-Ray)**、**SaaS 全球加速 (Global Accelerator)**、**ABAC 权限控制 (Attribute-Based Access Control)**、**Service Catalog 治理**、**Athena 查询性能优化 (Partitioning)**、**WAF 地理封禁与日志**、**FSx 跨区域复制 (DataSync + Peering)**、**Aurora Global Database** 等。

特别是 **Q385 (ABAC)** 和 **Q386 (Service Catalog TagOption)** 是 SAP 考试中的高级 IAM 和治理考点。

让我们开启 **逐题秒杀模式**！

---

#### 📝 [381/529] 三层架构性能故障排查 (CloudWatch Logs + X-Ray)

**1. 🕵️‍♂️ 题眼与约束分析**
* **故障：** 购物车错误和超时。
* **现状：** Web 服务器日志在实例终止前没收集到，Aurora 指标不足以分析查询性能。
* **需求：** Improve visibility during peak traffic (提高可见性)。
* **选择：** 3 个步骤。

**2. ⚡ 秒杀思路**
* **Web 层日志丢失问题：**
    * 需要实时收集日志，而不是等故障后去实例里找（因为实例可能被 ASG 终止了）。
    * **CloudWatch Agent (D):** 安装在 EC2 上，实时将 Apache 日志推送到 CloudWatch Logs。即使实例终止，日志还在。 $\rightarrow$ **选中 D**。
* **数据库查询性能：**
    * Aurora 指标不够，需要具体的慢查询日志。
    * **Aurora Logs to CloudWatch (A):** 将 Aurora 的慢查询日志和错误日志发布到 CloudWatch Logs。这样可以分析具体哪些 SQL 慢。 $\rightarrow$ **选中 A**。
* **端到端追踪：**
    * 为了定位“超时”是在哪一层（Web, App, DB），需要分布式追踪。
    * **AWS X-Ray (B):** 在 EC2 上通过 SDK 追踪 HTTP 请求，并通过 X-Ray SDK for Java 追踪 SQL 查询。这能构建完整的调用链，找出瓶颈。 $\rightarrow$ **选中 B**。
* **排除法：**
    * C (Kinesis): Aurora 日志直接发 Kinesis 不如发 CloudWatch Logs 方便查看（虽然也支持，但 CloudWatch Logs Insights 更适合即席分析）。
    * E (CloudTrail): CloudTrail 记录管理面 API (如 CreateInstance)，不记录应用层数据面流量（如 HTTP 请求或 SQL）。
    * F (Performance Benchmarking?): Aurora 没有这个功能开关叫“publish stream to X-Ray”。
* **锁定 A, B, D。**

**3. ✅ 正确选项解析 (选项 A, B, D)**
* **CloudWatch Agent:** 解决临时实例日志持久化。
* **Aurora Logs Export:** 解决数据库查询细节不可见。
* **X-Ray:** 解决端到端性能瓶颈定位。

**5. 📚 核心考点:** 全栈性能监控与日志收集的最佳实践。

---

#### 📝 [382/529] 季节性流量架构扩展 (Serverless + Auto Scaling)

**1. 🕵️‍♂️ 题眼与约束分析**
* **现状：** 2 EC2 + DynamoDB。
* **痛点：** Sluggish traffic during peak (高峰期慢)。
* **需求：** Scalable, **Minimize development effort** (最小开发工作量)。

**2. ⚡ 秒杀思路**
* **计算层：**
    * EC2 固定 2 台肯定不够。需要 **Auto Scaling Group (ASG)**。
    * 迁移到 Lambda (A/B) 需要重写代码（Refactor），违反 "Minimize development effort"。
    * $\rightarrow$ **选中 C 或 D**。
* **数据库层：**
    * DynamoDB 变慢通常是因为容量不足。
    * **DynamoDB Auto Scaling (C):** 自动根据流量调整 RCU/WCU。这是最简单的扩展方式。
    * SQS + Lambda (D): 引入队列写库确实能削峰，但增加了架构复杂度（开发工作量），且这只解决了写，没解决读（Read traffic is sluggish）。DynamoDB Auto Scaling 读写都能扩。
    * Global Tables (B): 是跨区域的，题目没提多区域。
* **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **Auto Scaling (EC2 & DynamoDB):** 这里的“最小开发”意味着利用平台原生的自动扩展能力，而不是改代码架构。

**5. 📚 核心考点:** 应对季节性流量的零代码/低代码扩展策略。

---

#### 📝 [383/529] 本地数据中心发现与评估 (Agentless Discovery)

**1. 🕵️‍♂️ 题眼与约束分析**
* **任务：** Assess on-prem VMs for rightsizing (评估本地 VM 规格)。
* **数据：** CPU, Memory, Disk, **Process inventory**, **Network dependencies** (进程和网络依赖)。
* **目标：** **Most cost-effectively** (最经济)。

**2. ⚡ 秒杀思路**
* **工具选型：**
    * **Application Discovery Service (ADS):**
        * **Agentless (C):** 通过 vCenter 收集，只能看 VM 配置和基本性能，**看不到** 进程级详情和详细的网络依赖。
        * **Agent-based (A):** 在每个 VM 装代理。能收集 **Processes** 和 **Network connections**。
    * **CloudWatch Agent (B):** 主要是性能监控，不擅长做“迁移评估”中的依赖分析和 TCO 映射。且在本地大规模部署并发送日志到 CloudWatch 可能会产生较高的日志存储费和流量费（相比 ADS 免费或低成本）。
* **矛盾点：**
    * 题目问 "Most cost-effectively"。ADS 服务本身是免费的。
    * 题目要求 "Inventory processes... monitor network connections"。这必须用 **Agent-based**。Agentless 做不到。
    * 所以虽然 Agentless (C) 部署更便宜（人力成本），但它**不满足需求**。
    * **必须选 A**。
    * (D 是什么？Enable in console... scan via VPN? ADS Agentless Collector 确实是部署在本地的 OVA，不是在控制台点一下就扫描的)。
* **锁定 A。**

**3. ✅ 正确选项解析 (选项 A)**
* **ADS Agent-based:** 唯一能收集进程和详细网络依赖的发现模式。

**5. 📚 核心考点:** Discovery Service Agent vs Agentless 的能力边界。

---

#### 📝 [384/529] SaaS 全球静态 IP 接入 (Global Accelerator)

**1. 🕵️‍♂️ 题眼与约束分析**
* **现状：** NLB + EC2 ASG (Single Region)。
* **扩展：** Deploy to other regions (多区域部署)。
* **需求：**
    1.  **Static IP addresses** for allow-listing (静态 IP)。
    2.  Route to **closest region** (就近接入)。
* **工具：** Global Accelerator vs CloudFront。

**2. ⚡ 秒杀思路**
* **Global Accelerator (GA):**
    * 提供 **2 个静态 Anycast IP**。
    * 自动将流量路由到最近的健康端点（跨区域 NLB/ALB）。
    * 完美符合所有要求。
    * **Standard Accelerator (B):** 标准加速器支持自动路由优化。
    * **Custom Routing Accelerator (D):** 用于特定场景（如游戏房匹配，路由到特定 EC2 实例和端口），不适合通用的 SaaS 负载均衡。
* **CloudFront (A/C):**
    * CloudFront 是 CDN，主要用于 HTTP/S。虽然也支持静态 IP（通过不常见的配置或专用 IP），但通常它的 IP 范围很大且会变。题目要求 "Provide static IP addresses... for allow list"，GA 的两个固定 IP 是为此而生的。
* **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **Global Accelerator (Standard):** 提供全球静态 IP 入口和跨区域流量调度。

**5. 📚 核心考点:** Global Accelerator 的核心场景（静态 IP + 跨区路由）。

---

#### 📝 [385/529] 基于标签的资源访问控制 (ABAC)

**1. 🕵️‍♂️ 题眼与约束分析**
* **痛点：** 开发人员误删了其他团队的 EC2。
* **需求：**
    1.  Prevent this (隔离团队资源)。
    2.  Allow developers to manage their own instances (允许管理自己的)。
* **环境：** Shared Production Account (共享账户), SAML Federation。
* **工具：** ABAC (Attribute-Based Access Control)。

**2. ⚡ 秒杀思路**
* **ABAC 核心逻辑：**
    * **资源标签：** EC2 实例打上 `DevelopmentUnit = TeamA`。
    * **用户标签：** 登录后的 Principal (Role/User) 带有 `DevelopmentUnit = TeamA`。
    * **策略条件：** 允许操作 `Condition: StringEquals: aws:ResourceTag/DevelopmentUnit == aws:PrincipalTag/DevelopmentUnit`。
* **SAML 集成：**
    * 在 SAML 断言中传递属性（如 `DevelopmentUnit`），并在 IAM Role 的 Trust Policy 中映射为 **Session Tags** (`aws:PrincipalTag`)。
* **选项对比：**
    * **B:** "Pass DevelopmentUnit as session tag attribute... Update IAM policy with **Deny** action and **StringNotEquals** condition"。
        * 逻辑：如果（资源标签 != 主体标签），则拒绝。
        * 这是一种有效的隔离策略（除了自己的，其他都拒绝）。
        * 或者用 Allow + StringEquals。
        * 让我们看选项 C。
    * **C:** SCP? SCP 是限制账户边界的，不能限制账户内不同 IAM Role 对不同资源的细粒度访问（SCP 不支持 Resource Tag 这种细粒度控制，或者说 SCP 主要是 Deny，很难做“允许匹配的”）。更重要的是，SCP 作用于 Account，这里大家都在**同一个 Production Account**。SCP 对同账户内的用户无效。
    * **A:** OU + SCP。同上，大家在一个账户里，OU 隔离没用。
    * **D:** 为每个单元创建单独的 IAM Policy？这意味着每个团队要用不同的 Role。虽然可以，但管理麻烦（每次加团队都要加 Policy 和 Role）。
    * **B vs D:** ABAC (B) 的优势在于**只需一个 Policy** 就能管所有团队（只要标签对就行）。而 D 是 RBAC（基于角色的），每个团队一个 Policy，扩展性差。
    * **仔细看 B 的逻辑：** Deny if `StringNotEquals`.
        * 这意味着：如果我不属于 TeamA，我就不能动 TeamA 的资源。
        * 但我还需要 **Allow** 权限来动我自己的资源。题目隐含了基本的 Allow 权限已经有了（开发人员可以管理资源）。我们只需要加一个限制。
        * 使用 **Deny + StringNotEquals** 是实现“边界防御”的经典 ABAC 写法。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **ABAC (Session Tags):** 利用 SAML 传递的标签实现细粒度资源隔离。
* **Condition Logic:** `StringNotEquals` + `Deny` 确保用户只能操作匹配自己标签的资源。

**5. 📚 核心考点:** 共享账户环境下的 ABAC 权限控制实现。

---

#### 📝 [386/529] 基础设施自助服务平台 (Service Catalog)

**1. 🕵️‍♂️ 题眼与约束分析**
* **需求：**
    1.  Users launch **approved** services only (仅批准的服务).
    2.  Least privilege (用户自身最小权限).
    3.  Central management (中央管理).
    4.  Distribute to multiple accounts (分发).
    5.  **Enforce tagging** (强制标签).
* **选择：** 3 个步骤。

**2. ⚡ 秒杀思路**
* **核心服务：** **AWS Service Catalog**。
    * 它允许定义“产品”（CloudFormation 模板）。 $\rightarrow$ **选中 B**。
    * **Launch Constraints:** 用户只需要 `ServiceCatalogEndUserAccess` 权限，实际部署由 Service Catalog 扮演特定的 IAM Role 执行。这满足了“用户最小权限”（用户没权限直接起 EC2，只能通过 SC 起）。 $\rightarrow$ **选中 D**。
    * **强制标签：** Service Catalog 支持 **TagOption Library**，强制用户在启动时选择标签，并自动应用到资源上。 $\rightarrow$ **选中 E**。
* **排除法：**
    * A (S3): 只是存模板，没解决权限控制和强制标签。
    * C (SCP): 只是限制了服务类型，没解决“批准的架构配置”和“强制标签”。
    * F (CloudFormation Resource Tags): 需要在模板里写死或者用参数？TagOption 更灵活且是治理层面的。
* **锁定 B, D, E。**

**3. ✅ 正确选项解析 (选项 B, D, E)**
* **Service Catalog:** 自助服务治理。
* **Launch Constraints:** 权限委派。
* **TagOptions:** 标签治理。

**5. 📚 核心考点:** Service Catalog 在企业级资源分发与治理中的完整应用。

---

#### 📝 [387/529] Athena 查询性能优化 (Partitioning)

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** WAF Logs -> Firehose -> S3 -> Athena。
* **查询：** Query past 24 hours (查询过去 24 小时)。
* **问题：** Query time increases over time (随时间推移变慢)。
* **原因：** 数据越来越多，Athena 扫描了整个桶的数据，而不仅仅是过去 24 小时的。
* **目标：** Prevent increasing query time (保持查询速度)。

**2. ⚡ 秒杀思路**
* **核心优化：** **Partitioning (分区)**。
    * 将 S3 数据按时间目录结构存储（如 `year=2023/month=10/day=01/`）。
    * 配置 Athena 表识别分区。
    * 查询时带上 `WHERE date = ...`，Athena 只扫描相关文件夹，速度恒定且快。
* **实现：**
    * Firehose 支持将数据按时间格式写入 S3 前缀（Partitioning）。
    * Athena 需要配置分区投影或手动加载分区。
    * **选项 D:** Modify Firehose config and Athena table definition to **partition data by date and time**. Change query to look at relevant partitions. 这是标准解法。
* **选项对比：**
    * A (Lambda merge): 这是解决小文件问题（KB 级），题目没说文件太小，而是说扫描量大。分区更关键。
    * B (Different buckets): 分桶管理麻烦。
    * C (Redshift Spectrum): 没必要引入 Redshift，Athena 分区就能解决。
    * **锁定 D。**

**3. ✅ 正确选项解析 (选项 D)**
* **Partitioning:** 将数据按时间分片，Athena 查询时只扫描特定分片，极大减少扫描量和时间。

**5. 📚 核心考点:** Athena/S3 数据湖的性能优化第一原则——分区。

---

#### 📝 [388/529] WAF 地理封禁与日志记录 (Geo Match + Log)

**1. 🕵️‍♂️ 题眼与约束分析**
* **需求：**
    1.  Allow access ONLY from specific countries (地理白名单)。
    2.  **Log blocked requests** (记录被阻断的请求)。
    3.  **Minimal maintenance** (最少维护)。
* **架构：** ALB。

**2. ⚡ 秒杀思路**
* **工具：** **AWS WAF**。
* **规则：** 使用 **Geo Match Statement** (地理匹配)。
    * 逻辑：Block requests NOT from specific countries (如果不是来自特定国家，则阻止)。
* **日志：** WAF 原生支持日志记录 (Logging Configuration)，可以记录所有请求（包括 Blocked）。题目要求“Able to log blocked requests”。虽然选项没明说“Enable Logging”，但使用 WAF 是前提。
* **选项对比：**
    * **选项 B:** Create WAF Web ACL. Configure rule to **block requests not originating from specific countries**. Associate with ALB. 这是最直接的配置。WAF 自带 Geo 数据库，无需维护 IP 列表。
    * 选项 A (IPSet): 手动维护国家 IP 库？那是天文数字，不可能维护。
    * 选项 C (Shield): Shield 是防 DDoS 的，不负责精细的 Geo 封禁（Shield Advanced 可能有，但 WAF 是标准工具）。
    * 选项 D (Security Group): SG 不支持 Geo/Country 规则。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **WAF Geo Match:** 零维护成本的地理位置访问控制。

**5. 📚 核心考点:** WAF 的地理封禁规则配置。

---

#### 📝 [389/529] FSx for Windows 跨区域灾备 (DataSync + Peering)

**1. 🕵️‍♂️ 题眼与约束分析**
* **源：** FSx for Windows (Region A)。
* **目标：** Replication to Region B for DR (灾备)。
* **约束：** **Not over public internet** (不走公网)。
* **工具：** AWS Managed Services。

**2. ⚡ 秒杀思路**
* **复制工具：**
    * **AWS DataSync:** 支持 FSx 到 FSx 的传输，且支持跨区域。
    * **网络路径：** DataSync 流量默认走公网（如果端点是公网）。要走私网，需要 **VPC Peering** (连接两个区域的 VPC) + **VPC Endpoint** (PrivateLink)。
* **选项对比：**
    * A (S3 + File Gateway): 题目要求目标也是 FSx（为了 DR 快速恢复，S3 还要还原）。
    * **C:** Region B create FSx. **VPC Peering** between regions. Use **PrivateLink** (VPC Endpoint) for DataSync.
        * 这确保了控制流和数据流都走 AWS 骨干网（Peering），不暴露给公网。DataSync 任务配置源和目标为两个区域的 FSx。
    * B (VPN): Region 间用 VPN？性能不如 Peering，且 Peering 是 AWS 原生的跨区连接。
    * D (Transfer Family): 是做 SFTP 的，不是做文件系统复制的。
    * **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **DataSync:** 高效的文件复制工具。
* **VPC Peering:** 提供跨区域的私有网络通道。

**5. 📚 核心考点:** 跨区域 FSx 数据复制的私有网络架构。

---

#### 📝 [390/529] 数据库 10TB 级灾备 (Aurora Global)

**1. 🕵️‍♂️ 题眼与约束分析**
* **数据量：** 10 TB。
* **RPO:** 5 mins。
* **RTO:** 10 mins。
* **需求：** Failover to secondary region。
* **目标：** **Most cost-effective** to meet requirements。

**2. ⚡ 秒杀思路**
* **方案 A (Snapshot Copy):**
    * 10 TB 的快照，每 5 分钟复制一次？根本传不完。快照复制是增量的，但对于 10TB 级别的大库，RPO 5 分钟很难通过快照保证（快照完成和传输都需要时间）。且 RTO 10 分钟恢复 10TB 数据？从快照还原 10TB 数据需要很久（预热）。不现实。
* **方案 B (RDS RR):**
    * RDS 跨区域副本。RPO 很低（异步复制），RTO 快（提升副本）。满足要求。
* **方案 C (DMS):**
    * 两个 Aurora 集群 + DMS CDC。架构复杂，DMS 实例有成本。
* **方案 D (RDS Local RR):**
    * Same Region？题目要求 Secondary Region。排除。
* **关键决战 A vs B:**
    * 题目问 "Cost-effective"。
    * RDS RR (B) 需要一直开着备用实例（计算+存储费用）。
    * Aurora Global Database (未列出，但在 C 中提及 Aurora) 也是一直开着。
    * 快照 (A) 便宜，但 **技术上无法满足 10TB 数据的 10分钟 RTO**。从 S3 还原 10TB 到 Aurora/RDS 即使是并行也远超 10 分钟（Hydration）。
    * 所以必须选 **热备/温备** 方案。
    * **选项 B (RDS Cross-Region RR)** 是满足 RPO/RTO 的最标准、成本相对合理的方案（相比 Aurora Global 可能便宜一点，取决于实例类型）。
    * **Wait, 为什么不选 C (Aurora + DMS)?** DMS 引入了额外的组件和管理开销。Aurora Global Database（原生复制）比 DMS 好。但选项 C 是 "Aurora + DMS"，不是 "Aurora Global"。
    * **Aurora Global vs RDS RR:** 题目没说一定要用 Aurora。RDS for MySQL/PG 也是选项。
    * **B 选项** 是完全可行的。
    * **结论：** 只有 B 和 C (以及隐含的 Aurora Global) 能满足时间要求。B 最简单直接。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **Cross-Region Read Replica:** 满足分钟级 RPO/RTO 的标准灾备方案。

**5. 📚 核心考点:** 大数据量数据库的灾备 RTO/RPO 限制。

---
**小结：**
这组题目的 **ABAC**、**Service Catalog**、**Athena 分区** 都是拿分点。

**恭喜你，390 题！加油！**