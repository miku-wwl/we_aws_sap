这 10 道题涵盖了 **S3 Access Points VPC 限制**、**Elastic Beanstalk 蓝绿部署**、**S3 异步处理架构 (SQS + EC2)**、**Aurora Global Database 写入转发**、**SFTP 迁移 (AWS Transfer + EIP)**、**AppSync 实时订阅**、**DynamoDB 成本优化**、**SCP 强制网络源**。

特别是 **Q286 (S3 Access Points & SCP)** 和 **Q289 (Aurora Global Write Forwarding)** 是 SAP 考试中的高级特性题。

让我们开启 **逐题秒杀模式**！

---

#### 📝 [251/529] API 保护与成本优化 (WAF vs OAI)

*(注：这题与 Q251 重复，再次解析以加深印象)*

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** API Gateway 区域端点。
* **攻击：** Botnet (500 IPs, 1000 RPS)。
* **正常：** 6 Partners, 1 request/day。
* **目标：** Protect API, **Minimize cost**。

**2. ⚡ 秒杀思路**
* **防御：**
    * **WAF (Rate-based):** 限制速率。可以设得很低（如 5 分钟 100 次），挡住攻击者，放行正常用户。
    * **API Key:** 认证合作伙伴。
* **架构：**
    * 将 API Gateway 放在 **CloudFront** 后面，并在 CloudFront 上启用 WAF（利用全球边缘节点的抗 D 能力）。
    * 在 CloudFront 回源时添加包含 API Key 的自定义 Header。
    * API Gateway 检查 Header 中的 API Key。
* **选项对比：**
    * **B:** CloudFront + WAF (Rate Limit) + CloudFront Custom Header (API Key) + API Gateway Check。完美组合。
    * A (OAI): OAI 是 S3 的。
    * C/D (Allow IP): 维护 IP 列表麻烦，且防不住 IP 伪造（虽然 Botnet 通常也是真实 IP，但列表维护是痛点）。Rate Limit 更通用。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **WAF Rate Limit:** 清洗攻击流量。
* **API Key via CloudFront:** 确保请求合法且经过了 CloudFront/WAF。

**5. 📚 核心考点:** API Gateway 的边缘防护架构。

---

#### 📝 [252/529] Aurora 数据库活动监控 (DAS)

*(注：这题与 Q252 重复)*

**1. 🕵️‍♂️ 题眼与约束分析**
* **需求：** Monitor **ALL database activity** (包含 SELECT)。
* **DB:** Aurora PostgreSQL。

**2. ⚡ 秒杀思路**
* **工具：** **Database Activity Streams (DAS)**。
* **流程：** Aurora -> DAS -> Kinesis Streams -> Firehose -> S3。
* **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **DAS:** 原生审计，高性能，支持所有 SQL 操作记录。

**5. 📚 核心考点:** Aurora 审计标准方案。

---

#### 📝 [253/529] Graviton ASG 优化

*(注：这题与 Q253 重复)*

**1. 🕵️‍♂️ 题眼与约束分析**
* **现状：** 12 * `r6g.16xlarge` (利用率 25%)。
* **目标：** Cost-effective + Dynamic scaling。

**2. ⚡ 秒杀思路**
* **规格调整：** 16xlarge 利用率 1/4 -> **4xlarge**。
* **类型保持：** `r6g` (内存优化 Graviton)。
* **ASG:** Min/Max 设置。Min=3, Desired=3, Max=12。
    * 3 台 4xlarge 只是原来的 1/16 容量，但这可能是基于“当前利用率极低”的判断。或者题目暗示“利用率 1/4”是指单台 16xlarge 的利用率。
    * 无论如何，C 选项的规格调整方向是对的。
* **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **Right-sizing:** 降规格提高利用率。

**5. 📚 核心考点:** 实例规格优化。

---

#### 📝 [254/529] DynamoDB 成本优化 (DAX + Provisioned)

*(注：这题与 Q254 重复)*

**1. 🕵️‍♂️ 题眼与约束分析**
* **负载：** 批量写 (可预测) + 突发读 (热点 Key)。
* **目标：** Reduce cost。

**2. ⚡ 秒杀思路**
* **写优化：** 可预测 -> Provisioned Capacity (比 On-Demand 便宜)。
* **读优化：** 热点 Key -> DAX (缓存)。
* **锁定 D。**

**3. ✅ 正确选项解析 (选项 D)**
* **Provisioned:** 适合可预测负载。
* **DAX:** 适合热点读。

**5. 📚 核心考点:** DynamoDB 成本优化组合。

---

#### 📝 [255/529] PrivateLink 排错

*(注：这题与 Q255 重复)*

**1. 🕵️‍♂️ 题眼与约束分析**
* **故障：** PrivateLink 连不上后端 EC2。
* **排查：** NACL 和 SG。

**2. ⚡ 秒杀思路**
* **NACL (A):** 检查 NLB 子网和 EC2 子网之间的通信。
* **Security Group (C):** 检查 EC2 SG 允许来自 NLB 子网的入站。
* **锁定 A, C。**

**3. ✅ 正确选项解析 (选项 A, C)**
* **Network Path:** PrivateLink 流量在 Service VPC 内表现为从 NLB 发起。

**5. 📚 核心考点:** PrivateLink 后端网络配置。

---

#### 📝 [256/529] S3 KMS 成本优化

*(注：这题与 Q256 重复)*

**1. 🕵️‍♂️ 题眼与约束分析**
* **痛点：** KMS 请求费太高 (SSE-KMS)。
* **目标：** Optimize cost。

**2. ⚡ 秒杀思路**
* **方案：** 切换到 **SSE-S3** (免费)。
* **手段：** **S3 Batch Operations** (Copy)。
* **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **SSE-S3:** 消除 KMS 费用。

**5. 📚 核心考点:** S3 加密类型与成本。

---

#### 📝 [257/529] Lambda 数据库压力解耦

*(注：这题与 Q257 重复)*

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** S3 -> Lambda -> DynamoDB。
* **问题：** Lambda 并发高，DB 写入慢。

**2. ⚡ 秒杀思路**
* **解耦：** SQS (D)。
* **DB 优化：** WCU (B)。
* **锁定 B, D。**

**3. ✅ 正确选项解析 (选项 B, D)**
* **SQS:** 缓冲。
* **WCU:** 写能力。

**5. 📚 核心考点:** 异步架构解耦。

---

#### 📝 [258/529] Web 上传重构 (Amplify)

*(注：这题与 Q258 重复)*

**1. 🕵️‍♂️ 题眼与约束分析**
* **需求：** Accelerate dev, Least overhead, Upload to S3。

**2. ⚡ 秒杀思路**
* **工具：** **AWS Amplify** (D)。一站式集成 Auth, Storage, Hosting。
* **锁定 D。**

**3. ✅ 正确选项解析 (选项 D)**
* **Amplify:** 快速开发。

**5. 📚 核心考点:** Web 应用现代化。

---

#### 📝 [259/529] ASG 日志持久化

*(注：这题与 Q259 重复)*

**1. 🕵️‍♂️ 题眼与约束分析**
* **问题：** 缩容后日志丢失。

**2. ⚡ 秒杀思路**
* **方案：** **CloudWatch Agent** (B)。实时推日志。
* **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **CW Agent:** 日志分离。

**5. 📚 核心考点:** EC2 日志持久化。

---

#### 📝 [260/529] CORS 排错

*(注：这题与 Q260 重复)*

**1. 🕵️‍♂️ 题眼与约束分析**
* **故障：** API Gateway 报 CORS 错。

**2. ⚡ 秒杀思路**
* **位置：** 在 **API Gateway** 上启用 CORS (C)。
* **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **API Gateway CORS:** 处理 OPTIONS 请求。

**5. 📚 核心考点:** Serverless CORS。

---
*(注意：以上 251-260 与上一组题目完全重复，可能是用户输入时的重复粘贴。我已快速通过。重点看下面新的题目)*

**请发送下一组题目（从 281 开始）！**
**(Wait, 281-290? You sent 251-260 above, but labeled them 251. Let me check the numbering continuity.)**
Ah, I see. You provided 281-290 in the *previous* prompt context (User: "单选题 281/529..."). Let me solve those now.

---

### **正式解析 Q281 - Q290**

#### 📝 [281/529] 降低 Presto 查询成本 (S3 数据湖)

**1. 🕵️‍♂️ 题眼与约束分析**
* **现状：** EMR (Persistent Cluster) + HDFS (ORC Data)。
* **负载：** SQL Queries (Presto), Run time < 15 mins, Only 5pm-10pm (每天 5 小时)。
* **痛点：** **High cost** (持久集群一直开着很贵)。
* **目标：** **Most cost-effective**。

**2. ⚡ 秒杀思路**
* **计算存储分离：**
    * 当前架构是存算耦合（HDFS 在 EMR 上）。为了存数据，EMR 必须 24/7 开着，即使只有 5 小时在跑查询。
    * 应该把数据移到 **Amazon S3**。S3 存储便宜且持久。
* **计算层：**
    * **Athena (Serverless Presto):** Athena 底层就是 Presto。它按查询数据量收费，没有闲置成本。对于每天只跑几小时的查询，Athena 是最省钱的（Pay-per-query）。且不需要维护 EMR 集群。
    * **EMR on S3 (Transient):** 也可以，但每次要启动集群，而且 Athena 更 Serverless。
    * **Redshift (A/D):** Redshift 成本比 Athena 高（需要预置节点，即使是 RA3 也有闲置费，或者 Serverless 也有底价）。
* **选项 B:** Data in **S3**, Query with **Glue Data Catalog & Athena**。这是标准的数据湖查询架构，极致成本效益。
* **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **S3:** 低成本存储。
* **Athena:** Serverless 查询，无闲置成本。

**5. 📚 核心考点:** 从 EMR/HDFS 迁移到 S3 数据湖 (Athena) 的成本优势。

---

#### 📝 [282/529] 强制标签策略 (SCP)

**1. 🕵️‍♂️ 题眼与约束分析**
* **痛点：** 成本不可见，缺乏一致标签。
* **需求：** Ensure **ALL existing and future** resources have Cost Center & Project ID tags。
* **环境：** Organizations。

**2. ⚡ 秒杀思路**
* **现有资源 (Existing):**
    * **Tag Editor:** 用于批量修改现有资源的标签。
    * **AWS Config:** 用于持续检测不合规资源（未标记）并报警/修复。
* **未来资源 (Future):**
    * **SCP (Service Control Policy):** 可以强制要求“创建资源时必须带特定标签”。如果不带，拒绝创建 (`Deny` `RunInstances` without `RequestTag`).
* **选项对比：**
    * 选项 A (Tag Editor): 只解决了现有，没强制未来。
    * 选项 B (Config + Lambda): 是事后修复（Reactive），不是事前强制（Proactive）。
    * 选项 D (IAM Role): 更新所有角色太麻烦。
    * **选项 C:**
        * Use **Tag Editor** for existing.
        * Use **SCP** to restrict resource creation (Future enforcement).
        * 这涵盖了存量和增量，且手段最强硬（SCP）。
    * **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **Tag Editor:** 处理存量。
* **SCP:** 强制增量。

**5. 📚 核心考点:** 标签治理的全面策略 (SCP + Tag Editor)。

---

#### 📝 [283/529] 跨账户 S3 私有上传 (VPC Peering vs PrivateLink)

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** On-prem $\rightarrow$ S3 (3 different accounts)。
* **连接：** **No existing dedicated connection** (没专线)。
* **需求：** **Privately** (私网)，Not over Internet。
* **选择：** 2 个步骤。

**2. ⚡ 秒杀思路**
* **连接建立：**
    * 既然没专线，要私网传数据，必须先建 **Direct Connect (DX)** 或 **VPN**。
    * 题目选项 A/B 提到了 "Set up AWS Direct Connect"。虽然题目说“No existing”，但这可能是解决方案的一部分（建立连接）。
    * 私有传输 S3，通常推荐 **Direct Connect + Public VIF** (但这是公网路由，只是专用线路) 或者 **Direct Connect + Private VIF + VPC Endpoint**。
    * 题目要求 "Send data privately, NOT over internet"。DX Public VIF 的流量虽然走专线，但用的是公网 IP。更严格的“私有”通常指 **Interface VPC Endpoint (PrivateLink)**，它使用 VPC 私有 IP。
* **架构设计：**
    1.  建立 **Network Account** 和 **Private VPC**。设置 DX (Private VIF)。 $\rightarrow$ **选中 A**。
        * (B 是 Public VIF，虽然也行，但 A 的 Private VIF 配合 Endpoint 更符合 "Privately" 的语境)。
    2.  在 Network Account VPC 中创建 **S3 Interface Endpoint** (C) 或 **Gateway Endpoint** (D)。
        * **Gateway Endpoint:** 不支持从 On-prem 通过 DX/VPN 直接访问（路由表限制）。
        * **Interface Endpoint:** 支持从 On-prem 访问。
        * $\rightarrow$ **选中 C**。
* **跨账户 S3：**
    * Interface Endpoint 可以访问任何账户的 S3 桶（只要 Endpoint Policy 和 Bucket Policy 允许）。所以只需在一个网络账户建 Endpoint 即可。
* **锁定 A, C。**

**3. ✅ 正确选项解析 (选项 A, C)**
* **DX Private VIF:** 建立私网通道。
* **S3 Interface Endpoint:** 允许从 On-prem 通过私网 IP 访问 S3。

**5. 📚 核心考点:** 本地通过 DX/VPN 私网访问 S3 的标准架构 (Interface Endpoint)。

---

#### 📝 [284/529] DynamoDB 周期性高峰优化 (Reserved Capacity)

**1. 🕵️‍♂️ 题眼与约束分析**
* **模式：** 每天 4 小时高峰，其余时间低。
* **现状：** Provisioned (100k RCU / 80k WCU) 覆盖高峰。
* **痛点：** 成本高。
* **目标：** Reduce cost, **Minimize operational overhead**。

**2. ⚡ 秒杀思路**
* **Auto Scaling (C):** 可以自动调整。但是对于极其剧烈的高峰（100k RCU），Auto Scaling 可能有滞后。不过通常是首选。
* **Reserved Capacity (D):**
    * DynamoDB 预留容量是**全天候**生效的（买了 100k，就是 24h 的 100k）。
    * 如果只在高峰 4 小时用 100k，剩下 20 小时闲置。买全天 100k 的预留容量**非常亏**（除非闲置时间利用率也高，或者折扣巨大）。
    * **但是，** 题目目前的配置是 "Provisioned... to meet peak"。也就是现在就是 24 小时开着 100k。
    * 如果不想改架构（Minimize overhead），买 Reserved Capacity 确实能直接打折。
    * **然而，** 更好的做法是 **Auto Scaling**。让它在非高峰期降下来。
    * **比较 C 和 D:**
        * C (Auto Scaling): 节省 20 小时的费用（降到低水位）。这比 D (买全天折扣) 省得多。且 DynamoDB Auto Scaling 是内置功能，Overhead 很小。
        * **但是，** 有时候题目会暗示 "Standard pattern"，如果 Reserved Capacity 能覆盖高峰，它是最简单的“财务手段”。但技术上 Auto Scaling 更优。
    * **再看 B (On-Demand):** 对于每天 4 小时的规律高峰，On-Demand 通常比 Provisioned + ASG 贵。
    * **关键点：** "Minimize operational overhead"。Auto Scaling 是一次性配置。
    * **还有一个因素：** 100k RCU 很大。Auto Scaling 预热可能跟不上？如果模式是 "Predictable" (可预测)，可以使用 **Scheduled Scaling** (预定扩展)。选项 C 只是说 "Enable Auto Scaling"。
    * **让我们算笔账：**
        * 现状：24h * 100k。
        * 方案 C: 4h * 100k + 20h * 1k。节省约 80%。
        * 方案 D: 24h * 100k * (折扣，比如 50%)。节省 50%。
        * 显然 C 更省。
    * **结论：** 除非题目暗示 Auto Scaling 不适用（如极速突发），否则对于可预测的周期负载，Auto Scaling (或者 Scheduled Scaling) 是正解。选项 C 最合理。
    * **修正：** 题目问 "Most cost-effective"。C 肯定比 D 省。
    * **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **DynamoDB Auto Scaling:** 自动适应负载变化，消除闲置浪费。

**5. 📚 核心考点:** DynamoDB 周期性负载的成本优化。

---

#### 📝 [285/529] 实时评论系统 (AppSync)

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** 博客评论。
* **需求：** **Comments appear in real-time** (实时显示)。
* **现状：** API Gateway (REST)。

**2. ⚡ 秒杀思路**
* **实时推送技术：**
    * **WebSockets:** 允许服务器主动推数据给客户端。
    * **AWS AppSync (C):** 托管的 GraphQL 服务，原生支持 **Subscriptions** (基于 WebSockets)。客户端订阅评论更新，一旦有新评论，AppSync 自动推送。这是实现“实时评论”的最现代、最简单的 AWS 方案。
* **选项对比：**
    * 选项 A (CloudFront Cache): 缓存会导致看到旧数据，反实时。
    * 选项 B (Polling): 轮询（每 10 秒）延迟高，且服务器压力大，不是“实时”。
    * 选项 D (Lambda Concurrency): 无关。
    * **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **AppSync GraphQL Subscriptions:** 轻松实现实时数据推送。

**5. 📚 核心考点:** 实时应用架构 (AppSync vs Polling)。

---

#### 📝 [286/529] 强制 S3 Access Point 网络来源 (SCP)

**1. 🕵️‍♂️ 题眼与约束分析**
* **需求：** Allow Product Teams to create Access Points, BUT only **VPC-restricted** ones (只能创建限制在 VPC 内的 AP).
* **禁止：** Internet-accessible Access Points。
* **管理：** Hundreds of accounts (Organizations)。
* **目标：** **Most operationally efficient** (最高效)。

**2. ⚡ 秒杀思路**
* **全局强制：**
    * 要在几百个账户里强制一个规则，**SCP (Service Control Policy)** 是最佳工具。
    * **SCP 逻辑：** **Deny** `s3:CreateAccessPoint` **Unless** `s3:AccessPointNetworkOrigin` == `VPC`。
    * 这样，任何人尝试创建“Internet”类型的 AP 都会被拒绝。
* **选项对比：**
    * 选项 A/D (Resource/Bucket Policy): 需要在每个 AP 或 Bucket 上配，无法“预防”创建（虽然 Bucket Policy 可以拒绝非 VPC 访问，但题目是限制“创建 Access Point”这个动作本身的属性）。
    * 选项 C (StackSets IAM Policy): 给每个用户/角色发 Policy？管理太乱，且容易被绕过。
    * **选项 B:** **SCP at Root level**。一键生效，覆盖全员。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **SCP:** 组织级预防性控制。
* **Condition Key:** `s3:AccessPointNetworkOrigin` 区分 VPC 和 Internet AP。

**5. 📚 核心考点:** S3 Access Point 类型的合规控制 (SCP)。

---

#### 📝 [287/529] Elastic Beanstalk 蓝绿部署切换 (Swap URLs)

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** Elastic Beanstalk (EB) 蓝绿部署。
* **现状：** 已创建新环境 (Green) 并部署了新代码。
* **下一步：** Cutover (切换流量)。

**2. ⚡ 秒杀思路**
* **EB 原生功能：** **Swap Environment URLs** (交换环境 URL)。
    * 它会自动交换两个环境的 CNAME 记录。
    * 瞬间将流量从 Blue 切到 Green。
    * 这是一个原子操作，DNS 传播极快（因为是 AWS 内部 DNS 别名切换）。
* **选项对比：**
    * 选项 A (Route 53 Redirect): 不需要手动配 R53，EB Swap URL 更好用。
    * 选项 C (Replace Launch Config): 这是原地更新，不是蓝绿。
    * 选项 D (Update DNS): 手动改 DNS 太慢且易错，Swap URL 是 EB 提供的标准按钮。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **Swap Environment URLs:** Elastic Beanstalk 实现零停机蓝绿部署的核心功能。

**5. 📚 核心考点:** Elastic Beanstalk 蓝绿部署操作。

---

#### 📝 [288/529] 图像处理架构 (S3 + SQS + ASG)

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** 用户上传图片，加文字，发布。
* **流量：** 10,000 concurrent uploads (高峰)。
* **处理：** 叠加文字 (CPU 密集)。
* **架构：** 解耦、抗压。

**2. ⚡ 秒杀思路**
* **摄取层：** 直接上传到 **S3** (B/C)。EFS (A) 或 EBS (D) 需要 EC2 作为前端接收，10000 并发需要巨大的 EC2 集群，不划算且难维护。S3 可以无限吞吐。
* **解耦层：**
    * S3 Event -> **SQS** (C) 或 **SNS** (B)。
    * SQS 是缓冲队列，适合削峰填谷。EC2 Worker 从 SQS 拉取任务。
    * SNS 是推送，如果并发大，会压垮 EC2（除非 EC2 很多，或者 SNS 再推给 SQS）。直接用 SQS 更稳。
* **处理层：**
    * EC2 ASG 根据 **Queue Depth** (队列深度) 扩展。这是标准模式。
* **结果存储：**
    * 处理完存回 S3 (C)。
    * EFS (B) 也可以，但 S3 也是 web hosting 的好地方。
* **B vs C:**
    * C (SQS) 提供了更好的流量控制和缓冲。B (SNS) 是推模式，对于后端处理能力有限的场景（EC2 ASG 需要时间启动），SNS 可能会导致请求丢失或重试风暴（除非 SNS -> SQS）。
    * 且 C 选项描述了 "S3 Event -> SQS -> EC2 -> S3"，这是经典的**扇入 (Fan-in)** 处理架构。
    * **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **S3 Direct Upload:** 卸载上传压力。
* **SQS:** 异步缓冲，保护后端。
* **Auto Scaling:** 按需计算。

**5. 📚 核心考点:** 高并发图像处理的 Serverless/异步架构。

---

#### 📝 [289/529] 跨大西洋双活数据库 (Aurora Global Write Forwarding)

**1. 🕵️‍♂️ 题眼与约束分析**
* **现状：** RDS MySQL (us-east-1)。
* **需求：**
    1.  Make data available to Europe (欧洲可用)。
    2.  **Low latency** for both US and Europe (双边低延迟)。
    3.  **Both need to WRITE** (双边写入)。
    4.  **See updates in real-time** (实时同步)。
* **架构：** Active-Active Database。

**2. ⚡ 秒杀思路**
* **Aurora Global Database:**
    * 支持 **Write Forwarding** (写入转发)。
    * 从区域（欧洲）的副本可以直接接受写请求，并自动转发给主区域（美国）的主节点。
    * 这种方式让欧洲应用感觉像是“本地写入”，虽然物理上还是写回美国，但应用逻辑简化了，且读是本地的（低延迟）。
    * 相比于多主（Multi-Master，仅限同区域），Write Forwarding 是跨区域实现“伪双活写入”的最佳方案。
* **选项对比：**
    * 选项 B (RDS RR Write back?): RDS Read Replica 是只读的，不支持“写回”。必须应用层自己拆分读写。
    * 选项 C (MySQL Logic Replication): 运维极其复杂，冲突解决难。
    * 选项 A vs D:
        * A: 创建 Aurora Replica -> Promote -> Add Region。这是**迁移**到 Aurora Global 的正确步骤（从 RDS 快照或副本迁移）。
        * D: "Convert RDS to Aurora"。RDS 控制台确实有 "Create Aurora Read Replica" 的功能（A 的前半部分）。
        * 关键是 **Write Forwarding**。
        * A 和 D 都提到了 Write Forwarding。
        * 区别在于迁移过程。
        * **A 的流程：** Create Aurora Replica from RDS -> Promote -> Add Region。这是将 RDS 数据迁移到 Aurora Global 的**零停机/低停机**标准路径。
        * **D 的流程：** "Convert RDS... to Aurora"。直接转换？通常是通过快照恢复或创建副本提升。A 的描述更具操作性细节。
        * **更正：** RDS 控制台现在支持 "Migrate to Aurora" (Snapshot based) 或 "Create Aurora Read Replica" (Replication based)。A 选项使用的是基于复制的方法，停机时间最短。
        * **结论：** A 选项描述了一个完整的、低风险的迁移和架构搭建过程。
    * **锁定 A。**

**3. ✅ 正确选项解析 (选项 A)**
* **Aurora Global Database:** 解决跨区域读。
* **Write Forwarding:** 解决跨区域写（简化应用）。
* **Migration via Replica:** 最小化迁移停机时间。

**5. 📚 核心考点:** RDS 到 Aurora Global Database 的迁移与双向读写能力。

---

#### 📝 [290/529] SFTP 固定 IP 迁移 (Transfer Family)

*(注：这题与 Q249 类似，但侧重不同)*

**1. 🕵️‍♂️ 题眼与约束分析**
* **现状：** EC2 SFTP, **Elastic IP (EIP)**, Security Group (Allow List)。
* **需求：**
    1.  Improve availability (提高可用性)。
    2.  Minimize management (减少管理)。
    3.  **Do not change connection method** (客户连接方式不变 -> **Must keep EIP**)。
* **迁移：** EC2 -> ?

**2. ⚡ 秒杀思路**
* **服务：** **AWS Transfer Family**。
* **IP 保留：**
    * Transfer Family 支持 **VPC Endpoint** (Internet facing) 类型，并且可以**关联现有的 EIP**。
    * 这样客户不需要改 IP，直接连旧的 EIP 就能连到新的 Transfer Family。
* **选项对比：**
    * 选项 A (Public endpoint): Public Endpoint 类型是 AWS 托管 IP，**不支持** 绑定自己的 EIP。必须用 **VPC Endpoint** 类型才能绑 EIP。
    * 选项 B: "VPC hosted internet facing endpoint... Associate EIP... Attach Security Group"。这完美复刻了 EC2 的网络环境（EIP + SG），且迁移到了托管服务。
    * 选项 C (EFS + Fargate + NLB): 架构太复杂，虽然也能绑 EIP（在 NLB 上），但 Transfer Family 是开箱即用的 SFTP 服务，Fargate 还要自己维护 SFTP 容器。
    * 选项 D (EBS Multi-Attach): 复杂且非托管。
* **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **Transfer Family (VPC Endpoint):** 支持绑定 EIP 和安全组，实现无缝迁移。

**5. 📚 核心考点:** 保留 EIP 的 SFTP 迁移配置细节。

---
**小结：**
这组题目的 **Aurora Write Forwarding**、**S3 Access Points**、**Transfer Family VPC Endpoint** 都是 SAP 进阶考点。

**恭喜你，290 题！**