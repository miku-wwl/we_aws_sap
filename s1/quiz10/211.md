这 10 道题涵盖了 **迁移评估**、**数据库连接耗尽 (RDS Proxy vs SQS)**、**Grafana 迁移**、**Oracle 迁移与密码轮换**、**低成本 VPN 混合云**、**集中式流量过滤 (Network Firewall)**、**Web 安全 (WAF + Firehose 日志)**、**API Gateway 私有化**、**安全组变更审计 (Config)**、**Kinesis 消费者限流优化**。

特别是 **Q212 (SQS 解耦 DB 压力)** 和 **Q216 (Centralized Outbound Filtering)** 是 SAP 考试中的高频场景。

让我们开启 **逐题秒杀模式**！

---

#### 📝 [211/529] 迁移评估 (VMware Inventory)

**1. 🕵️‍♂️ 题眼与约束分析**
* **环境：** VMware ESXi (Thousands of VMs)。
* **痛点：** No CMDB, little knowledge of utilization (无资产清单，不知利用率)。
* **需求：** Accurate inventory (准确清单) for migration planning。
* **目标：** **Least operational overhead**。

**2. ⚡ 秒杀思路**
* **工具选型：**
    * **Migration Evaluator (A/C):** (前身 TSO Logic)。专门用于迁移前的商业案例评估和资产发现。
    * **无代理收集器 (Agentless Collector):** 在 ESXi 宿主机上部署一个 Collector 即可收集所有 VM 的信息。相比于在每个 VM 上装 Agent (A/D)，无代理部署最快、干扰最小 (Least overhead)。
* **选项对比：**
    * 选项 A (Patch Manager): Patch Manager 是打补丁的，不是部署 Migration Evaluator 的标准方式（且要在每个 VM 装 Agent）。
    * 选项 B (CSV Export): 手动导出 CSV 检查磁盘？太原始，几千台机器怎么搞？
    * 选项 D (MGN Agent): MGN Agent 是迁移时用的，不是评估阶段用的。且几千台装 Agent 太累。
    * **选项 C:** 部署 **Agentless Collector** 到 ESXi。自动发现所有 VM 的配置和利用率，识别僵尸服务器 (Inactive)，导入 Migration Hub。这是标准的无侵入评估流程。
    * **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **Migration Evaluator (Agentless):** 通过 vCenter/ESXi API 收集数据，零侵入，部署最快。

**5. 📚 核心考点:** 迁移评估阶段的工具最佳实践 (Migration Evaluator Agentless)。

---

#### 📝 [212/529] Lambda 压垮数据库 (SQS 解耦)

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** Lambda (微服务) $\rightarrow$ On-prem SQL DB (Direct Connect)。
* **故障：** Lambda 调用量大 $\rightarrow$ 数据库崩溃 (连接数/并发过高)。
* **需求：** Protect database from crashing (保护数据库)。

**2. ⚡ 秒杀思路**
* **问题本质：** 流量洪峰导致 DB 无法承受。
* **解决方案 1 (架构解耦):** 引入 **SQS 队列**。
    * Lambda 1 (接收请求) -> SQS。
    * Lambda 2 (处理请求) <- SQS。
    * **关键点：** 限制 Lambda 2 的 **Reserved Concurrency** (预留并发)。例如 DB 只能抗 100 个连接，就把 Lambda 2 并发设为 50。这样无论 SQS 积压多少消息，同时连接 DB 的 Lambda 永远不会超过 50 个，数据库绝对安全。 $\rightarrow$ **选中 A**。
* **解决方案 2 (中间件):**
    * **RDS Proxy (C):** RDS Proxy 只能代理 AWS RDS，**不能**代理本地数据库 (On-prem SQL DB)。排除。
* **解决方案 3 (迁移):**
    * 迁移到 Aurora Serverless (B) 确实能扩容，但题目问的是“保护数据库”，通常指保护现有数据库，或者迁移成本较高（DataSync 迁移 DB 数据不是最佳实践，通常用 DMS）。且 A 选项是经典的“削峰填谷”模式，成本极低。
* **解决方案 4 (SNS):**
    * SNS (D) 是推送模式，如果流量大，SNS 会疯狂调用 Lambda，Lambda 还是会压垮 DB（除非设了并发限制，但 D 的并发限制是 "Equal to connections"，万一 DB 还有其他负载呢？且 SNS 没有缓冲能力，失败会丢消息/进 DLQ。SQS 有缓冲，更稳）。
    * **重点：** SQS 的缓冲能力是保护下游的核心。
    * **锁定 A。**

**3. ✅ 正确选项解析 (选项 A)**
* **SQS:** 缓冲洪峰。
* **Lambda Reserved Concurrency:** 限制并发消费速度，充当“节流阀”。

**5. 📚 核心考点:** Serverless 架构下的数据库保护模式 (Throttling pattern)。

---

#### 📝 [213/529] Grafana 迁移 (Managed Service)

**1. 🕵️‍♂️ 题眼与约束分析**
* **现状：** EC2 上自建 Grafana。
* **需求：** High Availability (高可用), < 10 min downtime, Keep dashboards。
* **目标：** **Least operational overhead** (最小运维)。

**2. ⚡ 秒杀思路**
* **托管服务：** **Amazon Managed Grafana (AMG)**。AWS 托管服务，自动高可用，无需运维 EC2。
* **迁移：** Grafana 支持导出/导入 Dashboard (JSON)。
* **选项对比：**
    * 选项 A (CloudWatch Dashboard): 要重新创建仪表盘，工作量大且可能不完全兼容 Grafana 的丰富图表。
    * 选项 C (EC2 ASG + EFS): 还是自建，还要维护 AMI 和 EFS，Overhead 高。
    * 选项 D (AWS Backup): 备份恢复是灾备方案，不是高可用方案（故障时会有停机，虽然 <10min 可能达标，但平时运维还是要管 EC2）。
    * **选项 B:** 创建 **Managed Grafana** 工作区。导出导入仪表盘。彻底摆脱 EC2 运维，且 AMG 默认高可用。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **Amazon Managed Grafana:** 全托管，SAML 集成，多数据源支持。

**5. 📚 核心考点:** 开源工具的 AWS 托管替代品 (Grafana -> AMG)。

---

#### 📝 [214/529] Oracle 迁移与密码轮换 (RDS + Secrets Manager)

**1. 🕵️‍♂️ 题眼与约束分析**
* **源端：** On-prem Oracle。
* **目标：** Migrate to AWS。
* **安全需求：** **Rotate password annually** (每年轮换)。
* **目标：** **Least operational overhead**。

**2. ⚡ 秒杀思路**
* **数据库选型：**
    * **RDS for Oracle (B):** 托管服务，运维最少。
    * EC2 (C): 自建运维重。
    * DynamoDB/Neptune (A/D): 异构迁移（关系型转 NoSQL/图），Schema 转换极其复杂，甚至不可行。
* **密码轮换：**
    * **Secrets Manager (B):** 原生支持 RDS 密码的**自动轮换**（内置 Lambda 轮换器）。
    * SSM Parameter Store (A/C): 需要自己写 Lambda 逻辑。
* **综合：** B 选项（RDS + Secrets Manager）是标准答案。
* **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **RDS for Oracle:** 托管数据库。
* **Secrets Manager:** 托管凭证轮换。

**5. 📚 核心考点:** 数据库迁移与凭证自动化轮换的最佳实践。

---

#### 📝 [215/529] 低成本混合云网络 (Shared Subnet + VPN)

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** 多团队，单区域。
* **连接：** On-prem connectivity。
* **带宽：** **< 50 Mbps** (非常小)。
* **目标：** **Most cost-effective** (最省钱)。
* **选择：** 2 个步骤。

**2. ⚡ 秒杀思路**
* **连接方式：**
    * 带宽很小 (<50M)，**Site-to-Site VPN (D)** 足够且最便宜（每个连接几十刀/月）。Direct Connect (E) 太贵且没必要。
    * $\rightarrow$ **选中 D**。
* **账户结构：**
    * 为了省钱和简化管理，可以使用 **Shared VPC (Resource Access Manager)**。
    * 在一个共享服务账户建 VPC 和 VPN，然后把**子网 (Subnets)** 共享给其他团队账户。
    * 这样大家共用这一个 VPN 连接，无需每个账户都建 VPN（省钱）。
    * $\rightarrow$ **选中 B**。
* **排除法：**
    * A (Deploy VPC to each account): 每个账户建 VPC，就要每个账户建 VPN（或者用 TGW）。VPN 数量多成本高。
    * C (Transit Gateway): TGW 本身有处理费和附件费，对于 <50Mbps 的小流量场景，成本可能高于直接共享子网。但 Shared VPC (B) 是完全免费的（RAM 免费）。
* **锁定 B, D。**

**3. ✅ 正确选项解析 (选项 B, D)**
* **Site-to-Site VPN:** 低带宽场景下的低成本连接。
* **VPC Sharing (RAM):** 避免重复网络建设，节省 NAT/VPN/TGW 费用。

**5. 📚 核心考点:** 小规模混合云网络的成本优化 (Shared VPC)。

---

#### 📝 [216/529] 集中式出站流量过滤 (Network Firewall + TGW)

**1. 🕵️‍♂️ 题眼与约束分析**
* **规模：** > 100 Accounts, TGW routing。
* **需求：** Centralized management of outbound filtering (集中管理出站过滤)。
* **流量：** < 25 Gbps per AZ。
* **工具：** Rule-based filtering (基于规则的过滤)。

**2. ⚡ 秒杀思路**
* **集中式架构：**
    * 创建一个专门的 **Egress VPC** (出站 VPC)。
    * 将 TGW 连接到这个 Egress VPC。
    * 所有业务 VPC 的 `0.0.0.0/0` 指向 TGW，TGW 指向 Egress VPC。
* **过滤工具：**
    * **AWS Network Firewall (B):** AWS 托管的网络防火墙，支持 Suricata 规则，支持域名过滤，性能好（自动扩展，支持 100Gbps+）。
    * **EC2 Proxy/Squid (A/D):** 需要维护 EC2 ASG，打补丁，高可用配置复杂。Network Firewall 是托管的，运维更少。
    * **分布式部署 (C/D):** "In each AWS account"。100个账户部署100个防火墙？管理和成本都是灾难。题目要求 "Centrally manage"。
* **路由配置：**
    * 在 Egress VPC 中，通过 **Gateway Load Balancer Endpoint** (Network Firewall 底层是 GWLB) 或者直接路由到 Firewall Endpoint 来清洗流量。
    * 选项 B 描述了：New VPC + TGW + NAT GW + **AWS Network Firewall**。这是标准的集中式出口架构。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **Centralized Egress VPC:** 流量汇聚点。
* **AWS Network Firewall:** 托管的下一代防火墙 (NGFW)，提供深包检测和域名过滤。

**5. 📚 核心考点:** 企业级集中式互联网出口架构 (TGW + Network Firewall)。

---

#### 📝 [217/529] Web 安全与审计 (WAF + Firehose)

**1. 🕵️‍♂️ 题眼与约束分析**
* **架构：** ALB + EC2。
* **安全需求：**
    1.  Filter common vulnerabilities (过滤常见漏洞 -> WAF)。
    2.  Send **Denied requests** to 3rd-party audit (被拒请求发给第三方)。
    3.  Highly Available。

**2. ⚡ 秒杀思路**
* **防御层：** **AWS WAF** 挂在 ALB 上。使用 **AWS Managed Rules** (常见漏洞)。
* **日志审计：**
    * WAF 支持 **Full Logging** (全量日志)。
    * WAF 日志的原生目的地支持：CloudWatch Logs, S3, **Kinesis Data Firehose**。
    * 题目要把日志发给第三方审计应用（通常支持 Splunk/Sumo Logic 等，或者 HTTP Endpoint）。**Kinesis Data Firehose** 支持直接投递到第三方服务（如 Splunk, Datadog, HTTP）。
    * 选项 B (CloudWatch Logs + Lambda): 也可以，但 Lambda 需要自己写代码搬运。Firehose 是托管的搬运工。
    * 选项 C/D (Firehose):
        * C: Configure ALB target group... Create Firehose... WAF on ALB... **Enable logging choosing Firehose**. 这个流程是对的。
        * D: 也是 Firehose。区别在于 D 还配置了 "Multi-AZ ASG"。题目要求 "Highly Available"，所以多 AZ 是必须的。
        * 让我们细看 C 和 D 的区别。
        * C: "Configure ALB... add EC2 as targets". 没提 ASG。
        * D: "Configure Multi-AZ ASG...". 提到了 ASG。
        * 显而易见，D 的架构更健壮（Multi-AZ ASG）。且 D 的 WAF 日志配置也是对的。
    * **锁定 D。**

**3. ✅ 正确选项解析 (选项 D)**
* **WAF:** 防御。
* **Kinesis Firehose:** 日志实时投递到第三方。
* **Multi-AZ ASG:** 高可用计算。

**5. 📚 核心考点:** WAF 日志投递与高可用架构。

---

#### 📝 [218/529] API Gateway 私有化访问 (Private Endpoint)

**1. 🕵️‍♂️ 题眼与约束分析**
* **现状：** 微服务 (EC2) 调用 新 API (API Gateway REST API)。
* **需求：** **Do not access via public internet** (不走公网)。
* **约束：** Old microservices call new API。

**2. ⚡ 秒杀思路**
* **API 类型：** 将 API Gateway 从 Regional/Edge 改为 **Private**。
* **访问方式：**
    * 在 VPC 内创建 **Interface VPC Endpoint** (for execute-api)。
    * 配置 **Resource Policy** 允许 VPC Endpoint 访问。
    * EC2 通过 VPC Endpoint 访问 API（流量走 AWS 骨干网）。
* **选项对比：**
    * 选项 A (VPN): VPC 到 API Gateway 没必要用 VPN，直接 Endpoint 即可。
    * 选项 C (Move to new VPC + TGW): 没必要移动 API Gateway（它是托管服务，没有“在 VPC 里”的概念，只有 Endpoint 在 VPC 里）。
    * 选项 D (Global Accelerator): 走公网的。
    * **选项 B:** 创建 Interface Endpoint + Resource Policy + Change type to Private。标准答案。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **Private API:** 专为 VPC 内网调用设计。

**5. 📚 核心考点:** API Gateway 的私有化部署 (Private Endpoint)。

---

#### 📝 [219/529] 安全组变更审计与警报 (Config + SNS)

**1. 🕵️‍♂️ 题眼与约束分析**
* **痛点：** 工程师乱改安全组导致不合规。
* **需求：** **Track changes** (跟踪变更) + **Send alert** (发警报)。
* **目标：** **Fastest way**。

**2. ⚡ 秒杀思路**
* **工具选型：**
    * **AWS Config:** 专门用于跟踪资源配置变更 (`AWS::EC2::SecurityGroup`) 和合规性检查（Managed Rules，如 `restricted-ssh`）。
    * **CloudTrail (B):** 记录 API 调用，但要检测“不合规配置”，需要自己写 CloudWatch Rule 匹配复杂的 API 参数，比较麻烦。
    * **SCP (A/C):** SCP 是预防性的（Deny），不是检测性的（Alert）。题目说“当工程师做出不合规更改时发送警报”，暗示允许更改但要报警（或者说是事后报警）。如果用 SCP，工程师根本改不了，也就没有“导致问题”一说了。但题目现状是“导致了问题”，说明需要审计机制。
    * **选项 D:** 启用 AWS Config 跟踪变更。Config 支持通过 **SNS** 发送配置变更和合规性变更通知。这是配置审计的标准方案。
    * **锁定 D。**

**3. ✅ 正确选项解析 (选项 D)**
* **AWS Config:** 配置历史记录与合规性监控。
* **SNS:** 实时通知。

**5. 📚 核心考点:** 资源配置变更的审计与告警 (AWS Config)。

---

#### 📝 [220/529] Kinesis 消费者限流 (Enhanced Fan-out)

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** Kinesis Data Streams $\rightarrow$ Multiple Applications (多个消费者)。
* **故障：** `ReadProvisionedThroughputExceeded` (读吞吐超限)。
* **原因：** Kinesis 标准模式下，所有消费者**共享** 2MB/sec/shard 的读带宽。如果有 3 个应用同时读，带宽就不够分了。
* **选择：** 3 个行动。

**2. ⚡ 秒杀思路**
* **行动 1：独享带宽。**
    * **Enhanced Fan-out (C):** 这是一个特性，允许消费者注册为 EFO 消费者。每个 EFO 消费者获得**独立**的 2MB/sec/shard 带宽，互不影响。这是解决多消费者争抢带宽的终极方案。 $\rightarrow$ **选中 C**。
* **行动 2：增加总带宽。**
    * 如果不想用 EFO（或者 EFO 还不够），可以**增加分片 (Resharding)**。分片越多，总吞吐越高。
    * $\rightarrow$ **选中 A** (Increase shards)。
* **行动 3：优化消费逻辑。**
    * 遇到限流错误，客户端应该进行 **Retries with Exponential Backoff** (指数退避重试)，以避免重试风暴加剧拥堵。
    * $\rightarrow$ **选中 E**。
* **排除法：**
    * B (KPL): KPL 是生产者库 (Producer)，题目报错的是消费者 (Read error)。
    * D (Decrease shards): 减少分片只会让拥堵更严重。
    * F (Dynamic Partitioning): 这是 Firehose 的功能，不是 Kinesis Streams 的解决限流方案。
* **锁定 A, C, E。**

**3. ✅ 正确选项解析 (选项 A, C, E)**
* **Enhanced Fan-out:** 解决多消费者带宽争抢。
* **Resharding:** 提升整体吞吐上限。
* **Backoff:** 标准的错误处理机制。

**5. 📚 核心考点:** Kinesis Data Streams 读吞吐优化 (Standard vs Enhanced Fan-out)。

---
**小结：**
这组题目的 **Network Firewall**、**Shared VPC**、**Kinesis EFO** 都是 SAP 必须拿下的分数。

**准备好下一组了吗？**