这 10 道题目（包含 1 道关于 IoT Greengrass 的边缘 ML 推理题）质量极高，涵盖了 **Spot Instance 优化**、**Compute Savings Plan**、**Lambda 别名/层/容器镜像**、**Global Accelerator 多区域路由**、**CloudFront 维护模式**、**IoT 边缘计算**、**迁移评估**、**DDoS 防护 (Shield Advanced)**、**DynamoDB/Aurora 多区域容灾**。

特别是 **Q157 (IoT Greengrass ML)** 和 **Q156 (Lambda Container Image)** 是 SAP 考试中的前沿考点。

让我们开启 **逐题秒杀模式**！

---

#### 📝 [151/529] 周期性午餐流量成本优化 (Spot vs Burst)

**1. 🕵️‍♂️ 题眼与约束分析**
* **前端：** 静态网站 (2 EC2)。
* **后端：** Python App (3 EC2)。
* **负载模式：** **Lunchtime heavy** (午餐高峰)，其余时间很少。
* **实例类型：** 目前是 Large General Purpose On-Demand (大通用按需)，按峰值配置。
* **目标：** **Optimize cost** (优化成本) + **No impact on availability** (不影响可用性)。

**2. ⚡ 秒杀思路**
* **前端优化：**
    * 静态网站跑在 EC2 上是巨大的浪费。S3 托管静态网站是最便宜且高可用的。
    * $\rightarrow$ **选中 B**。
* **后端优化：**
    * 目前是 Large 实例（为了扛午餐高峰），但平时空闲。这是 **Burstable Performance Instances (T系列)** 的完美场景。
    * T 系列实例平时积累 CPU 积分，午餐高峰消耗积分，成本远低于 M/C 系列的大实例。
    * Spot 实例 (D) 可能会被中断，虽然可以用，但题目强调 "No impact on availability"，纯 Spot 集群风险较大（除非混合 ASG），且对于有状态或长连接应用不友好。T 系列更稳妥。
    * $\rightarrow$ **选中 E**。
* **排除法：**
    * A (Compute Optimized): 只是换了类型，没解决空闲浪费。
    * C (Elastic Beanstalk): Beanstalk 底层也是 EC2，没改变成本结构。
* **锁定 B, E。**

**3. ✅ 正确选项解析 (选项 B, E)**
* **S3 Static Hosting:** 静态资源成本降至冰点。
* **Burstable Instances (T3/T4g):** 完美适配“短时间峰值 + 长时间空闲”的负载模式。

**5. 📚 核心考点:** 静态内容 S3 托管与 EC2 T 系列实例适用场景。

---

#### 📝 [152/529] EKS 成本优化 (Savings Plan + Spot)

**1. 🕵️‍♂️ 题眼与约束分析**
* **平台：** EKS (EC2) + RDS MySQL。正在开发 Fargate。
* **负载模式：** **Infrequent spikes** (不频繁的高峰，基于活动日期)。
* **目标：** **Most cost-effective**。

**2. ⚡ 秒杀思路**
* **计算层 (EKS):**
    * **Base Load (基线):** 应该用 **Compute Savings Plan** (比 EC2 SP 灵活，支持 Fargate 和 EC2)。覆盖预测的基线负载。
    * **Spikes (高峰):** 既然是不频繁的高峰，**Spot Instances** 是最便宜的扩展方式。EKS 对 Spot 支持很好（Managed Node Group）。
    * $\rightarrow$ **选中 D** (Compute SP for base + Spot for peaks)。
* **数据库层 (RDS):**
    * 选项 A (RI for peak): 为高峰买 RI？平时浪费惨重。错。
    * 选项 B (On-Demand Capacity Reservation): 容量预留只保容量不保价（还是按需价），且需要手动扩缩 Read Replica。不如计算层优化关键。
    * 选项 C (EC2 SP): EC2 Instance SP 灵活性差（锁死 Region/Family），不如 Compute SP（支持 Fargate，题目说正在开发 Fargate）。
    * **关键点：** 题目问的是整个平台的设置。选项 D 专注于计算层的最佳组合（SP + Spot）。通常数据库优化是 RI 覆盖基线，但选项 A/B 的组合都有瑕疵。D 是最纯粹的计算优化答案。
    * **再看 A:** "Standard RI for EC2... Spot for peaks... RI for DB peak". 数据库 RI 买峰值是错的。
    * **再看 D:** "Compute Savings Plan for base... Spot for peaks". 没提数据库？
    * **等等，** 题目只让选一个。
    * 让我们仔细比较 B 和 D。
    * B: Compute SP for medium load... On-Demand Capacity Reservation for peaks... DB RI for base... scale Read Replicas. 这个方案很全面，涵盖了 DB。
    * D: 只有 EKS 部分。
    * 但是，**On-Demand Capacity Reservation (ODCR)** 是要付费的（即使没跑实例也要付），而且是按需价格。对于“Infrequent spikes”，长期持有 ODCR 是亏的。Spot (D) 才是处理 Spikes 的省钱王道。
    * **Compute Savings Plans** 是最佳实践。
    * 题目中 D 选项虽然没提 DB，但在计算层（EKS）的策略是完美的：基线用 SP，峰值用 Spot。这通常是此类题目的标准答案。
    * **锁定 D。**

**3. ✅ 正确选项解析 (选项 D)**
* **Compute Savings Plans:** 覆盖基线，灵活支持 EC2 和 Fargate。
* **Spot Instances:** 最低成本处理突发流量。

**5. 📚 核心考点:** 计算资源成本优化组合 (SP + Spot)。

---

#### 📝 [153/529] CloudFront 维护页面 (S3 Origin 切换)

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** 每周维护，应用停机。
* **需求：** 显示 **Informational Message** (维护页面)，而不是报错。
* **工具：** CloudFront, S3 (已创建桶)。
* **选择：** 3 个步骤。

**2. ⚡ 秒杀思路**
* **准备工作：**
    * 把维护页面（HTML/图片）传到 S3。 $\rightarrow$ **选中 A**。
    * 把 S3 加为 CloudFront 的第二个 **Origin** (源站)。 $\rightarrow$ **选中 C**。
* **切换流量：**
    * 维护时，如何让流量去 S3？
    * 修改 CloudFront 的 **Default Cache Behavior**，将其 **Origin** 指向 S3。
    * 维护完，改回来指向 Elastic Beanstalk。
    * $\rightarrow$ **选中 D**。
* **排除法：**
    * 选项 B (New Distribution): 搞个新分发？那是不同的域名，用户访问不了。
    * 选项 E (Path Pattern): 维护时通常是拦截所有流量（`/*` 或 Default），而不是某个路径。且 E 的描述太繁琐。
    * 选项 F (EB serve from S3): EB 都停机维护了，怎么服务？
* **锁定 A, C, D。**

**3. ✅ 正确选项解析 (选项 A, C, D)**
* **S3 as Origin:** 存储维护页面。
* **Behavior Switch:** 通过修改 CloudFront 行为动态切换源站，无需改 DNS，生效快。

**5. 📚 核心考点:** CloudFront 源站切换实现维护模式。

---

#### 📝 [154/529] Lambda 版本发布与别名 (Alias)

**1. 🕵️‍♂️ 题眼与约束分析**
* **现状：** 更新 Lambda 环境变量 $\rightarrow$ 发布新版本 $\rightarrow$ **Update Client App to use new ARN**。
* **痛点：** 每次都要改客户端 App（因为版本号变了 ARN 变了），导致中断。
* **需求：** Simplify process, **Minimize disruption** (最小化中断), **Minimize overhead**。

**2. ⚡ 秒杀思路**
* **解耦版本号：** 客户端不应该依赖具体的版本号（如 `:1`, `:2`），而应该依赖一个**不变的指针**。
* **Lambda Alias (别名):** 创建一个别名（如 `PROD`），指向当前稳定版本。客户端只调用 `...function:PROD`。
* **更新流程：** 发布新版本 V2 $\rightarrow$ 测试 $\rightarrow$ 将 `PROD` 别名指向 V2。客户端毫无感知，无需更新。
* **选项对比：**
    * 选项 A (Modify Published Version): 已发布的版本是**不可变**的（Immutable），不能改环境变量。
    * 选项 B (DynamoDB): 引入 DB 存配置，增加了延迟和成本，且没解决 ARN 变化的问题（除非只用 $LATEST，但生产环境不推荐用 $LATEST）。
    * 选项 C (Hardcode): 硬编码参数？那每次改参数都要改代码重新部署，更麻烦。
    * **选项 D:** 使用 **Function Alias**。这是解决此问题的标准答案。
    * **锁定 D。**

**3. ✅ 正确选项解析 (选项 D)**
* **Lambda Alias:** 指向特定版本的指针，实现客户端与具体版本的解耦。

**5. 📚 核心考点:** Lambda 别名 (Alias) 的作用与发布流程。

---

#### 📝 [155/529] 全球应用多区域入口 (Global Accelerator)

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** 跨两个大陆的多区域部署 (ALB + DynamoDB Global Tables)。
* **需求：** Serve via **Top-level Domain** (顶级域名)。
* **痛点：** 两个区域有两个 ALB IP/域名。如何统一入口？
* **约束：** **Minimize effort**。

**2. ⚡ 秒杀思路**
* **方案 A (Route 53 Geolocation):** 可行。CNAME 指向 ALB DNS 吗？顶级域名 (Zone Apex, e.g., `example.com`) **不能**设为 CNAME。必须用 Alias 记录。选项 A 说 CNAME，这在 DNS 标准里是违规的（虽然 R53 Alias 支持，但术语要严谨）。
* **方案 B (NLB + Static IP):** 在每个区域 ALB 前加 NLB 获取静态 IP，然后 R53 指向 IP。这可以由 A 记录支持。但运维复杂（多层 LB）。
* **方案 C (Global Accelerator):**
    * GA 提供 **两个静态 Anycast IP**。
    * GA 后端可以挂**多个区域的 ALB**。
    * GA 自带流量路由（性能路由或加权）。
    * 在公共 DNS（哪怕不是 Route 53，题目说 "Company manages public DNS internally"）中，将顶级域名解析到这两个静态 IP（A 记录）。这是完全符合 DNS 标准的，且无需迁移 DNS 托管商。
    * **关键点：** 题目说 "Company manages public DNS internally"。如果用 Route 53 Alias (A)，前提是你得把 DNS 迁到 Route 53。如果公司不想迁 DNS，那么 **Global Accelerator 的静态 IP** 是唯一能让第三方 DNS 轻松解析顶级域名的方案（A 记录）。
    * **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **Global Accelerator:** 提供全球静态 IP，屏蔽后端多区域 ALB 的复杂性，且兼容所有 DNS 服务商的顶级域名解析（A 记录）。

**5. 📚 核心考点:** 多区域流量入口选型 (Global Accelerator vs Route 53)。

---

#### 📝 [156/529] Lambda 依赖包管理 (Container Image)

**1. 🕵️‍♂️ 题眼与约束分析**
* **现状：** Lambda + API Gateway。
* **痛点：** Multiple **shared libraries** and **custom classes** (大量依赖库)。
* **目标：** Simplify deployment, optimize code reuse。

**2. ⚡ 秒杀思路**
* **方案比较：**
    * **Lambda Layers (A/B):** 确实是为了代码重用。但如果依赖库很大（超过 250MB 解压限制），Layers 就用不了了。且管理多个 Layer 版本也挺繁琐。
    * **Lambda Container Image (D):** 2020 年推出的重磅功能。支持将 Lambda 打包成 Docker 镜像（最大 10GB）。
        * 优势：利用 Docker 生态（Dockerfile 管理依赖最方便），突破 250MB 限制，本地开发测试一致性好。
        * 题目提到 "Shared libraries and custom classes"，通常意味着打包体积可能较大或依赖复杂。Docker 是最标准化的打包方式。
    * **Fargate (C):** 题目没说 Lambda 跑不动，只是要简化部署。Fargate 运维比 Lambda 重。
* **决战 A/B vs D:**
    * 题目问 "Simplify deployment"。对于开发者来说，`docker build & push` 往往比 `zip & upload layer & update function` 更符合现代 CI/CD 习惯。
    * 特别是当依赖库涉及 OS 本地库时，容器镜像比 Zip 包更不容易出错。
    * 选项 D 直接把所有东西打包成镜像推 ECR，Lambda 直接用镜像。这是处理复杂依赖的新标准。
    * **锁定 D。**

**3. ✅ 正确选项解析 (选项 D)**
* **Lambda Container Image:** 支持大体积依赖 (10GB)，利用 Docker 工具链简化复杂依赖管理。

**5. 📚 核心考点:** Lambda 部署包类型选型 (Zip vs Container Image)。

---

#### 📝 [157/529] 边缘 ML 推理 (Greengrass)

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** 工厂装配线 IP 摄像机，ML 缺陷检测。
* **关键约束：** **Local feedback even if internet connectivity is lost** (断网也要能工作 -> 必须边缘计算)。
* **现有资源：** On-premise Linux Server。

**2. ⚡ 秒杀思路**
* **边缘计算选型：**
    * **AWS IoT Greengrass:** 专门用于在边缘设备（Linux 服务器）上运行 Lambda、Docker 和 **ML Inference (机器学习推理)**。它支持离线运行。
    * **Snowball (C):** 它是数据迁移或边缘计算设备，但题目说已经有一台 Linux Server 了，没必要再买个硬件。
    * **Kinesis Video Streams (A):** 需要传到 AWS 云端处理，断网就挂了。排除。
    * **Monitron (D):** 是震动/温度传感器，不是视觉检测。排除。
* **架构：** 在本地 Linux Server 装 Greengrass $\rightarrow$ 部署 SageMaker 训练好的模型到 Greengrass $\rightarrow$ 本地推理 $\rightarrow$ 本地 API 反馈。
* **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **IoT Greengrass:** 将 AWS 能力（ML, Lambda）延伸到边缘，支持离线运行。

**5. 📚 核心考点:** 边缘机器学习推理架构 (Greengrass)。

---

#### 📝 [158/529] 迁移商业案例分析 (Migration Evaluator)

**1. 🕵️‍♂️ 题眼与约束分析**
* **任务：** Create **Business Case** for migration (创建商业案例/TCO分析)。
* **数据源：** CMDB export (CMDB 导出文件)。
* **目标：** **Most cost-effective**。

**2. ⚡ 秒杀思路**
* **工具选型：**
    * **Migration Evaluator (前身 TSO Logic) (B):** 专门用于生成迁移商业案例（TCO 分析）。它支持**导入 CMDB 数据**（Import template）。这是做 Business Case 的对口工具。
    * **Application Discovery Service (D):** 主要用于技术发现（依赖关系、性能），通常需要安装 Agent。虽然也能导入数据，但它的输出更多是给 Migration Hub 做追踪，而不是直接生成“商业案例”。
    * **Well-Architected Tool (A):** 架构审查工具，无关迁移成本分析。
    * **Price List API (C):** 自己写代码查价格？太累。
* **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **Migration Evaluator:** 以前叫 TSO Logic，专为构建迁移商业论证 (Business Case) 设计，支持 CMDB 导入。

**5. 📚 核心考点:** 迁移评估阶段的工具选型 (Business Case = Migration Evaluator)。

---

#### 📝 [159/529] 自动化 DDoS 防御 (WAF + Shield)

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** ALB + WAF。
* **攻击：** Application layer attacks (应用层攻击)，来源 IP 随机变动。
* **目标：** Mitigate attacks (缓解攻击) + **Minimize operational overhead**。

**2. ⚡ 秒杀思路**
* **防御手段：**
    * 针对应用层攻击（HTTP Flood），**AWS WAF** 是第一道防线。
    * 针对 IP 封禁，手动分析日志太慢。
    * **AWS Shield Advanced (B):** 提供 DDoS 响应团队 (DRT) 和高级自动缓解。但它很贵 ($3000/月)。题目问 "Minimize operational overhead"，Shield Advanced 确实省事，但通常作为“高价值”选项。
    * **WAF Rate-based Rules (未列出):** 这是最简单的。
    * **选项 A:** CloudWatch Alarm 监控访问量 $\rightarrow$ 触发 Lambda (Action? A 说是把 IP 加黑名单)。这需要写代码。
    * **选项 B:** 部署 Shield Advanced。它能自动检测并缓解 DDoS，而且如果你用了 WAF，Shield Advanced 可以自动写 WAF 规则来拦截攻击。这是托管服务，运维最少。
    * **选项 C/D:** 都要自己分析日志或写 Lambda。
    * **但是，** Shield Advanced 主要是防 L3/L4 DDoS，虽然也有应用层防护，但 WAF 才是 L7 的主力。
    * **让我们重读 A:** "Configure alarm action to add IP to web ACL deny list". CloudWatch Alarm Action 原生不支持“修改 WAF 规则”。这需要 Lambda。A 的描述技术上不完整。
    * **选项 C:** "Configure alarm to invoke Lambda... add deny rule to subnet route table (NACL)". 修改 NACL？NACL 有条目限制（20/40条），对于大量攻击 IP，NACL 很快就爆了。不推荐。
    * **选项 B:** Shield Advanced 是 AWS 推荐的 DDoS 托管方案。对于不想自己写自动化脚本的公司，Shield Advanced 提供了自动的应用层 DDoS 缓解（自动向 WAF 添加规则）。虽然贵，但“Operational Overhead”确实最低。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **Shield Advanced:** 托管 DDoS 保护，自动集成 WAF 进行应用层清洗，零运维。

**5. 📚 核心考点:** DDoS 自动化防御选型 (Shield Advanced)。

---

#### 📝 [160/529] 关键应用多区域容灾 (Aurora Global + Global Tables)

**1. 🕵️‍♂️ 题眼与约束分析**
* **组件：** Aurora MySQL + DynamoDB。
* **政策：** 必须 **Deploy in two regions** (双区域部署)。
* **RTO/RPO:** **No more than a few minutes** (几分钟内)。
* **选择：** 2 个步骤。

**2. ⚡ 秒杀思路**
* **Aurora 容灾：**
    * 要实现分钟级 RTO/RPO 跨区域，必须用 **Aurora Global Database**。
    * 配置方法是：**Add another Region** to the Aurora Cluster。
    * $\rightarrow$ **选中 A**。
    * B (Add region to each table) 是 DynamoDB 的术语，Aurora 是基于集群的。
* **DynamoDB 容灾：**
    * 要实现多区域多活/热备，必须用 **Global Tables**。
    * 配置方法是：Convert existing table to Global Table (add region)。
    * $\rightarrow$ **选中 D**。
* **排除法：**
    * C (Backup): 备份恢复 RTO 肯定超过几分钟。
    * E (Route 53 ARC): 它是控制流量切换的，不是做数据复制的。题目问的是“Make data tier compliant” (让数据层合规)。
* **锁定 A, D。**

**3. ✅ 正确选项解析 (选项 A, D)**
* **Aurora Global Database:** 跨区域物理复制，低延迟。
* **DynamoDB Global Tables:** 跨区域逻辑复制，多活。

**5. 📚 核心考点:** 数据库层的跨区域合规配置。

---
**小结：**
这组题目的 **Greengrass**、**Global Accelerator**、**Lambda 别名** 都是非常实战的考点。

**恭喜你，160 题达成！**