这 10 道题目涵盖了 **Web 应用高可用 (Global Accelerator)**、**PGP 解密自动化 (Transfer Family + Secrets Manager)**、**内存数据库高可用 (MemoryDB)**、**成本分摊标签与可视化 (CUR + QuickSight)**、**IoT 数据高并发处理 (Kinesis)**、**WorkSpaces 跨区域 DR**、**迁移评估 (Migration Evaluator)**、**API 安全防护 (WAF + Inspector)**、**Lambda 数据库连接优化 (RDS Proxy + Provisioned Concurrency)**、**PrivateLink 私有 DNS**。

特别是 **Q483 (MemoryDB)** 和 **Q489 (RDS Proxy + Provisioned Concurrency)** 是 SAP 考试中关于高性能与 Serverless 的重点。

让我们开启 **逐题秒杀模式**！

---

#### 📝 [481/529] Web 应用全球高可用与读写优化 (Global Accelerator + Multi-AZ)

**1. 🕵️‍♂️ 题眼与约束分析**
* **现状：** Single EC2, RDS MySQL (Intensive Read)。
* **痛点：** Unresponsive under high load, Manual restart (不可靠)。
* **用户：** Global customers (全球)。
* **目标：** Improve reliability, **Minimal development effort**。

**2. ⚡ 秒杀思路**
* **接入层：**
    * 全球用户访问，为了提高可靠性和性能（特别是如果单个区域不可用，需要切流）。
    * **Global Accelerator (C):** 提供静态 Anycast IP，优化全球路由，支持跨区域故障转移（如果未来扩展到多区域）。对于单区域，它也能提供入口的高可用。
    * CloudFront (A): 主要做缓存。如果应用是动态的且写操作多，CloudFront 不如 GA 在路由层面的优化直接。但题目主要是“可靠性”。
    * ELB + ASG (B): 这是区域内高可用的基础。
* **数据库层：**
    * **Multi-AZ (A/C):** 解决单点故障，提高可靠性。
    * **Standby DB for Reads?** RDS Multi-AZ 的 Standby 节点通常**不可读**（它是同步复制用于 Failover 的）。只有 **Aurora** 的副本或是 **RDS Read Replica** 才是可读的。
    * 题目选项 A 和 C 都说 "Use standby DB instance for intensive read operations"。这是一个**技术错误描述**（对于标准 RDS Multi-AZ）。除非是指 Multi-AZ Cluster（两个可读备库），但通常 Standby 不读。
    * **选项 B:** Replace with **Aurora**. Use **Aurora Replicas** for read。Aurora Replica 既是备库又是读库。这完美解决了“Intensive Read”和“Reliability”。
    * **选项 D:** Lambda + Read Replica。Lambda 需要改代码（Migrate app）。
* **综合分析：**
    * A/C 的“读 Standby”在标准 RDS 中是不行的。
    * B 提到了 **ASG + ELB**（解决应用层单点和重启问题）和 **Aurora**（解决数据库读写分离和高可用）。这是最标准的架构升级路径。
    * 且从 RDS MySQL 迁移到 Aurora MySQL 是兼容的，开发工作量很小（Snapshop restore）。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **ASG + ELB:** 消除 EC2 单点故障，自动重启不健康实例。
* **Aurora Replicas:** 提供读扩展能力和故障转移能力。

**5. 📚 核心考点:** 传统 Web 应用向高可用架构（Aurora + ASG）的演进。

---

#### 📝 [482/529] SFTP PGP 解密自动化 (Transfer Family + Secrets Manager)

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** Transfer Family SFTP 接收 PGP 加密文件。
* **需求：** **Automatically decrypt** (自动解密)。
* **工具：** Transfer Family Managed Workflow。
* **密钥管理：** Secrets Manager。

**2. ⚡ 秒杀思路**
* **解密原理：** PGP 解密需要 **私钥 (Private Key)**。公钥是给发送方加密用的。
    * $\rightarrow$ **排除 A, D** (存储公钥)。
* **Workflow 步骤：**
    * Transfer Family Workflow 支持预定义的步骤类型，如 Copy, Tag, **Decrypt**。
    * Decrypt 步骤需要指定 PGP 私钥（从 Secrets Manager 获取）。
    * 这个步骤应该是 **Nominal step** (正常步骤)，而不是 Exception handler (异常处理步骤，只有失败才跑)。
    * $\rightarrow$ **选中 C**。
* **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **Private Key:** 解密必须用私钥。
* **Nominal Step:** 正常处理流程。

**5. 📚 核心考点:** AWS Transfer Family 托管工作流的 PGP 解密配置。

---

#### 📝 [483/529] 游戏排行榜微秒级读写 (MemoryDB)

**1. 🕵️‍♂️ 题眼与约束分析**
* **应用：** Gaming Leaderboard (排行榜)。
* **性能：** **Microsecond reads**, **Single-digit millisecond writes** (极高性能)。
* **数据：** Single-digit TB。
* **可用性：** Accept writes within < 1 min after primary failure。
* **持久性：** Data persisted for analytics。
* **目标：** **Minimal operational overhead**。

**2. ⚡ 秒杀思路**
* **微秒级读取：** 只有 **内存数据库** 能做到。
    * RDS (A) 是毫秒级。排除。
    * Redis (B/C) 是微秒级。
* **持久性与管理：**
    * **Amazon MemoryDB for Redis (B):** 它是兼容 Redis 的、持久化的内存数据库。它使用分布式事务日志（Multi-AZ），保证数据不丢失（Durability），且支持快照。它是**全托管**的。
    * EC2 Redis (C): 自建 Redis？运维噩梦（Patching, Backup, HA, Sharding）。违反 "Minimal operational overhead"。
* **选项 B:** MemoryDB Multi-AZ Cluster。满足性能、持久性、低运维。
* **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **MemoryDB:** 兼具 Redis 的微秒级性能和数据库的持久性，适合排行榜等高性能场景。

**5. 📚 核心考点:** MemoryDB for Redis 的适用场景（高性能+持久化）。

---

#### 📝 [484/529] 多账户成本分摊与可视化 (CUR + QuickSight)

**1. 🕵️‍♂️ 题眼与约束分析**
* **环境：** Organizations, Multiple Accounts。
* **标签：** `BusinessUnit` 标签已打好。
* **需求：**
    1.  Allocate costs to Business Units (分摊成本)。
    2.  **Visualize** costs (可视化)。
* **选择：** 2 个步骤？不对，题目是单选，找一个完整的解决方案。

**2. ⚡ 秒杀思路**
* **成本分配标签：**
    * 标签虽然打在资源上，但必须在 **Payer Account (Management Account)** 的计费控制台中**激活**（Activate）为“成本分配标签”，才能在账单中看到。
    * $\rightarrow$ **排除 B, D** (在成员账户创建? 标签是在成员账户打的，但激活是在管理账户)。
    * **Wait,** 选项说 "Create a cost allocation tag named BusinessUnit in Management Account"。这是指“激活”这个标签键。这是对的。
* **CUR 与可视化：**
    * **AWS Cost and Usage Report (CUR):** 是最详细的成本数据源。应在管理账户配置，将所有成员账户的数据汇总到一个 S3 桶。
    * **Athena + QuickSight:** 是分析和可视化 CUR 数据的标准组合（CUDOS Dashboard 架构）。
    * $\rightarrow$ **选中 A**。
* **排除其他：**
    * B (CloudWatch Dashboard): CloudWatch 不适合做复杂的成本多维分析和可视化（虽然有 Billing Metrics，但粒度不如 CUR + QuickSight）。
    * C (Each member account S3): 分散存储 CUR？不好聚合分析。
    * D (Each member account tag): 标签激活是全局（或至少在 Payer 层面）生效的。
* **锁定 A。**

**3. ✅ 正确选项解析 (选项 A)**
* **Activate Tag:** 在管理账户激活成本分配标签。
* **CUR + Athena + QuickSight:** 成本分析与可视化的黄金搭档。

**5. 📚 核心考点:** 多账户环境下的成本标签激活与可视化架构。

---

#### 📝 [485/529] IoT 高并发写入优化 (Kinesis + Batch)

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** 智能电表数据 -> API Gateway -> Lambda -> DynamoDB。
* **问题：**
    * Lambda duration increases (处理慢)。
    * **ProvisionedThroughputExceededException** (DynamoDB 写不动)。
    * **TooManyRequestsException** (Lambda 并发超限)。
* **原因：** 高并发小包写入，后端（DB 和 Lambda）抗不住。
* **目标：** Solve issues。选择 2 个。

**2. ⚡ 秒杀思路**
* **数据库层 (A):**
    * DynamoDB 报吞吐超限，最直接就是 **增加 WCU** (或开 Auto Scaling)。
    * $\rightarrow$ **选中 A**。
* **架构优化 (D):**
    * Lambda 遇到并发限制，且处理时间变长。
    * 将单条处理改为 **批处理 (Batching)**。
    * 引入 **Kinesis Data Streams** (D)。API Gateway 将数据推入 Kinesis（流式缓冲）。Lambda 从 Kinesis 批量读取（Batch Size > 1），一次处理多条，一次写入 DynamoDB（BatchWriteItem）。
    * 这极大减少了 Lambda 调用次数和 DynamoDB API 调用次数（降低开销，提高吞吐）。
    * $\rightarrow$ **选中 D**。
* **其他选项：**
    * B (Increase Memory): 可以减少 Lambda 耗时，但不解决 DynamoDB 写入瓶颈和 Lambda 并发限制（只是跑得快一点，并发还是高）。
    * C (Increase Payload): 没法控制电表发包。
    * E (SQS FIFO): FIFO 吞吐量有限（每秒 300/3000），不如 Kinesis 高吞吐。且 Kinesis 天然支持保序和批处理。
* **锁定 A, D。**

**3. ✅ 正确选项解析 (选项 A, D)**
* **Kinesis Batching:** 削峰填谷，减少下游调用频率。
* **Increase WCU:** 解决数据库吞吐瓶颈。

**5. 📚 核心考点:** 高并发 IoT 写入场景的架构优化（流式批处理）。

---

#### 📝 [486/529] WorkSpaces 跨区域高可用 (Connection Alias)

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** WorkSpaces in Primary & Failover Regions。
* **需求：** **Highly Available** (高可用)。
* **工具：** Connection Alias, Route 53。

**2. ⚡ 秒杀思路**
* **Connection Alias (连接别名):**
    * WorkSpaces 允许通过一个**统一的注册码 (Registration Code)** 访问不同区域的桌面。这通过 **Cross-Region Connection Redirection** 实现。
    * 需要在 Route 53 中配置 **Failover Routing Policy**，指向各个区域的 WorkSpaces 目录（通过 Connection Alias 关联）。
    * 客户端使用同一个 FQDN（别名），Route 53 根据健康状况返回对应区域的记录。
* **配置细节：**
    * 必须在**两个区域**都创建 Connection Alias。
    * Route 53 Failover Policy：Primary -> Primary Region, Secondary -> Failover Region。
    * **Evaluate Target Health = Yes** (如果是别名记录)。
    * $\rightarrow$ **选中 A**。
    * (D 选项说 "Create alias in Primary... associate with Failover directory"? 别名需要在各自区域创建并关联各自目录)。
* **锁定 A。**

**3. ✅ 正确选项解析 (选项 A)**
* **Cross-Region Redirection:** WorkSpaces 的多区域接入技术。
* **Route 53 Failover:** 实现自动切换。

**5. 📚 核心考点:** WorkSpaces 跨区域灾备的客户端接入配置。

---

#### 📝 [487/529] 本地迁移评估与依赖分析 (Migration Evaluator + Agentless)

**1. 🕵️‍♂️ 题眼与约束分析**
* **任务：** Initial assessment (初步评估), Visualize dependencies (依赖可视化), Business case (评估报告)。
* **权限：** Can install collector software (可安装收集器)。
* **目标：** **Minimal operational overhead**。

**2. ⚡ 秒杀思路**
* **工具选型：**
    * **Migration Evaluator (D):** 以前叫 TSO Logic。专门用于生成 **Business Case** (TCO/评估报告)。它有一个 **Collector** 可以部署在本地（无代理，通过 OS/Hypervisor API 扫描）。
    * **Application Discovery Service (A/C):** 也可以做发现，但 Evaluator 在生成“评估报告”（Business Case）方面更专业、更自动化（Quick Insights）。ADS 更多是给 Migration Hub 提供数据做追踪。
    * **Agent vs Agentless:**
        * 题目说 "Can install collector software... minimal overhead"。
        * **Agentless (D)** 部署一个收集器扫描整个网络，比在每个 VM 上装 Agent (A/B) 运维开销小得多。
        * 题目虽然说 "Can install on each VM" (A)，但这 Overhead 高。
        * **Migration Evaluator Collector (D)** 是一个部署在本地的虚拟机，自动收集并上传数据。
* **流程：**
    * Install Evaluator Collector -> Collect Data -> View in Migration Hub (Evaluator 数据也会同步) -> Download Quick Insights from Evaluator portal.
    * 选项 D 描述了这个流程。
    * **注意：** A/C 是 ADS。B 是自己手动导出导入 QuickSight？太麻烦。
    * **锁定 D。**

**3. ✅ 正确选项解析 (选项 D)**
* **Migration Evaluator:** 专门用于迁移前的商业评估和依赖分析。
* **Collector:** 集中式收集，低运维。

**5. 📚 核心考点:** 迁移评估阶段的首选工具 (Migration Evaluator)。

---

#### 📝 [488/529] API 安全防护 (WAF + Inspector)

**1. 🕵️‍♂️ 题眼与约束分析**
* **资产：** API Gateway API, Legacy API on EC2。
* **威胁：** DoS attacks, Vulnerabilities, Common exploits。
* **需求：** Better protection。

**2. ⚡ 秒杀思路**
* **Web 防护 (DoS/Exploits):**
    * **AWS WAF:** 防护 API Gateway 和 ALB（如果 EC2 前有 ALB，或者 CloudFront）。题目说 Legacy API on "single standalone EC2"。如果 EC2 暴露公网，WAF 只能挂在 CloudFront 或 ALB 上。题目没提 ALB。但为了保护 API Gateway，WAF 是必须的。对于 EC2，如果前面没 LB，WAF 无法直接保护。
    * 让我们看选项。所有选项都说 "Protect API Gateway with WAF"。
* **漏洞扫描 (Vulnerabilities):**
    * **Amazon Inspector:** 扫描 EC2 上的漏洞（CVE）。对于 Legacy API on EC2，Inspector 是绝佳选择。对于 API Gateway（Serverless），Inspector 现在也支持扫描 Lambda 代码漏洞。
    * $\rightarrow$ 选项 B/C/D 提到了 Inspector。
* **恶意访问监控:**
    * **GuardDuty:** 监控 AWS 账号层面的恶意活动（如异常 API 调用、EC2 通信）。
* **选项细分：**
    * A: WAF protect **BOTH**? WAF 不能直接挂 EC2。除非有 ALB/CF。如果假设有，A 可以。
    * B: WAF protect API Gateway. Inspector analyze **BOTH** (EC2 and Lambda code). GuardDuty block? GuardDuty 主要是检测 (Monitor)，自动阻断需要配合 Lambda/EventBridge。但选项说 "Configure GD to block"。这通常不准确。
    * C: WAF protect API Gateway. Inspector analyze **Legacy API** (EC2). GuardDuty **monitor**。
        * 这个描述最准确。GuardDuty 是监测服务。Inspector 扫 EC2 是传统强项。WAF 护 API Gateway。
    * D: Inspector protect **Legacy API**. GuardDuty block?
    * **B vs C:** Inspector 能扫 Lambda 吗？能（Inspector v2）。所以 B 说 Analyze both 是对的。但 GuardDuty "Block" 是错的。C 说 GuardDuty "Monitor" 是对的。
    * **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **WAF:** 保护 Web 层。
* **Inspector:** 扫描主机漏洞。
* **GuardDuty:** 监控恶意行为。

**5. 📚 核心考点:** AWS 安全三剑客（WAF, Inspector, GuardDuty）的职责分工。

---

#### 📝 [489/529] Lambda 数据库连接与冷启动优化 (RDS Proxy + Provisioned Concurrency)

*(注：这题是 Q413 的加强版)*

**1. 🕵️‍♂️ 题眼与约束分析**
* **故障：** Sudden traffic spike -> **Poor API performance** (Latency) & **DB connection failures**。
* **目标：** Minimize latency, Support spikes, Least changes。

**2. ⚡ 秒杀思路**
* **解决数据库连接失败：**
    * Lambda 扩容太快打爆 DB 连接。
    * **RDS Proxy (B/D):** 连接池化。必须。
* **解决延迟 (Cold Start):**
    * Java Lambda 冷启动较慢（JVM 启动）。流量突增时，新实例冷启动会导致 Latency。
    * **Provisioned Concurrency (预置并发) (B):** 预先初始化 Lambda 环境，消除冷启动，保证低延迟。
    * **Reserved Concurrency (预留并发) (A/C/D):** 只是保证有额度可用，不预热，不解决冷启动延迟。
    * $\rightarrow$ **选中 B**。
* **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **RDS Proxy:** 解决连接数瓶颈。
* **Provisioned Concurrency:** 解决冷启动延迟。

**5. 📚 核心考点:** Serverless 性能优化的两大杀手锏。

---

#### 📝 [490/529] PrivateLink 私有 DNS 解析 (Private DNS)

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** Interface Endpoint 连接 AWS 服务。
* **问题：** Service name resolves to **Public IP**, internal service cannot connect (App 只允许私有 IP 连接)。
* **原因：** 默认情况下，AWS 服务域名（如 `sqs.us-east-1.amazonaws.com`）解析到公网 IP。

**2. ⚡ 秒杀思路**
* **Private DNS:**
    * 启用 Interface Endpoint 的 **Private DNS** 选项。
    * AWS 会在 VPC 的私有 Hosted Zone 中自动创建一个记录，将服务默认域名解析到 **Endpoint 的私有 IP**。
    * 这样应用无需修改代码（继续用默认域名），就能解析到私有 IP 并走 Endpoint 连接。
* **选项对比：**
    * A (Route Table): 路由表控制流量走向，不控制 DNS 解析结果。
    * **B:** Enable **Private DNS** on VPC attributes (or Endpoint attributes)。这是正解。
    * C (SG): SG 控制通不通，不控制解析 IP。
    * D (Route 53 Private Zone): 手动建？Private DNS 选项会自动建托管的 PHZ，不用手动。
* **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **Private DNS:** 让 AWS 服务默认域名在 VPC 内解析为 Endpoint 私有 IP。

**5. 📚 核心考点:** Interface Endpoint 的 Private DNS 机制。

---
**小结：**
这组题目的 **RDS Proxy**、**MemoryDB**、**Global Accelerator** 都是高性能架构的基石。

**恭喜你，490 题！**