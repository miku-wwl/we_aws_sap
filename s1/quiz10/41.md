这 10 道题非常精彩，涵盖了 **DynamoDB 成本优化**、**大规模迁移发现**、**OpenSearch 存储分层**、**网络安全治理 (SCP)**、**Lambda 网络与连接池** 等 SAP 核心考点。

特别是 **Q48 (Lambda + Aurora 连接耗尽)** 和 **Q43 (OpenSearch 成本)** 是最近非常高频的考题。

让我们开启 **逐题秒杀模式**！

---

#### 📝 [41/529] DynamoDB 峰值成本优化

**1. 🕵️‍♂️ 题眼与约束分析**
* **负载特征：**
    * **Peak (峰值):** 每周一次，持续 4 小时，2倍于平均值。
    * **Average (平均):** 一周其余时间都很平稳。
    * **操作:** Write-heavy (写多读少)。
* **目标：** **Minimize cost** (最小化成本)。
* **核心机制：** DynamoDB Capacity Modes (Provisioned vs On-Demand)。

**2. ⚡ 秒杀思路**
* **模式对比：**
    * **On-Demand:** 适合不可预测的流量，或者流量极其稀疏。单价贵。
    * **Provisioned + Auto Scaling:** 适合有规律的、渐变的流量。单价便宜。
    * **Reserved Capacity:** 只能购买预配置容量（Provisioned），不能买 On-Demand。适合“基线负载”。
* **秒杀动作：**
    * 流量有明显的“基线”（平时）和“规律的峰值”（每周4小时）。
    * **最佳组合：** 对“基线负载”购买 **Reserved Capacity** (打折最狠) + 对“峰值”使用 **Auto Scaling** (自动把容量拉上去，峰值过后再降下来)。
    * 选项 B (On-Demand) 对于长期运行的平稳负载来说，比 Provisioned 贵约 5-7 倍。
    * 选项 C/D (DAX): DAX 是读缓存。题目明确说是 **Write-heavy**，DAX 对写操作毫无帮助，纯属浪费钱。
    * **锁定 A。**

**3. ✅ 正确选项解析 (选项 A)**
* **Reserved Capacity:** 覆盖底座流量，省钱。
* **Auto Scaling:** 覆盖每周那 4 小时的峰值，用完即走。

**5. 📚 核心考点:** DynamoDB 计费模式选型 (Reserved + AS 组合拳)。

---

#### 📝 [42/529] 媒体处理迁移 (长耗时任务)

**1. 🕵️‍♂️ 题眼与约束分析**
* **任务：** 媒体文件处理。
* **耗时：** **Up to 1 hour** (长达1小时)。
* **负载：** 工作时间激增 (Spike)，下班后下降。
* **目标：** **Most cost-effective** (最具成本效益)。

**2. ⚡ 秒杀思路**
* **计算层选型：**
    * 看到 "1 hour processing" $\rightarrow$ **绝对不能选 Lambda** (Lambda 上限 15 分钟)。排除 A 和 C。
    * 剩下 B 和 D。都是用 EC2。
* **队列选型：**
    * **SQS** vs **Amazon MQ**。
    * SQS 是 AWS 原生、Serverless、按量付费（极便宜）。Amazon MQ 也是托管的，但需要为 Broker 实例付费（按小时计费），且扩展性不如 SQS。对于“成本优先”的云原生迁移，SQS 完胜。
* **存储选型：**
    * S3 vs EFS。S3 是对象存储，最适合存媒体文件，且比 EFS 便宜。
* **扩展策略：**
    * 选项 B 说 "Create a new EC2 instance... when messages in queue" (每条消息启动一个实例)。这是反模式，启动慢且管理开销大。
    * 选项 D 使用 **Auto Scaling Group** 根据 SQS 队列深度扩展。这是标准架构。
    * **锁定 D。**

**3. ✅ 正确选项解析 (选项 D)**
* **SQS + ASG + EC2:** 经典的解耦架构。ASG 可以利用 Spot 实例进一步降低成本。S3 存储结果最便宜。

**5. 📚 核心考点:** 异步解耦架构与计算服务限制 (Lambda Timeout)。

---

#### 📝 [43/529] OpenSearch 数据分层与归档

**1. 🕵️‍♂️ 题眼与约束分析**
* **现状：** S3 $\rightarrow$ OpenSearch (10个数据节点)。
* **保留策略：** 集群内保留 1 个月用于只读分析。
* **合规需求：** 必须保留所有原始输入数据的副本 (Retain copy of all input data)。
* **痛点：** 10个节点太贵。
* **目标：** **Cost-effective**。

**2. ⚡ 秒杀思路**
* **OpenSearch 降本：**
    * 对于“只读分析”且“保留1个月”的数据，**UltraWarm** 节点是标准答案。它使用 S3 作为存储层，计算节点只做缓存，成本只有热节点的 1/10。
    * 所以架构应该是：少量 Hot 节点 (负责写入) + 大量 UltraWarm 节点 (负责那1个月的查询)。
* **原始数据归档：**
    * 输入数据在 S3 上。合规要求保留副本，但没说要频繁访问。**S3 Glacier Deep Archive** 是最便宜的归档存储。
* **秒杀动作：**
    * 选项 A: 替换所有节点为 UltraWarm。不行，UltraWarm 主要是只读的，写入性能差，通常需要 Hot 节点做前置摄取。
    * 选项 C: 引入 Cold Storage。Cold Storage 是为了把索引“冻结”（不可查询，需解冻）。题目说 "retained for analysis"（保留用于分析），意味着需要随时能查，UltraWarm 更合适。
    * 选项 D: 没提 UltraWarm，还是用普通实例，没解决成本问题。
    * **选项 B:** 减少热节点 (2个) + 添加 UltraWarm (处理容量) + 原始数据转存 Deep Archive。完美组合。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **Hot-Warm Architecture:** 2个热节点负责写入，索引变旧后迁移到 UltraWarm 供分析。
* **S3 Lifecycle:** 原始数据归档到 Deep Archive 满足合规。

**5. 📚 核心考点:** OpenSearch 存储分层 (Hot/UltraWarm/Cold) 与 S3 归档。

---

#### 📝 [44/529] 禁止 0.0.0.0/0 安全组 (SCP)

**1. 🕵️‍♂️ 题眼与约束分析**
* **目标：** NonProd OU 的账户，**Remove ability** (移除能力) 去创建源为 `0.0.0.0/0` 的安全组规则。
* **约束：** **Least operational overhead** (最小运维)。
* **核心工具：** **SCP** (预防性) vs **Config** (检测性)。

**2. ⚡ 秒杀思路**
* **预防 vs 检测：**
    * 题目要求 "Remove ability" (根本不让你做)，这是**预防性控制**。Config 规则（选项 B）和 Lambda 修复（选项 A）都是事后诸葛亮（先创建了，再报警/删除），存在短暂的风险窗口。
    * SCP 是预防性的，直接拦截 API 调用。
* **SCP 逻辑：**
    * 选项 C (Allow if not 0.0.0.0/0): 这种写法很危险。如果没有显式 Deny，只要其他策略允许了（比如 FullAWSAccess），这个 Allow 限制就没用了。
    * 选项 D (Deny if 0.0.0.0/0): **Explicit Deny** (显式拒绝) 是王道。无论你有什么权限，只要触碰了 Deny 规则（SourceIp = 0.0.0.0/0），请求直接被拒。
    * **锁定 D。**

**3. ✅ 正确选项解析 (选项 D)**
* **SCP Deny:** 在 Organization 层面直接封杀特定的 API 参数组合。

**5. 📚 核心考点:** SCP 的 Deny 策略编写与 Config 的区别。

---

#### 📝 [45/529] Webhook Serverless 迁移 (Lambda URL)

**1. 🕵️‍♂️ 题眼与约束分析**
* **源端：** Git Server $\rightarrow$ ALB $\rightarrow$ EC2。
* **目标：** **Serverless**。
* **约束：** **Least operational overhead**。
* **场景：** Webhook (通常是单个 HTTP POST 请求)。

**2. ⚡ 秒杀思路**
* **选项对比：**
    * 选项 C (App Runner + ALB): App Runner 本身就有 URL，前面再加个 ALB 是脱裤子放屁，且 App Runner 相比 Lambda 还是有点“重”（它是容器服务）。
    * 选项 D (ECS Fargate + API Gateway): 运维最重，还要管 Docker 镜像和集群定义。
    * **决战 A vs B (Lambda):**
        * **选项 B (API Gateway + Lambda):** 经典组合。功能强，但要配置 API Gateway 资源、阶段、部署。
        * **选项 A (Lambda Function URL):** 这是 AWS 2022 年推出的新功能。专为**"单函数、公网 HTTP 端点"**设计。它直接给 Lambda 分配一个 HTTPS URL，无需配置 API Gateway。对于 Webhook 这种简单场景，这是**极致的 Least Overhead**。
    * **锁定 A。**

**3. ✅ 正确选项解析 (选项 A)**
* **Lambda Function URLs:** 专用于 Webhook 接收等简单场景，省去了 API Gateway 的配置和费用。

**5. 📚 核心考点:** Lambda Function URLs 的适用场景。

---

#### 📝 [46/529] 迁移发现 (Agent vs Agentless)

**1. 🕵️‍♂️ 题眼与约束分析**
* **目标：** 收集 1000 台服务器指标。
* **关键数据：** CPU/RAM, **Running Processes** (运行进程), **Network Connections** (网络连接)。
* **后续：** Query and analyze (查询分析)。

**2. ⚡ 秒杀思路**
* **采集工具选择：**
    * **Agentless Discovery Connector (无代理):** 只能从 VMware vCenter 读数据，能拿到 VM 的基本配置（CPU/RAM/Disk），但**拿不到** 操作系统内部的“进程”和“网络连接”。
    * **Discovery Agent (有代理):** 安装在 OS 内部，能抓取进程和网络依赖。
    * 题目明确要求 "Running processes and network connections"，**必须选 Agent**。
    * $\rightarrow$ 排除 A (Agentless) 和 B (VM performance only)。
* **分析工具选择：**
    * 选项 C: 自己写脚本用 CLI 上传？这也太原始了，无法维护。
    * **选项 D:** 使用 Discovery Agent 采集 $\rightarrow$ 数据进入 Migration Hub $\rightarrow$ 导出到 S3 $\rightarrow$ 用 **Amazon Athena** 分析。这是官方推荐的数据探索链路。
    * **锁定 D。**

**3. ✅ 正确选项解析 (选项 D)**
* **Discovery Agent:** 获取深层依赖数据。
* **Athena:** Serverless 查询 S3 上的数据，完美符合“查询分析”需求。

**5. 📚 核心考点:** AWS Application Discovery Service 的两种模式区别。

---

#### 📝 [47/529] Lambda 静态公网 IP

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** Lambda 需要访问第三方服务。
* **限制：** 第三方服务有 **Allow list** (白名单)，只接受 **Single Public IPv4 Address**。
* **目标：** 让 Lambda 出去的流量带上固定的公网 IP。

**2. ⚡ 秒杀思路**
* **Lambda 网络原理：**
    * Lambda 默认在 VPC 外（有公网 IP 但动态）。
    * Lambda 在 VPC 内（默认无公网访问）。
    * 要让 VPC 内的 Lambda 访问公网且固定 IP，标准架构是：**Lambda (Private Subnet) $\rightarrow$ NAT Gateway (Public Subnet) $\rightarrow$ Internet Gateway**。
    * **NAT Gateway** 必须要绑定一个 **Elastic IP (EIP)**。这个 EIP 就是给第三方加白名单的 IP。
* **秒杀动作：**
    * 选项 B (Egress-only IGW): 仅支持 IPv6。
    * 选项 C (IGW 直接连 Lambda): Lambda ENI 是私有的，不能直接挂 IGW，也不支持直接绑定 EIP（除非通过 NAT）。
    * 选项 D (Default Route to IGW): 私有子网的路由表指向 IGW 是无效的（因为没有公网 IP 进行 NAT 转换）。
    * **选项 A:** 部署 NAT Gateway + 关联 EIP。标准答案。
    * **锁定 A。**

**3. ✅ 正确选项解析 (选项 A)**
* **NAT Gateway + EIP:** 也就是企业级出网流量的标准出口。

**5. 📚 核心考点:** VPC Lambda 的公网访问架构。

---

#### 📝 [48/529] Lambda 连接耗尽 (RDS Proxy)

**1. 🕵️‍♂️ 题眼与约束分析**
* **架构：** API Gateway + Lambda $\rightarrow$ Aurora MySQL (3 Read Replicas)。
* **故障：** High load $\rightarrow$ **Large number of database connections** (大量数据库连接)。
* **目标：** Improve performance (解决连接问题)。
* **选择：** 2 个步骤。

**2. ⚡ 秒杀思路**
* **问题根源：** Lambda 是无状态的，高并发时会启动数千个容器，每个容器都去连数据库，瞬间把 DB 连接池打爆。
* **解决方案 1 (架构层):** 引入 **RDS Proxy**。它可以复用数据库连接（Connection Pooling），让数千个 Lambda 请求共享少量的 DB 连接。
    * $\rightarrow$ **选中 B**。
* **解决方案 2 (代码层):** 优化连接建立逻辑。不要在 `handler()` 内部建立连接（每次调用都连一次），而要放在 `handler()` **外部**（全局作用域）。这样当 Lambda 容器被复用（Warm Start）时，连接也可以复用。
    * $\rightarrow$ **选中 D**。
* **排除法：**
    * A (Cluster Endpoint): 这是写节点，Lambda 读写分离应该连 Reader Endpoint。
    * C (Provisioned Concurrency): 解决的是冷启动延迟，解决不了连接数过多的问题（甚至可能因为预热更多容器而加剧连接消耗）。
    * E (Edge-optimized): 解决网络延迟，无关数据库连接。

**3. ✅ 正确选项解析 (选项 B, D)**
* **RDS Proxy:** 专门治 Lambda 连接耗尽的药。
* **Reuse Connections:** 这里的考点是 Lambda 执行上下文的复用机制。

**5. 📚 核心考点:** Serverless 与关系型数据库集成的最佳实践。

---

#### 📝 [49/529] 端到端加密 (E2E Encryption)

**1. 🕵️‍♂️ 题眼与约束分析**
* **架构：** Client $\rightarrow$ LB $\rightarrow$ EC2。
* **安全需求：** **End-to-end encryption** (端到端加密)。这意味着 LB 到 EC2 这一段也要加密（HTTPS）。

**2. ⚡ 秒杀思路**
* **ALB 机制：**
    * Client 到 ALB: 使用 HTTPS，证书在 ACM 管理。
    * ALB 到 EC2: ALB 会解密，然后重新加密（Re-encrypt）发给 EC2。
    * **关键点：** 要让 ALB 能够发 HTTPS 给 EC2，EC2 上必须也要装 SSL 证书。
    * **证书来源：** ALB 上的证书可以用 ACM。EC2 上的证书**不能**把 ACM 的公有证书导出来装上去（ACM 私钥不可导出）。EC2 上通常使用**自签名证书**或**第三方证书**。ALB 默认信任后端目标的自签名证书（需配置）。
* **秒杀动作：**
    * 选项 A: "Export SSL certificate... install on EC2"。错！ACM 证书不可导出私钥（除了 Nitro Enclaves 特例，一般不考）。
    * 选项 B: CloudFront + Target Group? CloudFront 不能直接连 EC2 目标组（需要通过 ALB），且没提 EC2 上的证书。
    * 选项 D (NLB): NLB 也可以做，但通常 Web 应用首选 ALB。且 D 选项说 "install on NLB and each EC2"，NLB 如果做 TCP 透传（Passthrough），证书只要在 EC2 上即可，不需要在 NLB 上。如果 NLB 做 TLS 卸载，则都需要。描述略显累赘。
    * **选项 C:** ALB + ACM (前端) + **Third-party/Self-signed cert on EC2** (后端)。这是实现 ALB 端到端加密的标准且唯一可行（在选项中）的路径。
    * **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **E2E Encryption:** ALB Terminate TLS (Front) -> Re-encrypt (Back)。

**5. 📚 核心考点:** ACM 证书的不可导出性与端到端加密实现。

---

#### 📝 [50/529] 零停机迁移与读写分离

**1. 🕵️‍♂️ 题眼与约束分析**
* **源端：** 本地 Node.js Apps (Collector, Aggregator) + MySQL。
* **痛点：** 聚合任务（读）运行时，加载任务（写）失败 $\rightarrow$ **锁竞争/性能问题**。
* **目标：** 解决数据加载问题（读写分离）+ 迁移到 AWS + **No interruption** (零停机/不改客户端)。
* **应用类型：** 简单的 Node.js 应用。

**2. ⚡ 秒杀思路**
* **架构优化：** 显然需要将 Aggregator（读）移到 **Read Replica** 上，Collector（写）连主库。
* **迁移工具：** **AWS DMS (Database Migration Service)** 是零停机数据库迁移的神器。
* **应用迁移：**
    * "Simple Node.js apps" $\rightarrow$ 迁移到 EC2 或容器最简单（Lift & Shift）。
    * 选项 A/C 提到了 Lambda。把一个现有的长连接或服务型 Node.js 应用重构为 Lambda 需要改代码（Refactor），风险高，不符合 "Simple migration"。
    * 选项 D (Kinesis): 重构太大。
    * **选项 B:**
        * DB: 本地 $\rightarrow$ DMS $\rightarrow$ Aurora。
        * 读写分离: Aggregator 连 Aurora Read Replica。
        * App: Collector 连 ALB + EC2 ASG (Lift & Shift)。
        * 切换: DNS 切换。
    * 这个方案最稳，改动最小，且通过 Read Replica 解决了原本的锁问题。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **DMS:** 持续复制，最小化停机。
* **Read Replica:** 解决 OLTP 和 OLAP 混合负载导致的锁竞争。
* **EC2 ASG:** 平滑迁移现有应用。

**5. 📚 核心考点:** 数据库迁移 (DMS) 与读写分离架构。

---
**小结：**
这组题涵盖了 **Serverless 网络**、**数据库连接管理**、**混合云迁移发现** 等实战痛点。

**请发送下一组题目！**