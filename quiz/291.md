这 10 道题目涵盖了 **EC2 夜间批处理成本优化 (Spot)**、**SFTP 迁移 (Transfer Family)**、**VPC 扩展 (Secondary CIDR)**、**CloudFormation 强制标签 (Tag Policy + SCP)**、**EC2 规格调整 (Compute Optimizer)**、**全栈灾备 (Aurora Global + DynamoDB Global)**、**CloudFront 缓存命中率优化 (Query String)**、**Aurora 跨区域备份成本 (Global vs Backup)**、**单体应用现代化 (SSM + ASG + Aurora)**、**迁移分组发现 (Migration Hub Network Diagram)**。

特别是 **Q297 (CloudFront Query String Normalization)** 和 **Q300 (Migration Hub Network Diagram)** 是 SAP 考试中的细节题。

让我们开启 **逐题秒杀模式**！

---

#### 📝 [291/529] EC2 夜间批处理成本优化 (Spot)

*(注：这题与 Q291 重复，再次解析以加深印象)*

**1. 🕵️‍♂️ 题眼与约束分析**
* **任务：** Nightly processing (夜间处理), 4 hours。
* **特性：** **Not business critical** (非关键), can be reprocessed (可重试)。
* **现状：** RI 即将过期，On-Demand 脚本处理。
* **目标：** **Most cost-effective**。

**2. ⚡ 秒杀思路**
* **摄取层：** 持续流数据。
    * **Firehose (A/B/D):** 直接存 S3，Serverless，按量付费。比维护 EC2 + EBS 便宜且省运维。
    * **EC2 RI (C):** 即使有 RI，还需要维护 OS、存储、修补。Firehose 更优。
* **处理层：** 4小时批处理，非关键，可重试。
    * **Spot Instances:** 完美适配。价格比 On-Demand 便宜 90%。
    * **AWS Batch:** 托管批处理服务，支持 Spot。
    * **Lambda (D):** 4小时超时（Lambda max 15min）。排除。
    * **EC2 On-Demand (A):** 最贵。
* **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **Firehose to S3:** 低成本摄取。
* **Batch with Spot:** 极低成本计算。

**5. 📚 核心考点:** 容错批处理任务的成本优化组合 (Spot)。

---

#### 📝 [292/529] SFTP 迁移与高可用 (Transfer Family + EFS)

**1. 🕵️‍♂️ 题眼与约束分析**
* **源端：** SFTP on Linux VM, NFS share downstream。
* **目标：** Migrate to AWS, **High Availability**, **Static Public IPs** (vendor allow list)。
* **连接：** Direct Connect (DX) 已有，但题目要求 Public IPs for external vendors? 题目说 "provide a set of static public IP addresses to external vendors"。通常这意味着 SFTP 是面向互联网的。
* **下游：** 应用挂载 NFS。

**2. ⚡ 秒杀思路**
* **SFTP 服务：** **AWS Transfer Family**。
* **存储后端：** 既然下游应用需要挂载 NFS，那么 Transfer Family 应该使用 **EFS** 作为后端（Transfer Family 支持 S3 和 EFS）。这样下游应用可以直接挂载同一个 EFS，无需改代码。
* **静态 IP：** Transfer Family 可以关联 **Elastic IP (EIP)**。这需要配置为 **VPC Endpoint (Internet Facing)** 类型。
* **选项对比：**
    * **选项 A:** Transfer Family + Internet-facing VPC Endpoint + EIPs + EFS。这是标准答案。
    * 选项 B: "Publicly accessible endpoint" 是托管 IP，不支持绑定自己的 EIP。
    * 选项 C (MGN to EC2): 自建 SFTP HA 复杂（需要 EFS + 多 EC2 + NLB），运维重。
    * 选项 D (MGN to Transfer Family?): MGN 是迁服务器的，不能迁到 Transfer Family（这是托管服务）。且 FSx for Lustre 是 HPC 用的，不适合做通用 NFS 共享。
* **锁定 A。**

**3. ✅ 正确选项解析 (选项 A)**
* **Transfer Family (EFS):** 兼容下游 NFS 应用。
* **VPC Endpoint + EIP:** 提供静态公网 IP。

**5. 📚 核心考点:** SFTP 迁移中存储后端与 IP 类型的选择。

---

#### 📝 [293/529] VPC 扩展到新可用区 (Secondary CIDR)

**1. 🕵️‍♂️ 题眼与约束分析**
* **现状：** 2 AZs, VPC CIDR `10.0.0.0/23` (512 IPs)。
    * Subnet 1: `10.0.0.0/24` (256 IPs)。
    * Subnet 2: `10.0.1.0/24` (256 IPs)。
* **问题：** VPC 空间已用完（/23 分成了两个 /24）。
* **需求：** Adopt **new 3rd AZ**。
* **约束：** **Without adding extra IPv4 address space** (不添加额外 CIDR，即不加 Secondary CIDR??) **Wait**, 题目说 "without adding extra IPv4 address space" 通常指不想申请新的大段 CIDR 或者不想扩 VPC 范围（比如不想引入 `10.1.0.0/16`）。但是现有的 /23 已经分完了，如果不加新 CIDR，只能**重新划分**现有 CIDR。
* **但是：** 题目也说 "without causing a service outage" (无中断)。
    * 如果重新划分（删除子网重建），必须先清空子网，这会中断服务。
    * 选项 A/B/D 都涉及 "Delete and recreate subnet"，这绝对会中断。
* **矛盾点：** "Without adding extra IPv4 address space" 和 "Without service outage" 在现有 IP 耗尽的情况下是互斥的。除非……
    * 难道是添加 **Secondary CIDR** 到 VPC？
    * 让我们再读选项。
    * **选项 A/B/D:** 都是破坏性的（删除子网）。
    * **选项 C:** "Create a NEW VPC with same CIDR... update ASG"。
        * 新 VPC 用同样的 CIDR？那怎么跟本地环境连？题目说 "VPC is connected to on-premises... connection must not be interrupted"。如果 IP 重叠，路由会乱，且迁移到新 VPC 也是大工程。
    * **是不是我对“Extra IPv4 space”理解有误？**
    * 或者题目其实是想考 **Resize Subnet**？AWS 不支持 Resize Subnet。
    * 让我们再看一遍选项 A/B/D 的逻辑。
    * 选项 A: Update ASG to use ONLY AZ2 -> Delete AZ1 -> Recreate smaller AZ1 -> Move ASG to AZ1 -> Delete AZ2 -> Recreate smaller AZ2 -> Create AZ3。
        * 这是一个**滚动迁移**的过程。
        * 1. 把实例都赶到 AZ2（AZ2 还在）。服务不中断（只要容量够）。
        * 2. 删 AZ1 子网（空了）。重建更小的 AZ1。
        * 3. 把实例赶到新 AZ1。
        * 4. 删 AZ2。重建更小的 AZ2。
        * 5. 建 AZ3。
        * 这样确实可以在**不增加总 CIDR** 的情况下，腾出空间给 AZ3。
        * **可行性：** 只要 ASG 能在单 AZ 支撑负载，且“连接到本地”不受子网重建影响（通常 VGW/DXGW 是 VPC 级别的，不绑子网；但如果用了 Transit Gateway Attachment，删子网会断连？TGW Attachment 是子网级的。VPN 是 VGW 级的。题目说 "VPC is connected"）。
        * 这种操作风险极高，但在 AWS 考题的逻辑闭环里，这是唯一满足“不加 IP”且“尽量不中断（业务层面）”的方案。
    * **选项 B:** Terminate instances in AZ1... 手动杀？不如 A 用 ASG 调度平滑。
    * **选项 D:** Update AZ1 subnet to have half address space? **AWS 不支持缩小/修改现有子网 CIDR**。必须删了重建。A 说是 Delete/Recreate，D 说是 Update。所以 D 是技术上不可行的。
    * **结论：** A 是唯一技术可行（通过 ASG 迁移流量，删重建）且符合所有约束（不加 IP）的方案。
    * **锁定 A。**

**3. ✅ 正确选项解析 (选项 A)**
* **Subnet Sizing:** AWS 子网一旦创建无法修改大小。必须删除重建。
* **Rolling Migration:** 利用 ASG 将流量在 AZ 间倒腾，腾出空间重组网络。

**5. 📚 核心考点:** VPC 子网 CIDR 的不可变性与重构策略。

---

#### 📝 [294/529] 强制 CloudFormation 标签 (Tag Policy + SCP)

**1. 🕵️‍♂️ 题眼与约束分析**
* **需求：** Force usage of **Project tags** (强制项目标签)。
* **验证：** Cost Explorer 发现不合规。
* **目标：** Enforce on **creation** (创建时强制) with **least effort**。
* **工具：** CloudFormation (CFN)。

**2. ⚡ 秒杀思路**
* **标签策略 (Tag Policy):** 定义标签的合法值（Key/Value 大小写等）。
* **SCP:** 强制要求资源创建请求必须带标签。
* **针对 CloudFormation:**
    * 如果我们要求所有 `CreateStack` 操作必须带 `Project` 标签。
    * 并且 CloudFormation 堆栈的标签会自动传播给它创建的资源（Resource Tags）。
    * 那么只要卡住 `cloudformation:CreateStack` 必须带标签即可。
* **选项对比：**
    * **选项 A:** 在 **Management Account** 创建 Tag Policy。创建 SCP Deny `cloudformation:CreateStack` unless `RequestTag/Project` exists。附加到 OUs。这是标准做法。
    * 选项 B: 在每个 OU 创建 Tag Policy？Tag Policy 可以在 Root/Mgmt 账户创建一次，共享给全组织。A 更高效。
    * 选项 C: IAM Policy？需要给每个用户配，麻烦。
    * 选项 D (Service Catalog): 虽然可以，但引入 SC 是个大工程，题目只要求强制标签。
* **锁定 A。**

**3. ✅ 正确选项解析 (选项 A)**
* **SCP:** 强制 `CreateStack` 必须带标签。
* **Tag Policy:** 规范标签值的标准。

**5. 📚 核心考点:** CloudFormation 堆栈标签的强制执行。

---

#### 📝 [295/529] EC2 规格优化 (Compute Optimizer)

**1. 🕵️‍♂️ 题眼与约束分析**
* **现状：** ASG, Single Instance Type。
* **问题：** **Underutilized** (利用率低)。
* **目标：** Reduce cost, improve utilization, **Least config changes**。

**2. ⚡ 秒杀思路**
* **Right-sizing:** 既然利用率低，应该换更小的实例。
* **ASG 功能:** ASG 现在的 Launch Template 支持 **Multiple Instance Types** (混合实例策略)。
* **选项对比：**
    * 选项 A: 修改 Launch Template 使用“多个相似属性的实例类型”。这通常是为了 Spot 容量池的多样化，或者是为了 Compute Savings Plan 的灵活性。但题目主要是想解决“利用率低”的问题，即**降级**（Downsizing）。
    * **选项 C:** "Use info about CPU/Memory... create **new version** of Launch Template... specifying CPU/Memory requirements"。
        * 这听起来像是 **Attribute-based Instance Type Selection**。
        * 你告诉 ASG：“我要 2 vCPU, 4GB RAM 的机器”。ASG 会自动选。
        * 但是，如果当前用的是 16xlarge，你需要显式地把要求降到 4xlarge。
        * 选项 B/C/D 的区别在于操作方式。
    * **选项 B:** "Select a right-sized instance type... Add new type... Remove current"。这是最直接的 **Manual Right-sizing**。比如把 c5.2xlarge 换成 c5.large。这是最稳妥、改动最小（只改型号）的方式。
    * 选项 C (Attribute-based): 如果你只指定 CPU/Mem，ASG 可能会选出很多种。虽然灵活，但对于“降低成本”这个明确目标，直接指定一个**更便宜的型号**（B）通常更可控。
    * **然而，** 题目提到 "Least configuration changes"。
    * 修改 Launch Template (B/C) 都是改配置。
    * **Compute Optimizer** 的建议通常是具体的实例类型（如 "Change to m5.large"）。
    * 所以 **B** 是实施 Compute Optimizer 建议的标准动作。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **Right-sizing:** 替换为利用率匹配的实例类型。

**5. 📚 核心考点:** ASG 实例规格调整的操作。

---

#### 📝 [296/529] 容器化应用灾备 (RPO 2h, RTO 4h)

**1. 🕵️‍♂️ 题眼与约束分析**
* **RPO:** 2 hours。
* **RTO:** 4 hours。
* **架构：** ECS, API Gateway, Aurora, DynamoDB。
* **目标：** **Most cost-effective**。

**2. ⚡ 秒杀思路**
* **方案 A/D (Global DB):** Aurora Global / DynamoDB Global Tables 是实时/秒级 RPO，RTO 分钟级。**成本高**（一直开着副本）。对于 2h/4h 的宽松要求，这是杀鸡用牛刀，不符合 Cost-effective。
* **方案 B (DMS/Streams):** 自己搭建复制链路？Lambda 维护复杂，且 EventBridge 触发复制可能不连续。
* **方案 C (AWS Backup):**
    * **Aurora/DynamoDB:** AWS Backup 支持跨区域复制备份。
    * **RPO:** 设置备份频率为 1 小时或 2 小时，即可满足 RPO 2h。
    * **RTO:** 4 小时足够从备份恢复数据库。
    * **成本:** 备份存储费远低于 Global Database 的计算/IO 费。平时 DR 区域不需要运行数据库实例。
    * **其他组件:** API Gateway / CloudFormation 可以快速部署。Route 53 Failover 负责切流量。
    * **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **AWS Backup Cross-Region Copy:** 满足宽松 RPO/RTO 的最低成本方案。

**5. 📚 核心考点:** 不同 RPO/RTO 等级下的数据库灾备选型 (Backup vs Global DB)。

---

#### 📝 [297/529] CloudFront 缓存命中率优化 (Query String Normalization)

**1. 🕵️‍♂️ 题眼与约束分析**
* **问题：** Cache hit ratio dropping (缓存命中率下降)。
* **原因：** **Inconsistent query string ordering** (参数顺序不一致) & **Mixed casing** (大小写混用)。
* **原理：** CloudFront 默认认为 `?a=1&b=2` 和 `?b=2&a=1` 是两个不同的 URL，分别缓存。大小写也一样。这导致缓存碎片化。
* **目标：** Improve hit ratio ASAP (尽快提高)。

**2. ⚡ 秒杀思路**
* **解决方案：** 需要在请求到达缓存键（Cache Key）生成之前，将 Query String **标准化 (Normalize)**。
    * 按字母顺序排序参数。
    * 统一转小写。
* **实现位置：** **CloudFront Functions** 或 **Lambda@Edge**。
    * CloudFront Functions 更便宜、更快，适合这种简单的头/URL 操作。
    * Lambda@Edge 也可以。
* **选项对比：**
    * **选项 A:** Deploy **Lambda@Edge**... order parameters... lowercase... Viewer Request trigger。这是正确的逻辑和触发点（Viewer Request 在检查缓存之前）。
    * 选项 B (Disable caching): 禁用缓存？那命中率直接 0 了。
    * 选项 C (Reverse Proxy): 在 LB 后加代理？那时候请求已经穿透 CloudFront 了（Cache Miss），后端再处理对缓存命中率没帮助。
    * 选项 D (Case insensitive config): CloudFront **没有** "Case insensitive" 的配置开关。必须用代码处理。
* **锁定 A。**

**3. ✅ 正确选项解析 (选项 A)**
* **Query String Normalization:** 通过 Lambda@Edge (或 CloudFront Functions) 统一 URL 格式，提高缓存复用率。

**5. 📚 核心考点:** CloudFront 缓存键优化技巧。

---

#### 📝 [298/529] Aurora 跨区域灾备 (1h RPO, Lowest Cost)

**1. 🕵️‍♂️ 题眼与约束分析**
* **DB:** Aurora MySQL (5 nodes, heavy write)。
* **需求：** Cross-region replication。
* **RPO:** **1 hour**。
* **目标：** **Lowest cost**。

**2. ⚡ 秒杀思路**
* **方案 A (Global Database):** 实时复制，RPO < 1s。成本高（跨区域 IO 费 + 备用实例费）。不符合 Lowest Cost。
* **方案 B (Backtrack + Lambda):** Backtrack 是回溯，不是跨区域复制。Snapshot copy 是对的，但 Backtrack 描述混淆。
* **方案 C (DMS CDC):** CDC 是实时的，且需要维护 DMS 实例，成本不低。
* **方案 D (Snapshot Copy):**
    * Aurora 自动备份本身就是快照。
    * 可以配置 **AWS Backup** 或手动脚本（题目说 "Turn off auto backup... configure hourly backup" 可能是指自定义策略，或者利用 AWS Backup 的跨区域复制功能）。
    * 这里的选项 D 描述有点怪 "Turn off Aurora auto backup"。通常我们不关自动备份。
    * **但是，** 如果我们看 RPO 1h。每小时打一个快照并复制到异地，完全满足 RPO。
    * 相比于 Global Database (A) 需要一直开着备用集群（计算+存储），快照复制 (D) 只需要支付 S3 存储费和传输费。**成本极低**。
    * **让我们仔细看 D:** "Turn off Aurora automated backups. Configure Aurora backups to take a snapshot every hour."
    * 为什么要关自动备份？可能是为了完全接管备份策略，或者是为了避免自动备份的连续归档日志复制成本？（其实没必要）。
    * 但在 A/B/C/D 中，只有 D 是基于 **快照 (Snapshot)** 的。快照方案是满足宽松 RPO 的最省钱方案。
    * A/C 都是实时/近实时，成本高。
    * B 的 Lambda 逻辑复杂。
    * **结论：** 尽管 D 的前半句有关闭自动备份的瑕疵，但 "Hourly Snapshot Copy" 是唯一匹配 "1 hour RPO + Lowest Cost" 的模式。
    * **修正：** 其实 **AWS Backup** 是做这个的最佳工具。D 描述的是一种手动/自定义的快照策略。
    * **锁定 D。**

**3. ✅ 正确选项解析 (选项 D)**
* **Snapshot Copy:** 满足 1 小时 RPO 的最低成本方案（无备用计算资源）。

**5. 📚 核心考点:** RPO 驱动的数据库灾备成本权衡。

---

#### 📝 [299/529] 单体应用现代化 (SSM + ASG + Aurora)

**1. 🕵️‍♂️ 题眼与约束分析**
* **现状：** Stateless App on 1 EC2 (AMI based), MySQL on 1 EC2。
* **痛点：** CPU 100% (Hang), Manual patching (Downtime)。
* **目标：** High Availability, **Least development effort** (最少开发)。

**2. ⚡ 秒杀思路**
* **数据库：**
    * 迁移到 **Aurora MySQL (D)** 或 **RDS** 是最简单的（同构迁移），全托管，高可用。
    * 迁移到 DynamoDB (B) / DocumentDB (A) / Neptune (C) 需要重写代码（Schema 变更），违反 "Least development effort"。
    * $\rightarrow$ **锁定 D**。
* **应用层：**
    * **ASG:** 解决单点故障和 CPU 100% 问题（自动扩展）。
    * **SSM Agent:** 解决 "Manual patching" 问题（通过 SSM Patch Manager 自动打补丁，零干扰）。
    * **D 选项：** New AMI with SSM Agent -> ASG -> ALB -> Aurora。完美的 Lift & Shift + 现代化运维。
* **锁定 D。**

**3. ✅ 正确选项解析 (选项 D)**
* **Aurora MySQL:** 兼容 MySQL，无需改代码。
* **ASG + SSM:** 解决扩展性和补丁运维难题。

**5. 📚 核心考点:** 传统单体架构上云的最佳实践路径。

---

#### 📝 [300/529] 迁移分组发现 (Migration Hub Network Diagram)

**1. 🕵️‍♂️ 题眼与约束分析**
* **任务：** 识别应用程序的 **Dependencies** (依赖项)。
* **特征：** **Latency-sensitive** (延迟敏感)，Port 1000。
* **现状：** 已安装 **Discovery Agent**，收集了数据。
* **目标：** Identify dependencies to **move together** (分组迁移)。

**2. ⚡ 秒杀思路**
* **可视化工具：**
    * **AWS Migration Hub** 提供了一个 **Network Diagram** (网络图) 功能（基于 Discovery Agent 的数据）。
    * 它能直观地展示服务器之间的连接关系和端口。
    * 你可以在图上选择服务器，查看谁连了谁（端口 1000），然后直接**Create a Move Group**。
* **选项对比：**
    * **选项 A:** "Visualize network diagram... Athena data exploration... Query port 1000... Create move group"。这描述了 Migration Hub 的高级分析流程。实际上 Migration Hub 控制台可能直接有图，但 Athena 提供了深度查询能力（Discovery Service 数据可以导出到 Athena）。
    * 选项 B (MGN Test): 还没分组呢，怎么测？这是迁移后的验证。
    * 选项 C (Network Access Analyzer): 这是 VPC 里的网络分析工具（分析可达性），不是分析本地服务器依赖的。
    * 选项 D (CloudWatch Logs): Discovery Agent 不发 CloudWatch Logs，它发给 Discovery Service。
    * **A vs A 的细节：** Migration Hub 的 Data Exploration 功能确实是基于 Athena 的。这是 AWS 官方推荐的深度依赖分析方法。
    * **锁定 A。**

**3. ✅ 正确选项解析 (选项 A)**
* **Migration Hub + Athena:** 深度分析服务器依赖关系，创建迁移分组 (Move Group)。

**5. 📚 核心考点:** 迁移前的依赖分析与分组工具。

---
**小结：**
这组题目的 **SFTP EFS**、**CloudFront 缓存优化**、**Aurora 成本 RPO** 都是非常实用的。

**恭喜你，300 题！**