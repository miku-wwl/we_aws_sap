#### 📝 [420/529] 本地 60TB 数据跨境传输 (DataSync)

**1. 🕵️‍♂️ 题眼与约束分析**
* **源：** Europe (On-prem), 60TB images。
* **目标：** ap-northeast-1 (Tokyo) S3。
* **需求：**
    1.  Transfer existing & **NEW** images (增量/持续)。
    2.  Encrypted in transit。
    3.  **No custom development** (无开发)。
* **挑战：** 跨洲传输，距离远，数据量大。

**2. ⚡ 秒杀思路**
* **工具选型：**
    * **AWS DataSync (A):**
        * 专为数据传输设计，支持网络优化（传输协议优化），适合跨洲长距离传输。
        * 支持 S3 作为目标。
        * 支持 **Scheduled/Automated** 任务（满足 "New images" 需求）。
        * 无需开发。
    * **Firehose (B):** 需要写代码把文件推给 Firehose（它没有 Agent）。
    * **Snowball (C):** 60TB 可以用 Snowball，但对于 "New images created every day"（每日增量），Snowball 不合适（不能每天寄快递）。
    * **S3 Multipart (D):** 需要自己写脚本管理并发、重试、加密，违反 "No custom development"。
* **锁定 A。**

**3. ✅ 正确选项解析 (选项 A)**
* **DataSync:** 自动化、高性能、免开发的混合云数据传输服务。

**5. 📚 核心考点:** DataSync 在跨洲大数据传输中的应用。

---
**恭喜你，420 题！**