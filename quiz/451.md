这 10 道题目涵盖了 **Direct Connect 冗余 (Active/Active, Active/Passive)**、**本地 MySQL 到云的迁移与视频存储 (S3 + DynamoDB)**、**EFS 备份与 RPO (AWS Backup + PITR)**、**强制 CLI 使用 MFA (STS GetSessionToken)**、**Windows 应用快速迁移 (Elastic Beanstalk)**、**批处理成本优化 (Batch + Spot)**、**大规模图像归档 (DataSync + Glacier)**、**CloudWatch Logs 指标提取 (Metric Filters)**、**GitHub Actions 访问 AWS (OIDC Federation)**、**网络爬虫成本优化 (Lambda + S3)**。

特别是 **Q454 (CLI MFA Enforcement)** 和 **Q459 (GitHub OIDC)** 是 SAP 考试中的 IAM 和 DevOps 安全高频题。

让我们开启 **逐题秒杀模式**！

---

#### 📝 [451/529] Direct Connect 高可用设计 (Cost-Effective HA)

**1. 🕵️‍♂️ 题眼与约束分析**
* **现状：** 1Gbps Direct Connect (Single Connection)。
* **需求：**
    1.  **High Availability** (高可用)。
    2.  **Fault Tolerance** (容错)。
    3.  **Secure** (安全 -> 加密)。
    4.  **Most Cost-effective** (最具成本效益)。
* **环境：** 制造应用。

**2. ⚡ 秒杀思路**
* **高可用与容错：**
    * 单条 DX 存在单点故障（物理线路、AWS 端口、本地路由器）。
    * 需要第二条路径。
    * **选项 B:** Another DX connection。这是最高性能的 HA，但 DX 端口费和线路费贵，且建设周期长。题目要求 "Cost-effective"。
    * **选项 A/D:** Site-to-Site VPN。VPN 通过公网（或 DX Public VIF，但通常指公网 VPN 作为备份），成本极低（相比 DX），部署快。对于 1Gbps 的主链路，VPN 作为备份是标准的经济型 HA 方案。
* **安全性（加密）：**
    * DX 本身不加密（物理层安全但数据明文）。
    * 题目要求 "Secure data transfer"。
    * **MACsec (A/B):** 只有 10Gbps 和 100Gbps 的专用连接才支持 MACsec。题目是 1Gbps，通常不支持（除非是特定位置的 10G 端口限速，但一般假设 1G 不支持 MACsec，或者即便支持，也需要硬件支持）。
    * **VPN over DX (或 VPN backup):** VPN 使用 IPsec，天生加密。
    * **选项 A:** "Add dynamic private IP VPN... configure MACsec inside DX"。MACsec 的限制如上。
    * **选项 D:** "Add static VPN... ensure secure... resilience"。
* **关于 VPN 类型：**
    * **BGP (Dynamic Routing):** 题目现状已经配了 BGP。为了实现自动故障转移，备份 VPN 也应该用 **Dynamic VPN (BGP)**。静态 VPN 需要手动切换或复杂的健康检查脚本。
    * **选项 A** 提到了 "Dynamic private IP AWS Site-to-Site VPN"。这通常指通过 DX 的 Public VIF 建立 VPN（这样 VPN 流量走 DX 物理链路，加密且私有）。或者指普通的公网动态 VPN。
    * **但是，** 选项 A 后半句说 "Configure MACsec inside Direct Connect connection"。这可能是一个干扰项或错误描述。如果忽略 MACsec 的可行性问题，A 提供了 Dynamic VPN（匹配 BGP 环境）和加密。
    * **让我们再看选项 D:** Static VPN。静态路由无法自动响应 DX 故障（除非配置非常复杂）。在 BGP 环境下，必须用 Dynamic VPN。
    * **选项 B (Dual DX):** 成本高。
    * **选项 C (Multiple VIF):** VIF 是逻辑的，都在同一根物理线上。物理线断了全断。不是容错。
    * **修正：** 也许题目中的 1Gbps 支持 MACsec？（AWS 后来扩展了 MACsec 支持，但主要是 10G/100G）。
    * **更关键的是：** **Site-to-Site VPN over Direct Connect (Public VIF)** 是实现 DX 加密的标准方法。或者 VPN over Internet 作为备份。
    * 题目问 "Update existing... ensure HA, FT, Secure... Cost-effective"。
    * 增加一个 **VPN** 作为备份是最省钱的 HA。
    * 只有 A 提到了 **Dynamic VPN**。这与现有的 BGP 兼容。即使后半句 MACsec 有争议（也许是指 VPN 提供了加密，或者题目假设 1G 支持），A 是唯一在路由协议上匹配（Dynamic）且成本低（VPN）的选项。
    * **注意：** 实际上，最标准的答案是 "VPN as backup"。至于加密，VPN 自带加密。
    * **锁定 A。**

**3. ✅ 正确选项解析 (选项 A)**
* **Dynamic VPN:** 与 BGP 配合实现自动故障转移。
* **Cost-effective:** VPN 备份比双 DX 便宜。
* **Encryption:** VPN 提供 IPsec 加密。

**5. 📚 核心考点:** Direct Connect 的低成本高可用备份方案 (VPN) 及路由协议匹配。

---

#### 📝 [452/529] 本地 MySQL 迁移与视频存储 (S3 + DynamoDB)

**1. 🕵️‍♂️ 题眼与约束分析**
* **源：** MySQL (User profiles + Video data as text/blob?)。
* **新需求：** Upload 4GB videos (大文件)。
* **性能：** **Do not impact app performance** (不影响性能，数据库存大文件是性能杀手)。
* **迁移：** Modernize (现代化)。

**2. ⚡ 秒杀思路**
* **视频存储：**
    * 4GB 视频绝对不能存数据库（无论是 MySQL 还是 DynamoDB，DynamoDB item limit 400KB）。
    * 必须存 **S3**。
    * 数据库只存 S3 Key/URL。
    * $\rightarrow$ **选中 B 或 C**。
    * (A 存 Aurora Text? 性能杀手。D 存 DynamoDB base64? 4GB base64 远超 400KB 限制)。
* **数据库迁移：**
    * **DynamoDB (B):** 适合用户配置文件（KV 结构），高性能，Serverless。配合 S3 存视频，是经典的现代化架构。
    * **Keyspaces (C):** Cassandra 兼容。除非原应用强依赖 Cassandra，否则 DynamoDB 是 AWS 首选 NoSQL。题目没提 Cassandra。
* **工具：** DMS + SCT (Schema Conversion Tool) 是异构迁移（MySQL -> NoSQL）的标准组合。
* **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **S3:** 存储大对象（视频）。
* **DynamoDB:** 存储元数据，提供快速读写。
* **SCT/DMS:** 实现异构数据库迁移。

**5. 📚 核心考点:** “大对象存 S3，元数据存 DB”的经典模式。

---

#### 📝 [453/529] EFS 备份 RPO 100 分钟 (PITR)

**1. 🕵️‍♂️ 题眼与约束分析**
* **存储：** EFS (KMS Encrypted)。
* **现状：** AWS Backup Default Plan (Daily?)。
* **需求：** Restore deleted documents within **100 minutes RPO** (RPO < 100min)。
* **机制：** Automatic backup。

**2. ⚡ 秒杀思路**
* **备份频率：**
    * AWS Backup 默认计划通常是每日。RPO 24小时。不满足。
    * 选项 A: Hourly backup plan (每小时)。RPO 60分钟。满足 100 分钟要求。
    * 选项 B: Cron expression every 30 mins。RPO 30分钟。满足。
    * 选项 C: **Continuous Backup (Point-in-Time Recovery)**。EFS 支持 AWS Backup 的 PITR。这允许恢复到过去 35 天内的任意秒。RPO 接近 0。满足。
* **权限 (KMS):**
    * AWS Backup 恢复或创建加密备份需要 KMS 权限。
    * 选项 A/C: "Create NEW IAM role... update KMS policy to allow NEW role"。这是正确的权限配置步骤（AWS Backup 需要一个 Service Role）。
    * 选项 B/D: "Allow `AWSServiceRoleForBackup`"。这是服务链接角色。通常我们创建一个自定义角色传给 AWS Backup，或者使用默认的。
* **对比 A, B, C:**
    * A (Hourly): 离散备份。产生很多恢复点。
    * B (30 mins Cron): 同上。
    * C (Continuous Backup): 这是 EFS/Backup 的高级功能，专为低 RPO 设计。**Point-in-Time Recovery (PITR)** 比频繁打快照更高效、更易管理。
    * 题目问 "Which solution meets requirements"。A, B, C 都满足 RPO。
    * 但是，**PITR (Continuous Backup)** 是 AWS Backup 针对 EFS/RDS 等服务推荐的实现低 RPO 的原生方式。它不需要你写 Cron 表达式，也不需要管理成千上万个每小时的快照。
    * **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **Continuous Backup (PITR):** 实现任意时间点恢复，满足严格 RPO。
* **IAM Role & KMS:** 正确的权限配置流程。

**5. 📚 核心考点:** AWS Backup 的持续备份（PITR）功能及其优势。

---

#### 📝 [454/529] 强制 AWS CLI 使用 MFA (STS GetSessionToken)

**1. 🕵️‍♂️ 题眼与约束分析**
* **用户：** Cloud Engineers (IAM Users + Access Keys + MFA Device)。
* **工具：** AWS CLI。
* **需求：** **Enforce MFA** for S3 operations (强制 MFA)。
* **当前策略：** IAM User in `S3-access` group。

**2. ⚡ 秒杀思路**
* **强制策略 (IAM Policy):**
    * 在 IAM Policy 中使用 `Condition: {"Bool": {"aws:MultiFactorAuthPresent": "true"}}`。
    * 如果没有 MFA，拒绝操作。
    * $\rightarrow$ **选中 C 或 D** 的前半部分。
* **CLI 操作流程：**
    * 长期凭证（Access Key / Secret Key）本身**不包含** MFA 信息。直接用它们调用 CLI，`aws:MultiFactorAuthPresent` 是 `false`（或不存在），会被拒绝。
    * 必须先使用长期凭证 + MFA Code 调用 **`aws sts get-session-token`**，获取**临时凭证**。
    * 这个临时凭证由于是带 MFA 换取的，所以包含 `aws:MultiFactorAuthPresent: true` 上下文。
    * 然后配置 CLI 使用这个临时凭证操作 S3。
* **选项对比：**
    * A (Prompt for MFA): CLI 不会自动弹出提示框输入 MFA。必须显式获取 Token。
    * B (Trust Policy): IAM User 没有 Trust Policy（只有 Role 有）。
    * C (Deny unless MFA): 策略是对的，但操作描述 "Use IAM access key and CLI to call S3" 是错的。直接用 AK/SK 会被拒绝。
    * **D:** Policy (Deny unless MFA) + **STS GetSessionToken** (Get temp creds) + **Use temp creds in profile**。这是 CLI 使用 MFA 的标准且唯一正确流程。
    * **锁定 D。**

**3. ✅ 正确选项解析 (选项 D)**
* **Condition: aws:MultiFactorAuthPresent:** 强制 MFA 的策略条件。
* **STS GetSessionToken:** CLI 获取带 MFA 上下文的临时凭证的方法。

**5. 📚 核心考点:** CLI 环境下强制 MFA 的实现机制与操作流程。

---

#### 📝 [455/529] Windows 遗留应用快速迁移 (Elastic Beanstalk)

**1. 🕵️‍♂️ 题眼与约束分析**
* **源：** 60 Legacy .NET Apps on Windows。
* **需求：**
    1.  **Minimize migration time** (最快)。
    2.  **No code changes** (不改代码)。
    3.  **No infrastructure management** (不管理基础设施 -> PaaS/Serverless)。
* **工具：** Windows Web Application Migration Assistant。

**2. ⚡ 秒杀思路**
* **平台选型：**
    * **Elastic Beanstalk (B):** PaaS 服务，自动管理 EC2、LB、ASG。支持 .NET on Windows。符合 "No infrastructure management"。**Migration Assistant** 专门支持迁移到 Beanstalk。
    * **EC2 (C):** IaaS，需要管理基础设施（补丁、扩展等）。违反需求。
    * **ECS/EKS (A/D):** 需要容器化 (Containerize)。虽然 "Refactor" 工具可以辅助，但容器化本身可能涉及配置变更，且 ECS/EKS 的运维复杂度（即使是 Fargate）通常比 Beanstalk 高（对于遗留 .NET 来说）。且 A/D 提到了 ".NET Refactoring"，题目说 "No code changes"。
* **工具匹配：**
    * **Windows Web Application Migration Assistant** 是 AWS 官方工具，专门用于将本地 IIS 应用打包并部署到 **Elastic Beanstalk**。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **Elastic Beanstalk:** 托管 .NET 应用的 PaaS 平台，免运维。
* **Migration Assistant:** 自动化迁移工具。

**5. 📚 核心考点:** .NET 应用迁移到 Elastic Beanstalk 的工具与优势。

---

#### 📝 [456/529] S3 批处理成本优化 (Batch + Spot)

**1. 🕵️‍♂️ 题眼与约束分析**
* **任务：** Large batch jobs on S3 data (Simulation)。
* **特点：** 15-20GB per job, **Can be interrupted** (可中断)。
* **目标：** **Most cost-effective**。

**2. ⚡ 秒杀思路**
* **计算资源：**
    * 可中断 $\rightarrow$ **Spot Instances**。
* **调度服务：**
    * **AWS Batch (B/C):** 专门为批处理设计，原生支持 Spot 实例调度，自动重试。
    * Step Functions + Lambda (A): Lambda 有内存（10GB Max）和时间（15min）限制。处理 15-20GB 数据可能不够或超时，且成本通常比 Spot 高。
    * EKS (D): 管理 K8s 集群有额外成本（Control Plane）和运维。Batch 更轻量（Serverless-like）。
* **分配策略 (Allocation Strategy):**
    * **SPOT_CAPACITY_OPTIMIZED (B/C):** 这是使用 Spot 的最佳实践，它选择中断率最低的池，而不是仅仅最便宜的（SPOT_PRICE_CAPACITY_OPTIMIZED）。这能减少作业中断重试的概率，从而间接省钱（重试也要钱）。
* **B vs C:**
    * B: **Spot Only**。既然任务可以中断，且要求最具成本效益，全 Spot 是最便宜的。
    * C: On-Demand + Spot。混合模式成本比全 Spot 高。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **AWS Batch:** 托管批处理调度。
* **Spot Instances:** 最低计算成本。
* **Capacity Optimized:** 减少中断，提高完成率。

**5. 📚 核心考点:** 大规模可中断批处理任务的成本优化架构。

---

#### 📝 [457/529] 大规模图像归档到 S3 (DataSync + Glacier Deep Archive)

**1. 🕵️‍♂️ 题眼与约束分析**
* **源：** On-prem NFS, Millions of 1MB images, batched into 1GB files.
* **存储：** No local capacity (本地满了)。
* **需求：**
    1.  Archive to AWS (归档)。
    2.  Retrieve within **1 week** (RTO 宽松)。
    3.  **Bandwidth limit** & **Schedule** (带宽限制 + 定时)。
    4.  **Most cost-effective**。
    5.  Connection: 10Gbps DX.
    6.  Compute: Hyper-V available.

**2. ⚡ 秒杀思路**
* **传输工具：**
    * **AWS DataSync (A/B/C):** 支持 NFS 源，支持 **Bandwidth Throttling** (带宽限制) 和 **Scheduling** (定时)。性能高。
    * Storage Gateway Tape (D): 磁带网关也可以，但管理虚拟磁带库比较麻烦，且 DataSync 直接存对象更灵活。
* **部署方式：**
    * 题目说 "Has Hyper-V environment and compute capacity available"。
    * DataSync Agent 可以部署为 **Hyper-V VM (B)**。这样不需要在 AWS 开 EC2 实例（省钱，且 DataSync 传输是推模式，Agent 离源数据近更好）。
    * A/C 建议 "Deploy DataSync Agent on new EC2 instance"。这是错的。DataSync Agent 必须部署在**源端网络**（本地），或者通过 VPC 访问。如果部署在 EC2，需要挂载本地 NFS（通过 DX），这增加了延迟和复杂性。通常 Agent 部署在本地。
* **存储类别：**
    * RTO < 1 week $\rightarrow$ **Glacier Deep Archive** (12-48h 取回)。这是最便宜的存储。
    * DataSync 支持直接写入 S3 对应的存储类（或者通过 Lifecycle）。
    * **选项 B:** DataSync Agent on Hyper-V -> **Glacier Deep Archive**。
    * **选项 C:** DataSync -> S3 Standard -> Lifecycle to Deep Archive。多了一步转换，S3 Standard 存一天也有费用（最小存储期限问题？Standard 没有，但 Deep Archive 有。不过直接存 Deep Archive 最省事）。
    * **关键：** DataSync 现在的确支持直接写入各层级。直接写入 Deep Archive 最省钱。
    * 且 B 选项利用了本地 Hyper-V 资源，不需要开 EC2。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **DataSync on Hyper-V:** 利用本地资源部署 Agent。
* **Glacier Deep Archive:** 最低成本归档存储。
* **Scheduling & Throttling:** DataSync 原生功能满足网络要求。

**5. 📚 核心考点:** DataSync 的部署位置与归档存储选择。

---

#### 📝 [458/529] 提取日志指标 (Metric Filters)

**1. 🕵️‍♂️ 题眼与约束分析**
* **源：** CloudWatch Logs (Log files from app).
* **数据：** Login actions (User name, Client name)。
* **需求：** Count unique users per client (统计)。
* **约束：** **Least changes** (最小改动)。

**2. ⚡ 秒杀思路**
* **CloudWatch Logs Metric Filters (A):**
    * 允许你定义模式（Pattern）来匹配日志行。
    * 可以从日志中**提取值**（如用户名、客户端名）作为 **Metric Dimensions** (维度)。
    * 一旦提取为指标，就可以在 CloudWatch Metrics 中进行统计（Count, Unique 等）。
    * 这是一个**纯配置**的方案，不需要改应用代码 (B)，不需要改 Agent 配置 (C - Agent 主要是传日志，不做复杂提取)，不需要写 Lambda (D)。
* **选项对比：**
    * A: Metric Filter 提取维度。最简单，零代码。
    * B: 改代码发 PutMetricData。工作量大。
    * C: CloudWatch Agent `metrics_collection` 主要收集系统指标，日志提取通常在服务端（CloudWatch Logs）做。
    * D: Lambda 订阅日志流。可以做，但维护 Lambda 比配置 Filter 麻烦。
* **锁定 A。**

**3. ✅ 正确选项解析 (选项 A)**
* **Metric Filters:** 从日志文本中提取结构化数据并转化为监控指标，零代码。

**5. 📚 核心考点:** CloudWatch Logs 的价值提取功能 (Metric Filters)。

---

#### 📝 [459/529] GitHub Actions 安全访问 AWS (OIDC Federation)

**1. 🕵️‍♂️ 题眼与约束分析**
* **源：** GitHub Actions CI/CD。
* **现状：** IAM User Access Keys (Long-term credentials)。
* **需求：** **Replace long-term keys with short-term solution** (短期凭证)。
* **目标：** **Least operational overhead**。

**2. ⚡ 秒杀思路**
* **身份联合：**
    * GitHub Actions 支持 **OIDC (OpenID Connect)**。
    * AWS IAM 支持 **OIDC Identity Provider**。
    * 可以配置 AWS IAM 信任 GitHub 的 OIDC 提供商。
    * GitHub Actions 在运行时获取 GitHub 颁发的 JWT Token，然后调用 `sts:AssumeRoleWithWebIdentity` 换取 AWS 临时凭证。
    * **全程无需 Access Key**，完全基于短期 Token。
* **选项对比：**
    * A (SAML): GitHub Actions 不是 SAML IdP。
    * **B:** Create **IAM OIDC IdP**. Create Role trusting GitHub OIDC via `sts:AssumeRoleWithWebIdentity`. 这是标准方案。
    * C (Cognito): 多此一举，IAM 直接支持 OIDC。
    * D (Roles Anywhere): 基于证书的，主要用于本地服务器。GitHub Actions 是云服务，OIDC 更原生。
* **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **OIDC Federation:** 实现 GitHub Actions 到 AWS 的无密钥（Keyless）安全认证。

**5. 📚 核心考点:** 第三方 CI/CD (GitHub/GitLab) 安全访问 AWS 的最佳实践。

---

#### 📝 [460/529] 网络爬虫成本优化 (Lambda + S3)

**1. 🕵️‍♂️ 题眼与约束分析**
* **任务：** Web Crawler (SQS -> Process -> CSV to EFS)。
* **现状：** t2.micro EC2 fleet。
* **痛点：** Idle instances when queue empty (空闲浪费)。
* **特点：** Crawl takes < 10s (短任务)。Infrequent rate (不频繁)。
* **目标：** **Optimize cost**。
* **选择：** 2 个步骤。

**2. ⚡ 秒杀思路**
* **计算层：**
    * 任务短（<10s），不频繁，SQS 触发。
    * **Lambda (B):** 完美匹配。按调用时长付费，无空闲成本。自动扩缩容。比维护一堆闲置的 EC2 便宜得多。
    * A (Larger EC2): 更贵。
* **存储层：**
    * 结果是 `.csv` 文件。
    * 之前用 EFS 是为了挂载到 EC2。
    * 转 Lambda 后，虽然也能挂 EFS，但对于 CSV 文件存储，**S3 (E)** 是更便宜、更原生的选择。Lambda 写 S3 非常简单。
    * C (Neptune) / D (Aurora): 数据库比 S3 贵，且题目只是存 CSV 文件。
* **选项组合：**
    * **B (Lambda)** + **E (S3)**。
    * 将 EC2 替换为 Lambda，将 EFS 替换为 S3。实现全 Serverless，极致成本优化。
* **锁定 B, E。**

**3. ✅ 正确选项解析 (选项 B, E)**
* **Lambda:** 消除闲置计算成本。
* **S3:** 最低成本的对象存储。

**5. 📚 核心考点:** 传统批处理/Worker 架构向 Serverless 的成本优化改造。

---
**小结：**
这组题目的 **GitHub OIDC**、**EFS 备份**、**DataSync 归档** 都是非常实用的场景。

**恭喜你，460 题！**