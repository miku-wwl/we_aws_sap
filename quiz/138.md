#### 📝 [138/529] 基因测序流程 (DataSync + Batch)

**1. 🕵️‍♂️ 题眼与约束分析**
* **源端：** 本地 SAN，测序数据 (200GB/genome)。
* **连接：** High-speed **Direct Connect** (DX)。
* **计算：** Docker containers, processing takes hours (数小时).
* **吞吐：** 10-15 jobs/day。
* **目标：** Reduce turnaround time (几天 -> 几小时), Scale based on workload。

**2. ⚡ 秒杀思路**
* **数据传输：**
    * 有高速 DX，首选在线传输。
    * **AWS DataSync (C):** 专为大数据量在线传输设计，比 Snowball (A) 快（Snowball 要快递几天，不适合每天 10-15 个作业的持续流）。Data Pipeline (B) 太老且主要用于调度，不适合大文件传输。Storage Gateway (D) 也可以，但 DataSync 针对吞吐量优化更好。
* **计算平台：**
    * Docker 容器 + 数小时运行 + 批处理 $\\rightarrow$ **AWS Batch (C/D)**。
    * Lambda (A) 超时。
    * EC2 ASG (B) 需要自己写调度逻辑。
* **编排：**
    * **Step Functions (C):** 编排复杂工作流（如解压、分析、质控）的最佳实践。
    * 选项 D 直接用 S3 Event 触发 Batch。虽然可行，但 C 的 DataSync + Step Functions + Batch 组合更符合基因组学的现代架构（DataSync 自动同步，Step Functions 管理流程）。
    * **关键点：** A (Snowball) 不适合日常持续作业。B (Data Pipeline) 过时。D (Storage Gateway) 也可以，但通常基因测序产生大量小文件或巨型文件，DataSync 效率更高。且 C 提到了 ECR 存镜像，这是容器化的标准。
    * **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **DataSync:** 高速传输基因数据。
* **AWS Batch:** 托管批处理计算。
* **Step Functions:** 流程编排。

**5. 📚 核心考点:** 基因组学/HPC 混合云架构。