
---

#### 📝 [23/529] 周期性大数据作业存储优化

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** 每月运行一次，持续 72 小时。读取 200TB 数据集的一部分。
* **当前痛点：** 共享文件系统实例 **runs constantly** (一直开着)，但只用 3 天。太贵。
* **需求：** **Cost reduction** (降成本) + **High performance** (高性能)。
* **核心技术：** **Amazon FSx for Lustre**。

**2. ⚡ 秒杀思路**
* **关键词匹配：**
    * "High performance access" + "S3 data source" + "Short term processing" $\rightarrow$ **FSx for Lustre** 链接到 S3。
* **排除法：**
    * 选项 B (EBS Multi-Attach): 只能挂载到最多 16 个实例，且必须在同一 AZ。题目说“数百个实例”，EBS Multi-Attach 根本不够用。
    * 选项 D (Storage Gateway): 性能不如 Lustre，且主要是为了混合云缓存，不是为了云上高性能计算。
    * **对比 A 和 C (FSx for Lustre):**
        * 区别在于 S3 存储类别：**Intelligent-Tiering (A)** vs **Standard (C)**。
        * 题目说 "subset of the file system... roughly 72 hours"。这意味着大部分数据是冷的。Intelligent-Tiering 能自动把不访问的数据沉降到低频层，省钱。
        * 更关键的区别：**Lazy Loading (A)** vs **Bulk Loading (C)**。
            * **Lazy Loading:** 只有当计算节点请求文件时，Lustre 才从 S3 拉取。启动快，省钱（不需要预先拉取 200TB）。
            * **Bulk Loading:** 预先加载。对于 200TB 数据，预加载时间长且没必要（因为只读 subset）。
    * **锁定 A。**

**3. ✅ 正确选项解析 (选项 A)**
* **FSx for Lustre + S3 Data Repository:** 允许你把 S3 桶当作文件系统挂载。
* **Lazy Loading:** 完美适配“只读取子集”的场景。
* **S3 Intelligent-Tiering:** 针对长期存储（非工作期间）的数据，自动降本。

**5. 📚 核心考点:** HPC 场景下的存储选型 (FSx for Lustre linked to S3)。
