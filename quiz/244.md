#### 📝 [244/529] 混合云监控日志流 (Firehose -> Splunk)

**1. 🕵️‍♂️ 题眼与约束分析**
* **源端：** CloudWatch Logs (EC2, VPC Flow Logs)。
* **目标：** **Splunk** (On-premise / Cloud)。
* **需求：** Near-real-time (近实时)。

**2. ⚡ 秒杀思路**
* **数据流：**
    * CloudWatch Logs $→$ ? $→$ Splunk。
    * **Kinesis Data Firehose (B):** 原生支持将数据投递到 **Splunk** (通过 HEC - HTTP Event Collector)。这是最标准的集成方式。
* **选项对比：**
    * 选项 A (Export to S3 + Pull): 导出是批量的，延迟高，不符合 Near-real-time。
    * 选项 C (Athena): 查询分析工具，不是流式投递工具。
    * 选项 D (Kinesis Analytics): 做实时分析的，虽然也能写 Firehose，但这里只需要"转发"日志，不需要复杂的 SQL 分析（如异常检测）。B 选项中的 "Preprocessing Lambda" 足以处理简单的格式转换（解压 CloudWatch Logs）。D 有点过度设计。
    * **选项 B:** CloudWatch Logs Subscription Filter $→$ Kinesis Firehose $→$ Splunk。这是教科书级的日志集成架构。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **Firehose to Splunk:** 托管的日志投递管道，支持解压和格式化。

**5. 📚 核心考点:** CloudWatch Logs 到第三方 SIEM (Splunk) 的集成。