太棒了！我们继续这 10 道题的分析。这一批题目涉及到了 **AWS SSO/IAM Identity Center**、**API 性能优化**、**大数据存储迁移**、**静态 IP 暴露**、**ECS 成本优化**、**数据库密码轮换**、**API Gateway 模式**、**多域名重定向**、**成本分配标签** 以及 **TGW 自动化**。

这些都是非常硬核的 SAP 考点，尤其是关于 **IAM Identity Center** 和 **Global Accelerator/NLB** 的场景。

让我们开启 **逐题秒杀模式**！

---

#### 📝 [21/529] AWS SSO (IAM Identity Center) 与 AD 集成

**1. 🕵️‍♂️ 题眼与约束分析**
* **现状：** 本地 Active Directory (AD)。
* **目标：** 登录 AWS Organizations 下的所有账户 (Single location management)。
* **关键需求：** **Conditional access based on user groups** (基于组的条件访问) + **Single location to manage identities**。
* **核心服务更新：** 注意，题目中的 "AWS Single Sign-On (AWS SSO)" 现在已更名为 **AWS IAM Identity Center**。

**2. ⚡ 秒杀思路**
* **关键词匹配：**
    * "Single location to manage" + "Access to AWS Accounts" + "Active Directory" $\rightarrow$ **AWS IAM Identity Center**。
    * "Conditional access" + "Attribute-based" (更灵活的权限控制) $\rightarrow$ **ABAC (Attribute-Based Access Control)** 是实现精细化条件访问的最佳实践。
* **排除法：**
    * 选项 C/D (IAM User/Role): 这需要在每个账户里配置 IAM，虽然可以用 StackSet 自动化，但不如 SSO 集中管理方便，且题目强调 "Single location managed"。
    * 选项 B (Permission Sets): 权限集是 SSO 的基本功能，但题目提到了复杂的“基于组和角色的条件访问”，选项 A 提到的 ABAC 是更高级、更符合现代安全架构的方案（虽然 B 也是可行的一部分，但 A 描述了连接机制 SAML + SCIM + ABAC，更完整）。
    * **细看 A vs B:** 选项 A 明确提到了 "Connect to Active Directory using SAML 2.0" 和 "SCIM"。这是标准的混合云 SSO 模式。选项 B 说 "Configure IAM Identity Center as identity source"（把 SSO 当成身份源），这意味着你要在 AWS 里重建用户，而不是用本地 AD。题目明确说 "Company uses on-premises Active Directory"，所以必须选 **连接到 AD** 的选项。
    * **锁定 A。**

**3. ✅ 正确选项解析 (选项 A)**
* **IAM Identity Center + SAML/SCIM:** 这是标准配置，AD 作为 IdP，AWS SSO 作为 SP。SCIM 自动同步用户和组。
* **ABAC:** 允许你写一条权限策略（如：允许访问 `Project=TeamA` 的资源），然后通过 AD 传递过来的属性（Team=TeamA）自动匹配。这比给每个组写死 Role 要灵活得多，完美满足 "Conditional access"。

**5. 📚 核心考点:** AWS IAM Identity Center 的 AD 集成模式及 ABAC 优势。

---

#### 📝 [22/529] API Gateway 写入节流 (Throttling)

**1. 🕵️‍♂️ 题眼与约束分析**
* **现象：** PUT 请求报错增加，错误显示给客户，损害声誉。
* **原因：** 单个客户端发起了大量 PUT 请求（Bad Actor/Heavy User）。
* **业务特征：** "API is not critical" (非关键)，"Clients can tolerate retries" (可容忍重试)。
* **目标：** **Improve customer experience** (改善体验，即让其他正常客户不受影响)。

**2. ⚡ 秒杀思路**
* **关键词匹配：**
    * "Single client causing high load" + "Throttling" $\rightarrow$ **Usage Plans & Throttling (使用计划与限流)**。
    * "Errors showing to customers" $\rightarrow$ 需要在客户端处理 **429 Too Many Requests**。
* **排除法：**
    * 选项 A (Client Retry): 只是让客户端重试，不能解决服务器端被压垮的问题，甚至可能加剧风暴。
    * 选项 C (Caching): 缓存只对 GET 有效，题目说的是 **PUT** 请求（写入），缓存无效。
    * 选项 D (Lambda Reserved Concurrency): 这会限制并发，导致更多请求直接报错（Throttling），虽然保护了下游，但没解决“谁导致的问题”。且 Usage Plan 能针对 API Key 限流，更精准地限制那个捣乱的客户端。
    * **选项 B:** 通过 Usage Plan 限制特定 API Key 的速率，直接把那个刷接口的客户端限制住，保护其他人。同时让客户端处理 429 错误（不要报错给用户看，而是静默重试或提示忙），符合“改善体验”。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **API Gateway Usage Plans:** 可以针对每个 API Key 设置 Rate Limit (RPS) 和 Burst。这是隔离“吵闹邻居”的标准做法。

**5. 📚 核心考点:** API Gateway 的多租户限流策略 (Usage Plans)。

---

#### 📝 [23/529] 周期性大数据作业存储优化

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** 每月运行一次，持续 72 小时。读取 200TB 数据集的一部分。
* **当前痛点：** 共享文件系统实例 **runs constantly** (一直开着)，但只用 3 天。太贵。
* **需求：** **Cost reduction** (降成本) + **High performance** (高性能)。
* **核心技术：** **Amazon FSx for Lustre**。

**2. ⚡ 秒杀思路**
* **关键词匹配：**
    * "High performance access" + "S3 data source" + "Short term processing" $\rightarrow$ **FSx for Lustre** 链接到 S3。
* **排除法：**
    * 选项 B (EBS Multi-Attach): 只能挂载到最多 16 个实例，且必须在同一 AZ。题目说“数百个实例”，EBS Multi-Attach 根本不够用。
    * 选项 D (Storage Gateway): 性能不如 Lustre，且主要是为了混合云缓存，不是为了云上高性能计算。
    * **对比 A 和 C (FSx for Lustre):**
        * 区别在于 S3 存储类别：**Intelligent-Tiering (A)** vs **Standard (C)**。
        * 题目说 "subset of the file system... roughly 72 hours"。这意味着大部分数据是冷的。Intelligent-Tiering 能自动把不访问的数据沉降到低频层，省钱。
        * 更关键的区别：**Lazy Loading (A)** vs **Bulk Loading (C)**。
            * **Lazy Loading:** 只有当计算节点请求文件时，Lustre 才从 S3 拉取。启动快，省钱（不需要预先拉取 200TB）。
            * **Bulk Loading:** 预先加载。对于 200TB 数据，预加载时间长且没必要（因为只读 subset）。
    * **锁定 A。**

**3. ✅ 正确选项解析 (选项 A)**
* **FSx for Lustre + S3 Data Repository:** 允许你把 S3 桶当作文件系统挂载。
* **Lazy Loading:** 完美适配“只读取子集”的场景。
* **S3 Intelligent-Tiering:** 针对长期存储（非工作期间）的数据，自动降本。

**5. 📚 核心考点:** HPC 场景下的存储选型 (FSx for Lustre linked to S3)。

---

#### 📝 [24/529] NLB 静态 IP 暴露

**1. 🕵️‍♂️ 题眼与约束分析**
* **需求：** TCP 静态端口，高可用，**DNS name** 访问，**Static IP addresses** (供客户加白名单)。
* **核心组件：** **Network Load Balancer (NLB)**。

**2. ⚡ 秒杀思路**
* **关键词匹配：**
    * "Static IP for allow-listing" + "High Availability" $\rightarrow$ **NLB** (每个 AZ 一个静态 IP)。
    * "TCP traffic" $\rightarrow$ NLB。
* **排除法：**
    * 选项 B/D (ECS Public IP): 让客户把动态的 ECS IP 加白名单是不可维护的。且 NLB 才是暴露服务的标准入口。
    * 选项 A (EC2 EIP + NLB): 逻辑混乱。把 EC2 注册到 NLB 后，客户应该访问 NLB 的 IP，而不是 EC2 的 IP。EC2 在私有子网更安全。
    * **选项 C:** 创建 NLB，为 NLB 的每个 AZ 分配一个 **Elastic IP (EIP)**。这是 NLB 的原生功能。然后把 EC2 注册到 NLB。DNS 指向 NLB。客户把那几个 EIP 加入白名单。
    * **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **NLB Static IP:** NLB 是 AWS 唯一支持每个可用区固定静态 IP 的负载均衡器。这正是为了防火墙白名单场景设计的。

**5. 📚 核心考点:** NLB 的静态 IP 特性。

---

#### 📝 [25/529] 混合工作负载成本优化 (SLA vs Spot)

**1. 🕵️‍♂️ 题眼与约束分析**
* **负载构成：**
    * **Scheduled (65%):** 有严格 SLA $\rightarrow$ **必须稳** $\rightarrow$ On-Demand / Reserved / Capacity Reservation。
    * **User (35%):** 无 SLA，可延迟 $\rightarrow$ **可以用 Spot**。
* **总容量：** 12 台服务器。
    * 按比例：65% $\approx$ 8 台 (稳)，35% $\approx$ 4 台 (Spot)。
* **高可用 (HA):** 必须跨 AZ 分布。即使一个 AZ 挂了，关键任务（SLA）不能受影响。
* **成本：** **Pay-for-what-you-consume**，**No long-term commitment** (不能用 RI 或 Savings Plans)。

**2. ⚡ 秒杀思路**
* **计算题：**
    * 需求：8 台稳，4 台 Spot。总共 12 台。
    * 限制：不能有长期承诺 $\rightarrow$ 排除 C (Savings Plans)。
    * 分布：分布在 3 个 AZ 通常比 2 个 AZ 容灾更好。
* **选项分析：**
    * **选项 A (2 AZs):** 每个 AZ 2 OD + 4 Spot。总共 4 OD + 8 Spot。
        * 风险：如果一个 AZ 挂了，只剩 2 台 OD。无法满足 8 台（65%）的 SLA 需求。
    * **选项 B (3 AZs):** 一个 AZ 4 OD，其余 Spot。
        * 风险：这是不平衡分布，也是单点风险。
    * **选项 D (3 AZs):** 每个 AZ 3 OD + 1 Spot。
        * 总计：3 * 3 = 9 台 OD。3 * 1 = 3 台 Spot。
        * 容灾分析：如果一个 AZ 挂了，剩余 2 个 AZ 还有 6 台 OD。虽然略少于 8 台，但比 A 的 2 台好得多。而且 Capacity Reservation (ODCR) 确保了按需实例一定能启动。
        * 比例符合：9 台 OD 覆盖了 65% (8台) 的需求，稍微多一点冗余，满足 SLA。Spot 用于补充。
    * **修正思考：** 题目问 "Most cost-effective"。
        * 需求量化：65% of 12 $\approx$ 7.8 台。也就是必须保证时刻有 8 台机器是稳的。
        * 选项 D 提供了 9 台 OD。这满足了 SLA。Spot 实例作为补充。
        * 选项 A 只有 4 台 OD。绝对不行。
        * 选项 C 用了 Savings Plan，违反 "No long-term commitment"。
    * **锁定 D。**

**3. ✅ 正确选项解析 (选项 D)**
* **ODCR (On-Demand Capacity Reservation):** 确保在特定 AZ 有容量启动按需实例，这是除 RI/SP 外保证容量的唯一方法（虽然不省钱，但题目说要 Pay-as-you-go）。
* **3 AZs 分布:** 3 OD/AZ * 3 = 9 OD。满足 65% 核心负载。

**5. 📚 核心考点:** 混合实例组合策略 (ODCR + Spot) 与 SLA 保障。

---

#### 📝 [26/529] 数据库密码自动轮换 (CloudFormation)

**1. 🕵️‍♂️ 题眼与约束分析**
* **需求：** 强密码、AWS 托管存储、每 90 天轮换、CloudFormation 部署。
* **核心服务：** **AWS Secrets Manager**。

**2. ⚡ 秒杀思路**
* **关键词匹配：**
    * "Rotate database credentials" (轮换凭证) $\rightarrow$ **Secrets Manager**。
    * Systems Manager Parameter Store 虽然也能存密码，但它**没有内置的自动轮换逻辑**（需要自己写 EventBridge + Lambda 甚至更复杂的逻辑）。Secrets Manager 有原生支持。
* **排除法：**
    * 选项 B/D (SSM Parameter Store): 轮换配置复杂，不是 "Least operational overhead"。
    * 选项 C (EventBridge): Secrets Manager 自带 Rotation Schedule 资源，不需要手动创建 EventBridge 规则来触发 Lambda。
    * **选项 A:** Secrets Manager 资源 + Lambda (轮换逻辑) + **RotationSchedule 资源**。这是 CloudFormation 中配置密码轮换的标准三件套。
    * **锁定 A。**

**3. ✅ 正确选项解析 (选项 A)**
* **AWS::SecretsManager::RotationSchedule:** 这是一个 CloudFormation 资源，直接绑定 Secret 和 Lambda，全自动托管轮换任务。

**5. 📚 核心考点:** Secrets Manager 自动轮换的 CloudFormation 实现。

---

#### 📝 [27/529] DynamoDB 无服务器 API (双选)

**1. 🕵️‍♂️ 题眼与约束分析**
* **目标：** 公开 API 访问 DynamoDB。
* **架构：** Serverless + Auto Scaling + HTTPS。
* **选择：** 两个选项。

**2. ⚡ 秒杀思路**
* **模式 1 (直连):** API Gateway 可以直接集成 AWS 服务（DynamoDB），不需要中间的 Lambda。这减少了延迟和成本。
    * **选项 A (REST API + AWS Integration):** 支持 VTL 转换，是很成熟的直连方案。
    * **选项 B (HTTP API + AWS Integration):** HTTP API 也可以直连，但在早期的考试题库中，REST API 的 AWS 集成被视为“标准答案”。不过现在两者都行。但让我们看其他选项。
* **模式 2 (代理):** API Gateway $\rightarrow$ Lambda $\rightarrow$ DynamoDB。这是最通用的模式，逻辑处理灵活。
    * **选项 C (HTTP API + Lambda):** 完全合法的 Serverless 架构，且 HTTP API 比 REST API 便宜。
* **排除法：**
    * 选项 D (Global Accelerator + Lambda@Edge): GA 不能直接触发 Lambda@Edge（L@E 只能由 CloudFront 触发），且 L@E 访问 DDB 网络延迟较高（通常不推荐作为主要 API 后端）。
    * 选项 E (NLB): NLB 转发 Lambda 需要复杂的 Target Group 配置，且 NLB 本身不是纯 Serverless（有每小时固定费），通常用于高性能 TCP/UDP，不是 HTTPS API 的首选。
* **争议点 A vs B vs C:**
    * 题目问 "Which solutions" (复数)。通常一个是直连，一个是代理。
    * **选项 C** (HTTP API + Lambda) 肯定对。
    * **选项 A** (REST API + AWS Integration) 肯定对。
    * **选项 B** (HTTP API + AWS Integration) HTTP API 的 AWS 集成功能较弱（不支持 VTL 转换），如果你需要把 API 请求体转换成 DynamoDB 的 JSON 格式，HTTP API 很难做（通常只能直通）。REST API 有强大的 Mapping Template。所以 **A 比 B 更好**。
    * **结论：** 选 A 和 C。

**3. ✅ 正确选项解析 (选项 A, C)**
* **A:** 利用 API Gateway (REST) 的 VTL 模板直接转换请求到 DynamoDB，去掉了 Lambda 层，极致 Serverless。
* **C:** 标准的 API Gateway (HTTP) + Lambda 模式，简单通用。

**5. 📚 核心考点:** API Gateway 集成模式 (Service Proxy vs Lambda Proxy)。

---

#### 📝 [28/529] 多域名重定向服务

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** 10 个域名，根据 JSON 配置重定向到不同 URL。
* **需求：** HTTP & HTTPS，操作最少。
* **核心组件：** **ALB** 或 **CloudFront** 或 **S3**。但涉及到 HTTPS 和 10 个证书。

**2. ⚡ 秒杀思路**
* **关键点：** HTTPS 需要证书。10 个域名。
* **架构选择：**
    * 选项 A/C/D 都是后端逻辑。但前端谁来扛 HTTPS？
    * 选项 E/F 提到了 CloudFront/ACM。
    * **重定向逻辑：** 输入 URL $\rightarrow$ 查 JSON $\rightarrow$ 返回 301/302。这是一个非常轻量的逻辑，适合 ALB 或 Lambda。
* **最强组合 (ALB):**
    * ALB 支持 **Host-based Routing** (基于主机的路由) 和 **Redirection Actions** (重定向动作)。但题目说重定向规则在 JSON 里，ALB 的规则数有限制（虽然后来增加了，但管理 JSON 还是代码方便）。
    * **最省事方案：** 只有 **ALB** 原生支持 HTTP 和 HTTPS 监听器，并且可以完美集成 **ACM** (SSL 证书)。ALB 后面挂一个 **Lambda** 处理 JSON 逻辑是最简单的。
* **选项筛选（三项）：**
    * 1. 必须要处理 HTTPS $\rightarrow$ **F (ACM 证书)**。
    * 2. 必须要有个入口接收流量 $\rightarrow$ **B (ALB 监听器)**。
    * 3. 必须要有逻辑处理 JSON $\rightarrow$ **C (Lambda)**。ALB 可以把 Lambda 作为目标（Target）。
* **为什么不选 API Gateway (D)?** API Gateway 配置 Custom Domain 需要一个个配，10 个域名配 10 次，还得配证书，比较繁琐。ALB 可以在一个 Listener 上挂一张包含多个 SAN (Subject Alternative Name) 的证书，或者 SNI 挂多张证书，然后统一把流量扔给 Lambda。
* **为什么不选 EC2 (A)?** 运维麻烦。

**3. ✅ 正确选项解析 (选项 B, C, F)**
* **ACM:** 搞定证书。
* **ALB:** 搞定 HTTP/HTTPS 卸载和路由。
* **Lambda:** 搞定业务逻辑（读 JSON 返回 URL）。

**5. 📚 核心考点:** ALB + Lambda 实现轻量级微服务。

---

#### 📝 [29/529] 跨账户成本分摊 (Cost Allocation Tags)

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** Organizations 多账户。
* **目标：** 计算特定标签 (`costCenter`) 资源的成本。
* **核心机制：** **Cost Allocation Tags**。

**2. ⚡ 秒杀思路**
* **关键步骤 1：** 标签打了没用，必须**激活**。在哪里激活？
    * 用户定义标签 (User-Defined Tags) 必须在 **Management Account (管理账户/Payer Account)** 的计费控制台激活，才能在账单里看到。即使资源在成员账户，激活操作是在管理账户做的。（这是一个常见的误区，很多人以为在成员账户激活）。
* **关键步骤 2：** 怎么看报告？
    * AWS Cost and Usage Report (CUR) 是最详细的。
* **秒杀动作：**
    * 选项 B/C 说 "Activate... in the member accounts"。错。标签激活是全局账单层面的操作，在管理账户做。
    * **选项 A:** "Activate... in the organization's management account" + "Use tag breakdowns"。这是标准流程。
* **锁定 A。**

**3. ✅ 正确选项解析 (选项 A)**
* **Activate in Management Account:** 这是铁律。
* **CUR + S3:** 这是分析详细成本的标准方式。

**5. 📚 核心考点:** 成本分配标签的激活位置（管理账户）。

---

#### 📝 [30/529] TGW 自动化连接 (双选)

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** 50 个账户，新账户要自动连 TGW。
* **自动化：** 自动创建 VPC + 自动创建 TGW Attachment。
* **核心工具：** **RAM** (共享 TGW) + **CloudFormation StackSets** (跨账户部署)。

**2. ⚡ 秒杀思路**
* **步骤 1：共享 TGW。** TGW 在管理账户，成员账户要连它，必须先通过 **RAM** 共享出来。
    * $\rightarrow$ **选中 A**。
* **步骤 2：自动化部署。** 要在所有成员账户（包括未来的新账户）执行操作（建 VPC、建 Attachment），**CloudFormation StackSets** 是唯一选择。
    * $\rightarrow$ **选中 C**。
* **排除法：**
    * 选项 B (SCP): SCP 是控制权限的，不能用来共享资源。
    * 选项 D (Peering Attachment): TGW 只有跨 Region 才用 Peering。同 Region 连 VPC 用的是 VPC Attachment。且 Service-Linked Role 是自动的，不需要手动搞那么复杂。
    * 选项 E (Service Catalog): 需要用户去点击触发，不是“自动化”。

**3. ✅ 正确选项解析 (选项 A, C)**
* **RAM:** 将 TGW 共享给整个 Organization，这样成员账户就能看到这个 TGW。
* **StackSets:** 设置为 "Auto-deployment" 模式，当新账户加入 Org 时，StackSet 会自动在该账户运行模板，创建 VPC 和 Attachment。

**5. 📚 核心考点:** 多账户网络自动化的黄金组合 (RAM + StackSets)。

---
**小结：**
这组题目中的 **SSO 集成**、**ALB 静态 IP**、**成本标签激活位置** 都是非常容易踩坑的细节。

准备好下一组了吗？