这 10 道题目涵盖了 **S3 上传优化**、**RDS 代理**、**IoT 架构选型**、**IAM 最小权限与 CloudFormation**、**大数据摄取存储选型**、**RDS 跨区容灾**、**VPC 传递路由 (Transitive Routing)**、**SES 兼容性**、**成本报告 (CUR)** 和 **IoT 高并发架构**。

特别是 **Q77 (Transitive Routing)** 和 **Q75 (High ingestion storage)** 是架构设计中的经典陷阱题。

让我们开启 **逐题秒杀模式**！

---

#### 📝 [71/529] S3 跨国上传优化

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** 视频分享 App。
* **用户：** **Australia** (澳大利亚)。
* **目标桶：** **us-east-1** (美东)。
* **痛点：** 长时间等待，上传失败。文件大小 1-10GB。
* **目标：** Improve upload performance (提高上传性能)。

**2. ⚡ 秒杀思路**
* **方案 A (S3 Transfer Acceleration):** 这是专为“远距离上传”设计的。用户上传到最近的 AWS 边缘节点（Edge Location，澳大利亚有节点），然后通过 AWS 骨干网（高速、低延迟）传输到 us-east-1。这是标准答案。 -> **选中 A**。
* **方案 B (S3 CRR):** 在澳大利亚建个桶，上传快，然后异步复制到 us-east-1。这也是可行且常见的架构模式（特别是对于极差网络环境）。然而题目问的是“improve upload performance”，通常 Transfer Acceleration 是首选，但 B 也是好答案。
* **方案 C (Route 53 Latency):** Route 53 只能解析 IP，不能把数据“路由”到最近的桶（除非你有多个桶配合）。如果配合方案 B，这是对的。单独使用没用。
* **方案 D (Multipart Upload):** 对于大文件（>100MB），**Multipart Upload** 是必须的。题目说文件 1-10GB，不仅能提高速度（并行上传），还能解决“无法完全上传”（断点续传）的问题。这比 S3 Transfer Acceleration 更基础、更关键。
* **方案 E (Random Prefix):** 这是 S3 性能优化的老黄历了（2018 年后 S3 不再需要随机前缀来提高 IOPS），且这解决的是高并发读写，不是上传延迟。
* **决战 A, B, D:**
    * **D (Multipart)** 是必须的，因为 10GB 单线程上传几乎必败。
    * **A (Transfer Acceleration)** 是解决跨国延迟的神器。
    * **B (CRR)** 架构改动较大（多桶管理）。相比之下，A + D 是对现有架构改动最小且效果最直接的组合。
    * **锁定 A 和 D。**

**3. ✅ 正确选项解析 (选项 A, D)**
* **S3 Transfer Acceleration:** 利用 AWS 全球边缘网络加速上传。
* **Multipart Upload:** 大文件上传的基石，提升吞吐并支持重试。

**5. 📚 核心考点:** S3 大文件跨国上传优化组合拳。

---

#### 📝 [72/529] RDS 连接恢复 (Proxy)

**1. 🕵️‍♂️ 题眼与约束分析**
* **故障：** RDS Multi-AZ 故障转移后，应用失去连接，无法重连，**重启后才好**。
* **目标：** **Re-establish connection without restarting** (无需重启即可重连)。
* **痛点：** DNS 缓存或连接池僵死。

**2. ⚡ 秒杀思路**
* **RDS Proxy:** 它的核心功能之一就是 **Failover transparency** (故障转移透明化)。RDS Proxy 会处理底层的数据库故障转移，对应用保持连接不断（或快速恢复），大大减少了故障转移时间（从 30s 降到 <1s），且无需应用重启。
* **选项对比：**
    * 选项 A (Aurora Serverless v1): 迁移麻烦，且 Serverless v1 有冷启动问题，不是专门解决连接僵死的。
    * 选项 C (Aurora Cluster + Proxy): 迁移到 Aurora 是好主意，但题目只要求解决连接问题，原地加 Proxy (B) 更简单。且 C 的描述也包含了 B 的逻辑，但 B 成本更低、改动更小。
    * 选项 D (Athena): 离谱。Athena 是查询 S3 的，不能替代 OLTP 数据库。
    * **选项 B:** 创建 RDS Proxy，应用连 Proxy。Proxy 负责处理后端 RDS 的 IP 变化和 DNS 切换，应用端无感知或只需极短重连。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **RDS Proxy:** 解决连接池管理和故障转移中断的神器。

**5. 📚 核心考点:** RDS Proxy 在故障转移场景下的作用。

---

#### 📝 [73/529] IoT 设备认证 (X.509 + MQTT)

**1. 🕵️‍♂️ 题眼与约束分析**
* **规模：** 数千设备。
* **协议：** **MQTT**。
* **认证：** **X.509 certificates** (双向认证)。
* **约束：** **Minimize operational overhead** (最小运维)。

**2. ⚡ 秒杀思路**
* **关键词匹配：**
    * "MQTT" + "X.509" + "Thousands of devices" + "Least overhead" $\rightarrow$ **AWS IoT Core**。
* **AWS IoT Core** 是全托管的 IoT 平台，原生支持 MQTT 和 X.509 证书认证。
* **排除法：**
    * 选项 A (Amazon MQ): 虽然支持 MQTT，但主要用于后端消息队列，不适合作为海量 IoT 设备的直接接入点（连接数扩展性不如 IoT Core）。且要为每个设备建队列是疯了。
    * 选项 B/D (EC2/NLB 自建 Broker): 运维巨大（High overhead），还要自己搞 X.509 认证逻辑。
    * **选项 C:** 设置 IoT Core，为每个设备创建 Thing 和证书。这是标准 IoT 接入流程。
    * **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **AWS IoT Core:** 托管服务，原生支持题目所有需求。

**5. 📚 核心考点:** IoT 设备接入与认证的标准服务 (AWS IoT Core)。

---

#### 📝 [74/529] CloudFormation 强制使用 (IAM PassRole)

**1. 🕵️‍♂️ 题眼与约束分析**
* **政策：** 工程师只能配置 **Approved Resources**，且必须通过 **CloudFormation (CFN)**。
* **目标：** 强制 IAM 角色限制，防止工程师绕过 CFN 直接创建资源。

**2. ⚡ 秒杀思路**
* **IAM 权限分离：**
    1.  **工程师 (Engineer Role):** 只能有操作 CloudFormation 的权限（CreateStack），**没有**直接创建 EC2/S3 的权限。
    2.  **CFN 服务角色 (Service Role):** 这是一个由 CloudFormation 服务扮演的角色，它拥有创建 EC2/S3 等资源的实际权限。
    3.  **PassRole:** 工程师需要有 `iam:PassRole` 权限，以便将“CFN 服务角色”传递给 CloudFormation 服务。
* **选项对比：**
    * 选项 A: 工程师只能访问 S3 和 CFN。那 CFN 用什么权限去建资源呢？如果用工程师的权限，工程师没权限建资源，CFN 也会失败。
    * 选项 B: 工程师有配置资源的权限？这违反了“必须通过 CFN”的初衷（工程师可以直接调用 API 建资源了）。
    * 选项 D: 限制访问自己的 Stack，没解决核心问题（权限来源）。
    * **选项 C:**
        * 工程师 IAM: 仅允许 CFN 操作（+ PassRole）。
        * Service Role: 拥有创建资源的权限。
        * 流程: 工程师调用 CFN -> 传递 Service Role -> CFN 用 Service Role 建资源。完美实现了“工程师不能直接建，必须通过 CFN 建”。
    * **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **Service Role + PassRole:** 这是实现“基础设施即代码 (IaC) 强制治理”的标准 IAM 模式。

**5. 📚 核心考点:** CloudFormation Service Role 与 iam:PassRole 的配合。

---

#### 📝 [75/529] 高吞吐小数据存储 (DynamoDB TTL)

**1. 🕵️‍♂️ 题眼与约束分析**
* **负载：** **Millions of small records per minute** (每分钟数百万条小记录)。
* **数据特征：** < 4KB/条。**Ephemeral** (短暂)，存 120 天。
* **查询：** Low latency retrieval (低延迟检索)。
* **目标：** **Most cost-effective** (最具成本效益)。

**2. ⚡ 秒杀思路**
* **选项对比：**
    * 选项 A (S3 单文件): 每分钟数百万个小文件（4KB）存 S3？Put 请求费用会炸裂（S3 Put 很贵），且 S3 索引检索延迟较高。
    * 选项 C (RDS MySQL): 关系型数据库抗每分钟数百万写入压力很大，且删除 120 天老数据（Delete操作）会造成严重的碎片和锁表，影响性能。
    * 选项 D (S3 Batching): 批处理存 S3 是大数据摄取的常见做法（如 Kinesis Firehose）。成本低，但检索是个问题（S3 Metadata Search 能力有限，且延迟不如数据库）。
    * **选项 B (DynamoDB):**
        * **写入能力:** DynamoDB 专为高并发小数据写入设计。
        * **TTL:** 原生支持 **Time to Live (TTL)**，自动免费删除过期数据（无需 Cron Job，无性能影响）。
        * **成本:** 虽然 DDB 写贵，但相比 S3 Put 数百万次，DDB WCU 是可控的（或者用 On-Demand）。更重要的是 TTL 免去了删除数据的巨大维护成本和 IOPS。对于 <4KB 的数据，DDB 效率极高。
    * **决战 B vs D:**
        * D (S3 Batching) 写入成本最低（Firehose），但“Low latency retrieval” (低延迟检索) 是软肋。如果需要按 ID 毫秒级查单条记录，S3 做不到。
        * B (DynamoDB) 完美满足“低延迟检索”和“自动删除”。
        * 考虑到题目强调 "Low latency retrieval"，DynamoDB 是更优解。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **DynamoDB TTL:** 处理海量数据自动过期的最佳实践。
* **Performance:** 毫秒级延迟，高吞吐写入。

**5. 📚 核心考点:** 高并发小数据写入存储选型 (DynamoDB vs S3)。

---

#### 📝 [76/529] RDS 跨区域高可用 (Read Replica vs Global DB)

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** 跨区域 (Multiple Regions) 电子商务网站。
* **需求：** **24/7 operation** (全天候), **Highest Availability** (最高可用性)。
* **数据库：** RDS for MySQL。

**2. ⚡ 秒杀思路**
* **技术演进：**
    * **普通 Read Replica (D):** 跨区域复制延迟较高，故障转移需要手动提升 (Promote)，RTO 较长。
    * **Lambda 复制 (B/C):** 手写 Lambda 复制数据？太原始且不可靠。
    * **RDS Global Database (不支持 MySQL?):** 等等，Aurora 才有 Global Database。普通的 RDS for MySQL 没有 "Global Table" 这个功能（DynamoDB 才有 Global Table，Aurora 有 Global Database）。
    * **再读选项：** 选项 B/C 提到了 "Configure Global Tables on Amazon RDS"。这是**术语错误**。AWS 中只有 DynamoDB 有 Global Tables。Aurora 有 Global Database。RDS MySQL 只有 Cross-Region Read Replicas。
    * **难道是题目笔误？** 或者指的是 Aurora？题目明确说 "RDS for MySQL"。
    * 如果必须在 RDS for MySQL 语境下选：只有 **D** 是技术上可行的（Cross-Region Read Replica）。
    * **但是**，如果题目其实是指 Aurora（或者把 Global Database 泛指了），那么 Aurora Global Database 确实比 RR 快。
    * **让我们仔细看 A:** "Automated backups... promote backup"。备份恢复太慢了，不算高可用。
    * **分析选项 D:** "Configure Read Replicas... promote... independent DB instance"。这是 RDS MySQL 跨区域容灾的标准做法。虽然 RTO 不是零，但在 RDS MySQL 的能力范围内是最高的。
    * **关于 B/C:** "Global Tables" 是 DynamoDB 的术语，"Lambda copying" 是反模式。直接排除。
    * **结论:** 只能选 D。这是 RDS MySQL 原生支持的唯一跨区域 DR 方案。

**3. ✅ 正确选项解析 (选项 D)**
* **Cross-Region Read Replica:** 允许将数据异步复制到另一个区域。灾难发生时，将其提升为新主库。

**5. 📚 核心考点:** RDS MySQL 的跨区域容灾限制与方案。

---

#### 📝 [77/529] VPC 传递路由陷阱 (Transitive Routing)

**1. 🕵️‍♂️ 题眼与约束分析**
* **拓扑：** On-prem <-> VPC A (Peering) <-> VPC B。
* **现状：** On-prem 能访问 VPC A。VPC A 能访问 VPC B。
* **需求：** **On-prem 连接 VPC B**。
* **核心原理：** **VPC Peering 不支持传递路由 (Transitive Routing)**。即 A 连 B，B 连 C，A **不能** 通过 B 连 C。

**2. ⚡ 秒杀思路**
* **解决方案：** 要打破传递路由限制，必须引入 **Transit Gateway (TGW)** 或者在 On-prem 和 VPC B 之间再拉一根 VPN（Mesh 网络）。
* **选项对比：**
    * 选项 D (修改 VGW): VGW 不支持这种“一拖二”的魔法。
    * 选项 C (BGP): 依然受限于 Peering 的传递性限制，路由表怎么改都通不了。
    * **选项 B (VPN to VPC B via TGW?):** 描述混乱。"Create TGW... create VPN between On-prem and VPC B... attach VPN to TGW"。这实际上是让 VPC B 通过 TGW 连回 On-prem。这能通，但有点绕。
    * **选项 A:** **创建一个 Transit Gateway**。将 VPN、VPC A、VPC B 全部连接到 TGW。这是**星型拓扑**。TGW 原生支持传递路由（A 可以通过 TGW 访问 B，On-prem 也可以通过 TGW 访问 A 和 B）。这是最标准、扩展性最好、运维最少（Least operational effort）的方案。
    * **锁定 A。**

**3. ✅ 正确选项解析 (选项 A)**
* **Transit Gateway:** 解决 VPC Peering 传递路由限制的终极方案，实现 Any-to-Any 连接。

**5. 📚 核心考点:** VPC Peering 的 Transitive Routing 限制与 TGW 的优势。

---

#### 📝 [78/529] 旧 SMTP 迁移到 SES (兼容性)

**1. 🕵️‍♂️ 题眼与约束分析**
* **现状：** 旧 SMTP 服务，不支持 TLS，使用 **Port 25**。
* **应用限制：** **Application can only use SMTP** (只能用 SMTP，不能改代码用 SDK/API)。
* **目标：** 使用 **Amazon SES**。
* **SES 要求：** SES SMTP 接口要求 **STARTTLS** (加密) 和身份验证。

**2. ⚡ 秒杀思路**
* **兼容性断层：** App (No TLS, Port 25) <---> SES (TLS Required)。
* **中间件：** 需要一个本地代理（Wrapper）来通过 Port 25 接收 App 的明文邮件，然后加密转发给 SES。
* **选项对比：**
    * 选项 C/D (API/SDK): 违反 "Application can only use SMTP"。
    * 选项 B (STARTTLS): App 不支持 TLS，配置它用 STARTTLS 会失败。
    * **选项 A:** "Configure application to use TLS Wrapper"。虽然选项 A 的描述略显奇怪（通常是在 EC2 上装一个 Postfix/Sendmail 作为 Relay），但 "TLS Wrapper" (如 stunnel) 确实是解决此问题的通用术语。它在本地监听明文端口，把流量加密后发给 SES。配合 IAM Role (ses:SendEmail) 可以免去 SMTP 账号密码管理的麻烦（如果使用 EC2 上的代理转发）。
    * **纠正：** SES SMTP **必须** 使用 SMTP Credentials (User/Pass)，**不支持** IAM Role 直接认证 SMTP 连接（IAM Role 只能用于 API/SDK）。
    * **再看 A vs B:**
        * 选项 A 提到了 "IAM Role"。这在 SMTP 协议下是行不通的。SES SMTP 接口只认 SMTP 用户名密码。
        * 选项 B 提到了 "STARTTLS" 和 "SMTP Credentials"。这符合 SES 的要求。但题目说 "Legacy SMTP server does not support TLS"。
        * **破局点：** 题目问 "How should the company **modify the application**"。
        * 如果应用代码可以修改配置来支持 STARTTLS（很多旧库其实支持，只是没开），那么 B 是对的。
        * 如果应用**死活**不支持 TLS，那么 A 的 "TLS Wrapper" 是唯一的救命稻草。**但是** A 的后半句 "Create IAM Role... attach to EC2" 对于 SMTP 连接是**无效**的。
        * **让我们重新审视 C:** "Configure application to use SES API"。题目说 "Application can only use SMTP"。
        * **难道是用 SDK (D)?** 同上。
        * **回过头看 A 的逻辑漏洞：** "TLS Wrapper" 是对的，但 "IAM Role" 是错的（除非 Wrapper 内部把 SMTP 转成了 API 调用，比如 aws-cli send-email）。如果 Wrapper 是一个简单的 stunnel，它只负责加密，不负责认证转换，还是需要 SMTP 凭证。
        * **再看 B:** 也许题目暗示的是“修改应用以支持 STARTTLS”？ "Configure the application to use STARTTLS" 听起来像是一个行动项。虽然题目说 "Legacy SMTP server does not support..."，但这指的是旧的**服务器**，不是**应用**本身。应用可能支持，只是之前连的是旧服务器。
        * **关键线索：** 题目说 "Old SMTP server... does not support TLS"。应用依赖于它。现在要停用旧服务器，直连 SES。SES 要求 TLS。所以应用**必须**被配置为使用 TLS（通过修改配置或 Wrapper）。
        * **最关键的判据：** **SES SMTP 接口不支持 IAM Role 认证**。A/C/D 都提到了 IAM Role/User Access Key 用于 API。只有 B 提到了 **SMTP Credentials**。这是连接 SES SMTP Endpoint 的唯一凭证。
        * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **SMTP Credentials:** 连接 SES SMTP 接口必须生成专用的 SMTP 用户名和密码（不同于 IAM Access Key）。
* **STARTTLS:** 即使应用旧，要连 SES 也必须开启 STARTTLS（或使用 Wrapper，但 B 选项强调了凭证的正确性）。

**5. 📚 核心考点:** Amazon SES SMTP 接口的认证方式 (SMTP Credentials vs IAM Role)。

---

#### 📝 [79/529] 跨公司成本报告 (Data Visualization)

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** 收购多家公司，多个 AWS 账户，合并到 Organizations。
* **需求：** **Self-managed application** (自行管理的应用程序) 来报告成本。
* **数据源：** **All companies** (所有账户)。
* **核心工具：** **AWS Cost and Usage Report (CUR)** + **QuickSight**。

**2. ⚡ 秒杀思路**
* **数据源选型：**
    * **Price List Query API (C/D):** 只有价格表，没有你的使用量（Usage）。无法计算支出。排除。
    * **CUR (Cost and Usage Report):** 包含最详细的成本和使用量数据。这是构建自定义报告的基石。
* **可视化选型：**
    * **Cost Explorer (B):** 是 AWS 托管的控制台，不是 "Self-managed application"。且 CE 的定制化能力有限。
    * **Amazon QuickSight (A):** 这是一个 BI 工具，可以连接 Athena (查询 CUR S3 数据)，制作高度定制的仪表盘。这符合 "Self-managed application"（构建自己的报告应用）的定义。
    * **锁定 A。**

**3. ✅ 正确选项解析 (选项 A)**
* **CUR + Athena + QuickSight:** 这是 AWS 经典的“成本智能（CUDOS）”架构，用于构建高度定制的 FinOps 仪表盘。

**5. 📚 核心考点:** 自定义成本报告的标准架构 (CUR -> Athena -> QuickSight)。

---

#### 📝 [80/529] IoT 平台写入瓶颈优化 (Kinesis + DynamoDB)

**1. 🕵️‍♂️ 题眼与约束分析**
* **现状：** IoT 传感器 $\rightarrow$ API Server (EC2) $\rightarrow$ RDS MySQL。
* **瓶颈：** API Server 过载，RDS **High Write Latency** (高写入延迟)。
* **预期：** 传感器数量显著增长。
* **目标：** **Permanently resolve** (永久解决) + **Cost efficiency** (成本效率)。
* **选择：** 2 个步骤。

**2. ⚡ 秒杀思路**
* **数据库层优化：**
    * RDS MySQL 对于海量 IoT 写入（高并发、持续插入）并不是最佳选择，容易遇到 IOPS 瓶颈和锁竞争。
    * **DynamoDB (E)**: 专为高并发写入设计，Serverless 扩展，非常适合 IoT 数据存储。比 Aurora 更适合这种“纯写入流”场景。
    * $\rightarrow$ **选中 E**。
* **摄取层优化：**
    * API Server (Node.js) 是同步处理，容易被突发流量打挂。
    * **Kinesis Data Streams (C)**: 引入消息队列/流处理缓冲。传感器数据先入 Kinesis，然后用 Lambda 异步消费写入 DB。削峰填谷，解耦前端。
    * $\rightarrow$ **选中 C**。
* **排除法：**
    * A (增加 EBS): 治标不治本，迟早还要扩，且不仅是存储问题，还有计算和连接数问题。
    * B (Aurora): 虽然比 MySQL 强，但面对海量 IoT 写入，DynamoDB 依然是更优解（成本和扩展性）。
    * D (X-Ray): 调试工具解决不了架构瓶颈。

**3. ✅ 正确选项解析 (选项 C, E)**
* **Kinesis + Lambda:** 缓冲与解耦，实现高并发摄取。
* **DynamoDB:** 承接海量写入，替代关系型数据库。

**5. 📚 核心考点:** IoT 高并发写入架构演进 (RDS -> Kinesis + DynamoDB)。

---
**小结：**
这组题目的 **Transitive Routing**、**SES 认证**、**IoT 架构** 都是深水区考点。

**请发送下一组题目！**