这 10 道题目（包含 1 道关于 WorkSpaces 存储扩容的题目）涵盖了 **SQS 死信队列排查**、**API Gateway 私有化**、**S3 全球加速**、**FSx 自动扩容**、**SFTP 现代化架构**、**Aurora 跨区域灾备**、**敏感数据脱敏 (Glue)**、**AWS Elastic Disaster Recovery (DRS)**、**跨账户审计访问**、**DAX 加速**。

特别是 **Q148 (Elastic Disaster Recovery)** 和 **Q144 (FSx Capacity Mgmt)** 是 SAP 考试中关于运维自动化的经典考点。

让我们开启 **逐题秒杀模式**！

---

#### 📝 [141/529] SQS 消息处理失败排查 (Visibility Timeout)

**1. 🕵️‍♂️ 题眼与约束分析**
* **处理时间：** 30 分钟。
* **Visibility Timeout:** 1 小时 (60 分钟)。
* **Retry Policy:** maxReceiveCount = 1 (失败一次就进死信队列)。
* **现象：** 消息进入 DLQ (死信队列)，但**应用日志无错误**。
* **推断：** 既然日志无错，说明代码没抛异常。为什么消息被认为“处理失败”了？
* **核心机制：** SQS 认为消息失败的唯一标准是：**Visibility Timeout 到期了，但消息还没被删除**。或者消费者主动 NACK。
* **矛盾点：** 既然处理只需 30 分钟，Timeout 是 60 分钟，理论上够用。为什么还会进 DLQ？
* **隐藏因素：** Auto Scaling Group **Scale-in** (缩容)。
* **场景重现：** 实例正在处理视频（需要30分钟）。第 15 分钟时，队列变空了，ASG 触发缩容，把这台正在干活的实例**终止 (Terminate)** 了。实例被杀，处理中断（还没来得及删消息）。Visibility Timeout (60分钟) 到期后，消息重新可见。由于 maxReceiveCount=1，消息立刻被送入 DLQ。
* **日志无错：** 因为实例被强杀，日志可能没来得及写（或写在本地盘随实例一起没了）。

**2. ⚡ 秒杀思路**
* **防止处理中断：** 需要告诉 ASG “我正在干活，别杀我”。这就是 **Instance Scale-in Protection** (缩容保护) 或 **Lifecycle Hook**。
* **选项对比：**
    * 选项 A (Termination Protection): 这是防止用户手动 API 误删的，对 ASG 缩容操作无效。
    * 选项 B (Visibility Timeout): 改成 3 小时没用，因为实例已经被杀了。
    * 选项 D (maxReceiveCount=0): 这会导致所有消息直接进 DLQ，更糟。
    * **选项 C:** **Configure scale-in protection** (配置缩容保护)。Worker 在领取任务时开启保护，处理完任务关闭保护。这样 ASG 就不会在任务处理中途杀掉实例。
    * **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **Scale-in Protection:** 专门用于长任务 Worker，防止 ASG 缩容误杀。

**4. ❌ 错误选项排查**
* **选项 A:** 这是一个常见的混淆点。EC2 控制台的 "Change termination protection" 只能防 API 调用，防不住 ASG。ASG 有特权。

**5. 📚 核心考点:** SQS 长任务处理与 ASG 缩容的冲突解决。

---

#### 📝 [142/529] API Gateway 私有化 (Private Endpoint)

**1. 🕵️‍♂️ 题眼与约束分析**
* **现状：** Regional API Gateway。
* **需求：** **Make APIs accessible only from the VPC** (仅限 VPC 访问)。
* **约束：** **Least effort** (最少工作量)。

**2. ⚡ 秒杀思路**
* **API Gateway 类型：** API Gateway 支持三种端点类型：Edge, Regional, **Private**。
* **Private API:** 只能通过 **Interface VPC Endpoint** 访问。这是专门为 VPC 内网访问设计的。
* **操作步骤：**
    1.  将 API 类型从 Regional 改为 Private。
    2.  在 VPC 创建 Interface Endpoint。
    3.  配置 Resource Policy (只允许该 Endpoint 访问)。
* **选项对比：**
    * 选项 A (Internal ALB): API Gateway 前面挂 ALB？这是反模式（ALB Target Group 支持 Lambda，但没必要经过 API Gateway 再去调 ALB）。或者把 API Gateway 放在 ALB 后面？API Gateway 是托管服务，不在你 VPC 里，ALB 连不上它（除非 Private API）。架构复杂。
    * 选项 B (Route 53 CNAME): 只是改 DNS，无法阻止公网访问（Regional API 默认公网可达）。
    * 选项 D (EC2 Apache 代理): 自建代理，运维重。
    * **选项 C:** 直接利用 API Gateway 原生功能 **Private Endpoint**。最简单，最标准。
    * **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **Private API + VPC Endpoint:** 确保流量只在私有网络内流转，公网无法解析或访问。

**5. 📚 核心考点:** API Gateway 私有化配置。

---

#### 📝 [143/529] S3 跨区域访问加速 (2选)

**1. 🕵️‍♂️ 题眼与约束分析**
* **主区域：** eu-west-1 (频繁更新)。
* **用户：** **us-east-1** (北美用户) 访问慢。
* **架构：** CloudFront $\rightarrow$ S3。
* **目标：** Resolve performance issues for us-east-1。

**2. ⚡ 秒杀思路**
* **分析慢的原因：** 虽然用了 CloudFront，但如果 S3 源站只有 eu-west-1，当内容未命中缓存（Cache Miss）或动态更新时，CloudFront 边缘节点仍需回源到欧洲，延迟高。
* **优化策略：** 在用户附近 (us-east-1) 增加一个 S3 副本源站。
* **组合拳：**
    1.  **数据同步：** **S3 Cross-Region Replication (CRR)** 将数据从 eu-west-1 实时复制到 us-east-1。 $\rightarrow$ **选中 B**。
    2.  **流量路由：** 让北美用户的请求指向 us-east-1 的桶。
        * 怎么做？CloudFront 支持 **Lambda@Edge**。
        * 在 **Origin Request** 触发器中，检查用户位置（CloudFront Headers），如果是北美，修改 Origin 域名为 us-east-1 的桶。
        * $\rightarrow$ **选中 D**。
* **排除法：**
    * 选项 A/E (Global Accelerator): CloudFront 本身就是全球加速，前面加 GA 没意义。且 GA 不支持直接作为 S3 前端（除非 S3 是静态网站托管，但那样就不用 CloudFront 了？不，CloudFront 才是 CDN 王道）。
    * 选项 C (Transfer Acceleration): 这是加速**上传**的，题目是“View weather maps” (下载/查看)。
* **锁定 B, D。**

**3. ✅ 正确选项解析 (选项 B, D)**
* **S3 CRR:** 数据物理本地化。
* **Lambda@Edge:** 智能路由，将用户导向最近的源站（Origin Selection）。

**5. 📚 核心考点:** 基于 Lambda@Edge 的多源站（Multi-Origin）路由架构。

---

#### 📝 [144/529] FSx 容量自动扩容 (EventBridge + Lambda)

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** WorkSpaces User Profiles stored on FSx for Windows。
* **故障：** **Full capacity** (满了)。
* **需求：**
    1.  Regain access (扩容)。
    2.  **Prevent recurring** (防止再犯 -> 自动化)。
* **技术点：** FSx 支持在线扩容。

**2. ⚡ 秒杀思路**
* **自动化扩容流程：**
    * 监控：CloudWatch Metric (`FreeStorageCapacity`)。
    * 触发：Alarm $\rightarrow$ 动作。
    * 动作：调用 API `UpdateFileSystem` 增加容量。
* **选项对比：**
    * 选项 A (Migrate to Lustre): Lustre 是高性能计算用的，不是给 Windows 用户配置文件用的（不支持 SMB/AD）。
    * 选项 C (Step Functions): 监控指标触发 Step Functions？CloudWatch Alarm 通常触发 SNS 或 Lambda。虽然 SF 也能做，但 B 选项更直接。且 C 没提具体怎么触发（Using CW metrics...）。
    * 选项 D (Create another FSx): 分流用户？管理极其复杂（AD 组策略重定向），治标不治本。
    * **选项 B:** 使用 **update-file-system** 命令（解决当下）。实施 **CloudWatch Metric** 监控空闲空间 $\rightarrow$ **EventBridge/Alarm** $\rightarrow$ **Lambda** 自动扩容。这是标准的自动化运维方案。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **FSx Online Scaling:** 支持不中断业务扩容。
* **Automated Remediation:** 监控 + Lambda 闭环。

**5. 📚 核心考点:** FSx for Windows 的容量管理与自动化。

---

#### 📝 [145/529] SFTP 现代化 (Transfer Family + S3 Event)

**1. 🕵️‍♂️ 题眼与约束分析**
* **现状：** 手持设备 (FTP) $\rightarrow$ EC2 (处理/加元数据) $\rightarrow$ S3。
* **痛点：** EC2 内存溢出、连接拒绝、单点故障。
* **限制：** **Handheld devices cannot be modified** (设备只能用 FTP)。
* **需求：** Maximize scalability, ensure updates。

**2. ⚡ 秒杀思路**
* **FTP 层：** 既然不能改设备，必须提供 FTP 接口。EC2 自建 FTP 维护难。**AWS Transfer Family** (支持 FTP/SFTP) 是最佳托管替代品，直接对接 S3。
* **处理层：**
    * 现在的逻辑是：上传 -> EC2 处理 -> S3。
    * Transfer Family 逻辑：上传 -> 直落 S3。
    * 那么“处理/加元数据”怎么办？
    * 使用 **S3 Event Notifications** 触发 **Lambda**。
    * 流程：设备 FTP 上传 -> Transfer Family -> S3 (触发事件) -> Lambda (读取文件，查库，加元数据，更新系统)。
* **选项对比：**
    * 选项 A (EC2 ASG): 只是扩容了 EC2，没解决 FTP 服务本身的脆弱性（连接保持、Session 管理）。且 Transfer Family 更 Scalable。
    * 选项 B (Transfer to EFS): EFS 挂载给 EC2 处理？还是依赖 EC2。
    * 选项 D (SQS): 题目说 "Handheld devices cannot be modified"。D 选项说 "Update handhelds to put directly to S3"。这直接违反约束。
    * **选项 C:** Transfer Family (FTP) $\rightarrow$ S3 $\rightarrow$ SNS (or directly Lambda) $\rightarrow$ Lambda。这是完美的 Serverless 事件驱动架构，去除了 EC2 瓶颈。
    * **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **AWS Transfer Family:** 兼容旧设备的 FTP 协议。
* **S3 Event -> Lambda:** 异步处理，无限扩展。

**5. 📚 核心考点:** 遗留 FTP 服务的 Serverless 现代化改造。

---

#### 📝 [146/529] Aurora 跨区域恢复 (Global DB / Replica)

**1. 🕵️‍♂️ 题眼与约束分析**
* **App:** ECS Fargate。
* **DB:** Aurora MySQL。
* **需求：** **Recover to different region** (跨区恢复)。
* **关键约束：** **No data loss** (RPO = 0, 零数据丢失) ? 或者是 **Minimize data loss**? 题目说 "In case of failure, no data can be lost"。
* **注意：** 跨区域完全零丢失（RPO=0）在物理上是非常难的（光速延迟）。但在 AWS 选项语境下，我们要找最接近的。
* **选项分析：**
    * 选项 B/C (DataSync/DMS): 都是异步复制，有延迟，会有数据丢失。
    * 选项 D (DLM Snapshot): 快照备份 RPO 是分钟/小时级的，丢失数据多。
    * **选项 A:** **Aurora Replicas (Global Database)**。Aurora Global Database 使用存储层复制，延迟极低（通常 < 1秒）。虽然理论上异步复制在灾难瞬间可能丢最后几百毫秒的数据，但这已经是 AWS 提供的 RPO 最小的跨区域方案了。而且题目问的是 "Least operational overhead"。
    * **等等，** 题目真的说 "No data can be lost" 吗？这是非常苛刻的。
    * 如果必须 RPO=0，通常需要同步复制（Synchronous Replication）。AWS 只有 **Multi-AZ** 是同步的（同区域）。跨区域没有同步复制服务（延迟太高应用受不了）。
    * **也许题目是 "Minimize data loss"?**
    * 让我们再看选项。DataSync 是文件级的，不适合数据库。DMS 是逻辑复制，慢。DLM 是快照，更慢。
    * 只有 **Aurora Replicas (Global Database)** 是数据库原生的、最高效的复制。在 SAP 考试中，面对跨区域 DR，Aurora Global Database 就是标准答案。
    * **锁定 A。**

**3. ✅ 正确选项解析 (选项 A)**
* **Aurora Global Database:** 物理层复制，低延迟，快速故障转移。

**5. 📚 核心考点:** Aurora 跨区域灾备的最佳实践。

---

#### 📝 [147/529] 敏感数据脱敏 (Glue vs Lambda)

**1. 🕵️‍♂️ 题眼与约束分析**
* **输入：** 5000 records/15min (吞吐量不大)。明文 CSV。
* **敏感数据：** **PAN** (信用卡号)。
* **需求：**
    1.  **Mask PAN** (脱敏)。
    2.  Remove/Merge fields (转换)。
    3.  Convert to JSON (格式转换)。
    4.  **Easy to scale** (易扩展，未来有新源)。
* **选项对比：**
    * **A (Lambda 串联):** 这种复杂的 ETL 逻辑（提取、清洗、转换）全部手写 Lambda 代码？维护成本高，且对于数据结构的变更（Schema Evolution）支持不好。
    * **B (Fargate):** 自己写容器处理？也是造轮子。
    * **D (EMR):** 杀鸡用牛刀。5000条记录/15分钟，启动一个 EMR 集群太慢且贵。
    * **C (Glue):** **AWS Glue** 是专为 ETL 设计的。
        * **Crawler:** 自动识别 Schema（适应未来新数据源）。
        * **ETL Job:** 内置转换（FindMatches, ResolveChoice 等），且 Glue 脚本（PySpark/Python）处理 PAN 脱敏、格式转换非常容易。
        * **Trigger:** S3 Event -> Lambda -> Start Glue Job。
        * 这是最符合 "Easy to scale" 和 "Data Transformation" 场景的托管服务。
    * **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **AWS Glue:** 托管 ETL，擅长 Schema 发现和复杂数据转换。

**5. 📚 核心考点:** ETL 任务选型 (Glue vs Lambda)。

---

#### 📝 [148/529] 本地业务连续性 (AWS Elastic Disaster Recovery)

**1. 🕵️‍♂️ 题眼与约束分析**
* **源端：** 物理服务器 (Physical Servers)，运行 App + MySQL。
* **目标：** Business Continuity / DR on AWS。
* **约束：** **Least operational overhead** (最少运维)。

**2. ⚡ 秒杀思路**
* **工具选型：**
    * **AWS Elastic Disaster Recovery (AWS DRS):** (前身是 CloudEndure)。这是 AWS 官方推荐的物理机/虚拟机到 AWS 的 DR 工具。它通过安装 Agent，进行块级别（Block-level）的持续复制。RPO 是秒级，RTO 是分钟级。平时只需由轻量级复制服务器运行，故障时才启动全尺寸实例。
    * **选项 A (Replication Agent):** 描述很像 DRS，但没提服务名字，只说 "Install AWS replication agent... launch test instances"。这是 DRS 的工作方式。
    * **选项 B:** 明确提到了 **"Initialize AWS Elastic Disaster Recovery"**。这比 A 更准确。DRS 支持故障演练（Failover/Failback）。
    * **选项 C (DMS + SCT):** 只是迁移数据库。应用服务器呢？还要手动装软件？太麻烦。
    * **选项 D (Storage Gateway):** 卷网关只能复制数据卷，不能复制操作系统状态（Boot Volume）。你需要手动重装 OS 和 App，RTO 极长。
* **A vs B:**
    * A 描述的是通用的“复制代理”，B 明确指名 **AWS Elastic Disaster Recovery**。在 SAP 考试中，指名道姓的服务通常是考点。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **AWS DRS:** 物理机/VM 的全系统（OS+Data）持续复制 DR 方案。

**5. 📚 核心考点:** 本地到云的灾难恢复标准工具 (AWS DRS)。

---

#### 📝 [149/529] 外部审计访问 (Cross-Account Role)

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** 外部审计师 (External Auditor) $\rightarrow$ 公司 AWS 账户。
* **审计师身份：** **Has their own AWS account** (有自己的 AWS 账户)。
* **需求：** **Secure, Read-only access**。
* **合规：** AWS Security Best Practices。

**2. ⚡ 秒杀思路**
* **跨账户最佳实践：** 永远不要给外部人员创建 IAM User (C/D)。**Use IAM Roles**。
* **安全加固：** 对于第三方（Third-party）访问，必须使用 **External ID** 来防止混淆代理人问题。
* **选项对比：**
    * 选项 A (Resource Policy): 不是所有资源都支持 Resource Policy。且管理分散。
    * 选项 C/D (IAM User): 违反“不共享长期凭证”的最佳实践。
    * **选项 B:** 创建 **IAM Role**，信任审计师的账户 ID。附加 ReadOnlyAccess 策略。配置 **External ID**。审计师在他们自己的账户里 Assume 这个 Role。完美。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **Cross-Account Role:** 第三方访问标准模式。
* **External ID:** 必选的安全增强。

**5. 📚 核心考点:** 第三方审计访问的最佳实践。

---

#### 📝 [150/529] 交易平台低延迟 (DAX Cluster)

**1. 🕵️‍♂️ 题眼与约束分析**
* **应用：** 交易平台，**Latency-sensitive** (延迟敏感)。
* **后端：** DynamoDB (On-demand)。
* **需求：** Improve performance, **High Availability** (高可用)。
* **工具：** DynamoDB Accelerator (DAX)。

**2. ⚡ 秒杀思路**
* **DAX 模式：**
    * DAX 是 **Write-through** (直写) 缓存。这意味着应用程序应该**读写都经过 DAX**。
    * 如果只读 DAX，写直接写 DB (Write-around)，那么 DAX 里的缓存不会更新，会导致数据不一致（Stale Data）。对于交易平台，数据一致性至关重要。所以必须通过 DAX 写入（DAX 会自动同步写入后端 DDB）。
    * $\rightarrow$ **排除 B, C, D** (Direct write to DynamoDB)。
    * $\rightarrow$ **选中 A** (Use DAX for reads and writes)。
* **高可用 (HA):**
    * HA 需要至少 **2 个节点** (Multi-AZ)。
    * 选项 A (Two nodes) 符合 HA。选项 D (Single node) 不符合 HA。
    * 选项 B/C 虽然是 3 节点，但读写模式（Direct Write）是错的。
    * **锁定 A。**

**3. ✅ 正确选项解析 (选项 A)**
* **Write-through:** 保证缓存一致性。
* **Multi-node Cluster:** 保证高可用。

**5. 📚 核心考点:** DAX 的读写模式 (Write-through) 与高可用配置。

---
**小结：**
这组题目中的 **AWS DRS**、**FSx 扩容**、**DAX 写穿策略** 都是容易被忽视的细节。

**恭喜你完成了 150 题！**