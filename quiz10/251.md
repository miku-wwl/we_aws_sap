这 10 道题（包含 1 道关于 EC2 日志持久化的题目）涵盖了 **API 安全 (Rate Limiting)**、**Aurora 审计**、**Graviton 成本优化**、**DynamoDB 预置容量**、**PrivateLink 排错**、**S3 加密成本优化 (SSE-S3)**、**S3 上传解耦 (SQS)**、**AppSync + Cognito**、**CloudWatch Logs 持久化**、**CORS 故障排查**。

特别是 **Q254 (DynamoDB Cost)** 和 **Q256 (KMS Cost Optimization)** 是关于“隐形成本”的经典考点。

让我们开启 **逐题秒杀模式**！

---

#### 📝 [251/529] REST API 防僵尸网络 (WAF Rate Limiting)

**1. 🕵️‍♂️ 题眼与约束分析**
* **正常流量：** 6个合作伙伴，每天1次（频率极低）。
* **攻击流量：** 每秒 1000 次请求，来自 500 个不同 IP。
* **目标：** Protect API, **Minimize cost**。

**2. ⚡ 秒杀思路**
* **防御手段：**
    * 面对 DDoS/Bot 攻击，**AWS WAF** 是首选。
    * **Rate-based Rules (基于速率的规则):** 可以设置“每个 IP 每 5 分钟允许 X 次请求”。如果超过，自动封禁。
    * 题目说正常用户“每天1次”。攻击者“每秒1000次”。设置一个较低的速率限制（如 5分钟 5次）可以有效拦截攻击者，且不误伤正常用户。
* **选项对比：**
    * **选项 A (OAI):** OAI 是 S3 用的，不是 API Gateway 用的。
    * **选项 C/D (WAF Allow IP):** 允许 6 个合作伙伴 IP？如果合作伙伴 IP 变了怎么办？而且题目说“Allow access to IP addresses used by 6 partners”，这需要手动维护 IP 白名单。虽然安全，但维护成本高。如果没有 IP 列表，怎么配？
    * **选项 A/B (CloudFront + WAF):** 将 WAF 挂在 CloudFront 上是标准做法（虽然 API Gateway 也支持 WAF，但 CloudFront 抗 DDoS 能力更强且能缓存）。
    * **决胜点：** **Rate Limiting**。
    * 选项 A/B 都提到了 "Block clients that submit more than 5 requests per day"。WAF Rate-based rule 最小周期是 5 分钟，不是 1 天。但这里的描述可能指逻辑上的速率限制。
    * **API Key:** 选项 B 提到了 **API Key**。这是识别合法用户的好方法。API Key 可以作为最后一道防线。
    * **选项 A:** "Use OAI... ensure only OAI can run POST". 概念错误。OAI 是 S3 的。
    * **选项 B:** CloudFront + WAF (Rate Limit) + **API Key** (in Custom Header)。
        * WAF 挡掉大部分攻击。
        * CloudFront 添加自定义头（包含 API Key）。
        * API Gateway 校验 API Key。
        * 这确保了只有通过 CloudFront（且经过 WAF 过滤）的流量才能访问 API，并且有 API Key 认证。
        * **更正:** 其实 WAF 规则里写的 "5 requests per day" 在技术上是不准确的（WAF 最小是 5 分钟）。但这并不影响 B 是唯一架构合理的选项（相比 A 的 OAI 错误，C/D 的 IP 白名单维护困难）。
    * **其实最简单的可能是 D:** Usage Plan 限制请求。但这防不住 DDoS（DDoS 会消耗配额，导致正常用户也无法访问）。WAF 是在边缘拦截，更适合防 Bot。
    * **结论:** 选 B。利用 CloudFront + WAF 在边缘清洗流量，利用 API Key 做认证。

**3. ✅ 正确选项解析 (选项 B)**
* **WAF Rate-based Rule:** 拦截高频攻击。
* **API Key:** 认证合法请求。
* **CloudFront Custom Header:** 安全地传递 API Key。

**5. 📚 核心考点:** API Gateway 的 DDoS 防护架构。

---

#### 📝 [252/529] Aurora 数据库活动监控 (Database Activity Streams)

**1. 🕵️‍♂️ 题眼与约束分析**
* **需求：** Monitor **ALL database activity** (监控所有活动，包括 SELECT)。
* **数据库：** Aurora PostgreSQL。

**2. ⚡ 秒杀思路**
* **原生功能：** **Database Activity Streams (DAS)**。它能以近乎实时的速度捕获所有 SQL 活动（审计），并推送到 **Kinesis Data Streams**。
* **后续处理：** Kinesis Streams $\rightarrow$ Kinesis Firehose $\rightarrow$ S3 (或其他目标)。
* **选项对比：**
    * 选项 A/D (DMS CDC): DMS 主要捕获数据变更 (INSERT/UPDATE/DELETE)，**不捕获 SELECT**。无法满足 "ALL activity"（通常审计需要看谁查了什么）。
    * 选项 B (EventBridge): 数据库活动流不直接发 EventBridge。
    * **选项 C:** Start Database Activity Streams $\rightarrow$ Kinesis Data Streams $\rightarrow$ Kinesis Firehose $\rightarrow$ S3。这是 DAS 的标准架构路径。
    * **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **Database Activity Streams:** 审计 Aurora 数据库所有操作的唯一原生、高性能方案。

**5. 📚 核心考点:** Aurora 审计与合规 (DAS)。

---

#### 📝 [253/529] Graviton 迁移与 ASG 优化 (R6g)

**1. 🕵️‍♂️ 题眼与约束分析**
* **现状：** 12 个 `r6g.16xlarge` (Graviton2 内存优化)。
* **监控：** CPU/Memory 利用率只有 **1/4** (25%)。
* **需求：** **Cost-effective** (省钱) + **Dynamic scaling** (动态扩展)。

**2. ⚡ 秒杀思路**
* **Right-sizing (规格调整):**
    * 当前：16xlarge。利用率 1/4。
    * 目标：16 / 4 = **4xlarge**。
    * 实例系列：原为 `r6g` (内存优化)。题目没说应用特性变了，只说资源利用率低，所以应保持 **R 系列**（内存优化），因为如果换成 C 或 M，内存可能不够（虽然利用率低，但内存是硬指标，如果还没超过 C/M 的比例，可以换。但最稳妥是降规格不换系列）。
    * **Graviton:** 原来用 `g` 系列，现在继续用 `g` 系列性价比最高。
* **容量配置：**
    * 原来 12 台，利用率 25%。这意味着只需要 3 台 16xlarge 的算力。或者 12 台 4xlarge 的算力。
    * 题目问 "Configure ASG"。
    * 如果换成 **4xlarge**（大小是原来的 1/4），那么为了维持总容量不变，数量应该是原来的 1 倍？不，原来利用率只有 25%，说明**总容量严重过剩**。
    * 实际上，如果单台 16xlarge 利用率 25%，那么单台 4xlarge 利用率将是 100%。
    * 为了留有余地（ASG 动态扩展），我们应该设置一个合理的 Min/Max。
    * 原来 12 台 16xlarge。
    * 实际负载 = 3 台 16xlarge = 12 台 4xlarge。
    * **选项 C:** `r6g.4xlarge`。Min=3, Desired=3, Max=12。
        * 3 台 4xlarge = 0.75 台 16xlarge。这连原来的 1/10 负载都扛不住？
        * **等等，** 题目说 "Consumed CPU and memory was approximately 1/4 of what was expected"。
        * 这句话有点歧义。是说利用率只有 25%？还是说利用率是“预期”的 1/4（而预期如果是 80%，那实际就是 20%）。
        * 总之，资源严重过剩。
    * **让我们换个角度：**
        * 当前：12 * 16xlarge。
        * 实际负载：3 * 16xlarge（假设 25% 利用率）。
        * 换算成 4xlarge：3 * 4 = 12 台 4xlarge。
        * 如果选 C (Max=12)，那勉强够。但 Min=3 有点少。
    * **再看 D:** `r6g.8xlarge` (一半大小)。Min=2, Max=6。
        * Max=6 * 8xlarge = 3 * 16xlarge。这正好等于当前的“实际负载”。但这没有余量了。
    * **有没有可能题目意思是：单台实例利用率低？**
    * 是的。所以要缩小实例规格 (Scale Down)。
    * 从 16xlarge 降到 4xlarge 是合理的（降 4 倍）。
    * 此时，如果请求量不变，单台 4xlarge 的利用率会变成 100%。
    * 为了维持健康（比如 50% 利用率），需要多少台？
    * 之前 12 台 16xlarge (25%) = 3 台 16xlarge (100%)。
    * = 12 台 4xlarge (100%)。
    * = 24 台 4xlarge (50%)。
    * **这里的计算有点对不上选项。**
    * 让我们重新审视 "1/4 of what was expected"。
    * 也许公司预期需要 12 台，结果发现只需要 3 台（1/4）？
    * 如果只需要 3 台 16xlarge。
    * 那么换成 4xlarge 的话，需要 12 台。
    * 选项 C (Max=12) 看起来是上限。
    * **或者，** 这里的 "1/4" 指的是单台实例的规格太大。
    * 如果我们将规格缩小到 4xlarge（1/4 大小），那么单台实例的利用率就会达到 100%（如果数量不变）。
    * 题目问 "Most cost-effective"。
    * **C 选项：** `r6g.4xlarge`。
    * **D 选项：** `r6g.8xlarge`。
    * 考虑到负载 "became more variable"（波动大），更小的实例（4xlarge）组成的集群比大实例（8xlarge/16xlarge）颗粒度更细，扩缩容更平滑，更省钱。
    * **结论：** 选 C。不仅规格合适（R6g），而且利用了 ASG 的弹性。

**3. ✅ 正确选项解析 (选项 C)**
* **Right-sizing:** 16xlarge -> 4xlarge，提高单机资源利用率。
* **ASG:** 适应波动负载。

**5. 📚 核心考点:** EC2 实例规格调整与 ASG 容量规划。

---

#### 📝 [254/529] DynamoDB 成本优化 (Provisioned + Reserved)

**1. 🕵️‍♂️ 题眼与约束分析**
* **现状：** DynamoDB On-Demand。
* **负载模式：**
    * 每天午夜批量写入（可预测）。
    * 白天突发读取，但 **limited set of keys** (热点 Key)。
* **目标：** Reduce costs。

**2. ⚡ 秒杀思路**
* **模式切换：**
    * 每天午夜的批量写入是**可预测**的。On-Demand 模式单价高。对于可预测负载，**Provisioned Capacity (预置容量)** 更便宜。
    * $\rightarrow$ **选中 C 或 D**。
* **缓存优化：**
    * 白天突发读取，且是“有限的键被重复查询”。这是 **DAX (DynamoDB Accelerator)** 的完美场景（缓存热点 Key）。DAX 可以吸收读流量，从而降低 DynamoDB 的 RCU 需求（省钱）。
    * $\rightarrow$ **选中 D**。
* **Savings Plan vs Reserved Capacity:**
    * DynamoDB 有 **Reserved Capacity** (预留容量)，没有 Savings Plan（Compute Savings Plan 不含 DDB）。
    * **选项 B/C** 提到 "Purchase Savings Plan in Cost Explorer"。这是**陷阱**。DynamoDB 只能买 Reserved Capacity，不能买 Savings Plan。
    * **因此，排除 B 和 C。**
* **只剩 D:** "Deploy DAX. Use Provisioned capacity. Configure Auto Scaling"。
    * DAX 解决热点读。
    * Provisioned + Auto Scaling 解决批量写和波动读，且比 On-Demand 便宜。
    * **锁定 D。**

**3. ✅ 正确选项解析 (选项 D)**
* **Provisioned Capacity:** 比 On-Demand 便宜（特别是配合 Auto Scaling）。
* **DAX:** 缓存热点数据，大幅降低 RCU 成本。

**5. 📚 核心考点:** DynamoDB 计费模式优化 (On-Demand vs Provisioned) 与缓存 (DAX)。

---

#### 📝 [255/529] PrivateLink 连接排错 (NACL/SG)

**1. 🕵️‍♂️ 题眼与约束分析**
* **架构：** Client VPC $\rightarrow$ Interface Endpoint $\rightarrow$ NLB $\rightarrow$ EC2 (Log Service)。
* **故障：** Clients cannot submit logs (不通)。
* **排查点：** NACL 和 Security Group。

**2. ⚡ 秒杀思路**
* **PrivateLink 数据流向：**
    * Client $\rightarrow$ Interface Endpoint ENI (在 Client VPC)。
    * Interface Endpoint $\rightarrow$ NLB (在 Service VPC)。
    * NLB $\rightarrow$ EC2 (在 Service VPC)。
* **关键检查点：**
    * **NLB 安全组 (E):** NLB 以前没有安全组，但最近更新支持了。如果启用了，必须允许来自 **Interface Endpoint 子网**（如果是跨 VPC，其实是 Endpoint Service 的连接）的流量？不，PrivateLink 的流量对于 NLB 来说，源 IP 是 **Client 的 IP** (如果在同一个 VPC) 或者是 **NLB 自己的 IP** (如果启用了 Client IP Preservation，那是另一回事)。
    * **PrivateLink 的特殊性：** 流量到达 NLB 时，源 IP 会被替换为 **NLB 节点的 IP** (除非启用 Client IP Preservation，但那是针对 TGW 的，PrivateLink 有点不同)。
    * 对于 PrivateLink 也就是 Endpoint Service，Service 端的 NLB 看到的源 IP 是 **Endpoint Service 在 Service VPC 中创建的 ENI 的 IP**？不对。
    * **纠正：** PrivateLink 流量到达 Service VPC 时，是通过 **Gateway Load Balancer Endpoint** 或者是直接通过 NLB。对于 Interface Endpoint，AWS 会在 Service VPC 侧将流量通过 NLB 转发给后端。
    * **重点：** 后端 EC2 看到的是 **NLB 的 IP**。
    * 所以，**后端 EC2 的安全组**必须允许来自 **NLB 子网**的流量。
    * $\rightarrow$ **选中 C** (Check SG on EC2 allows ingress from NLB subnets)。
* **NACL (A):**
    * NACL 是无状态的，必须允许进和出。
    * **NLB 子网 NACL:** 必须允许来自 Endpoint（或者是 Service VPC 内部流量）的入站，以及去往 EC2 的出站。
    * **EC2 子网 NACL:** 必须允许来自 NLB 的入站，以及回包给 NLB 的出站。
    * 选项 A 说 "Check NACL on Log Service subnet... allow comms with NLB subnet"。这是对的。
* **排除法：**
    * 选项 B: 提到 "Interface Endpoint Subnet"。Interface Endpoint 在 Client VPC（不同的账户）。Service VPC 的 NACL 无法配置允许 "Client VPC Subnet"（因为 IP 可能重叠，且是通过 PrivateLink 隧道过来的）。在 Service VPC 侧，流量看起来像是从 NLB 出来的（或者从 PrivateLink 的隐藏 ENI）。通常只要允许 VPC 内部通信即可。
    * 选项 D: EC2 SG 允许 Client IP？不行，PrivateLink 会做 SNAT（除非开了 Proxy Protocol，但 SG 依然只看 IP包头，包头是 NLB IP）。
    * 选项 E: NLB SG。虽然 NLB 现在支持 SG，但通常 EC2 SG 才是最后一道防线。且 C 和 A 更基础。
    * **结论：** 最常见的配置错误是 **EC2 安全组没放行 NLB** (C) 和 **NACL 阻断了子网间通信** (A)。
    * **锁定 A, C。**

**3. ✅ 正确选项解析 (选项 A, C)**
* **A (NACL):** 确保 NLB 子网和 EC2 子网之间双向畅通。
* **C (Security Group):** 确保后端实例允许来自负载均衡器的流量。

**5. 📚 核心考点:** PrivateLink 后端网络路径的故障排查。

---

#### 📝 [256/529] S3 加密成本优化 (SSE-S3 vs SSE-KMS)

**1. 🕵️‍♂️ 题眼与约束分析**
* **现状：** S3 Standard + **SSE-KMS**。
* **痛点：** **AWS KMS costs are increasing** (KMS 费用暴涨)。
* **原因：** SSE-KMS 每次上传/下载都要调用 KMS API (`Decrypt`/`GenerateDataKey`)。S3 请求量大，KMS 调用费就贵。
* **目标：** Optimize costs, **Minimal changes** (最少改动)。

**2. ⚡ 秒杀思路**
* **替代方案：**
    * **SSE-S3 (B):** 使用 S3 托管密钥。**免费**！完全省去了 KMS 调用费。
* **迁移方法：**
    * 不能直接“修改”对象的加密方式。必须 **Copy** (复制) 对象。
    * **S3 Batch Operations (B):** 批量复制对象到新桶（或原地复制），并指定新的加密方式 (SSE-S3)。
* **选项对比：**
    * 选项 A (SSE-C): 需要客户自己管理密钥并在每次请求时提供，改动代码巨大。
    * 选项 C (CloudHSM): CloudHSM 比 KMS 更贵且复杂。
    * 选项 D (Intelligent-Tiering): 只是优化存储费，不解决 KMS 请求费（每次访问还是要解密）。
    * **选项 B:** Create new bucket with **SSE-S3** + **S3 Batch Operations** copy。彻底消除 KMS 费用。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **SSE-S3:** 零成本的服务器端加密方案。
* **Batch Operations:** 处理数百万对象迁移的最佳工具。

**5. 📚 核心考点:** S3 大规模访问场景下的 KMS 成本陷阱与优化。

---

#### 📝 [257/529] Lambda 并发与数据库压力 (SQS 解耦)

**1. 🕵️‍♂️ 题眼与约束分析**
* **场景：** S3 Upload $\rightarrow$ Lambda $\rightarrow$ DynamoDB。
* **故障：** High concurrency $\rightarrow$ Lambda issues (Concurrency limit) & DynamoDB performance。
* **目标：** Improve performance and reliability。
* **选择：** 2 个步骤。

**2. ⚡ 秒杀思路**
* **解耦 (D):**
    * S3 触发 Lambda 是异步的，但如果并发太高，Lambda 会被限流（Throttling）。
    * 引入 **SQS** 作为缓冲。S3 Event $\rightarrow$ SQS $\rightarrow$ Lambda。
    * 这样可以控制 Lambda 的消费速率（Batch Size），保护下游 DynamoDB，且 SQS 自带重试。
    * $\rightarrow$ **选中 D**。
* **数据库优化 (B):**
    * DynamoDB 写入性能问题 $\rightarrow$ **Adjust WCUs** (写容量) 或开启 Auto Scaling。
    * 选项 A (RCU): 题目是上传（保存数据），主要是写，不是读。
    * 选项 C (ElastiCache): 缓存主要优化读，不优化写。
    * 选项 E (Transfer Acceleration): 优化上传速度，不解决后端处理瓶颈，反而可能让洪峰来得更猛烈。
    * $\rightarrow$ **选中 B**。
* **锁定 B, D。**

**3. ✅ 正确选项解析 (选项 B, D)**
* **SQS:** 削峰填谷，防止 Lambda/DB 被打爆。
* **WCU:** 增加数据库写能力。

**5. 📚 核心考点:** S3 触发器的异步解耦模式 (S3-SQS-Lambda)。

---

#### 📝 [258/529] 媒体上传应用重构 (AppSync + S3)

**1. 🕵️‍♂️ 题眼与约束分析**
* **现状：** Web App 上传文件到文件服务器。
* **痛点：** Over-utilized app server (应用服务器过载), upload failures。
* **需求：** Authenticated users only, **Accelerate development** (加速开发), **Refactor** (重构), **Least operational overhead**。

**2. ⚡ 秒杀思路**
* **架构重构：**
    * **前端：** 静态网站存 S3 + CloudFront (C/D)。
    * **身份认证：** **Amazon Cognito** (C/D)。
    * **上传逻辑：**
        * 传统做法是上传到 EC2 (A/B)。题目要 Refactor 且 Least overhead，Serverless 更好。
        * **S3 Direct Upload (C/D):** 让前端直接把文件传到 S3，绕过应用服务器。这是解决“应用服务器过载”的最佳方案。
* **选项 C vs D:**
    * **D (Amplify):** AWS Amplify 是加速全栈开发的工具集。它整合了 Cognito, S3, CloudFront, AppSync 等。选项 D 描述了 "Use AWS Amplify to create static website... Use Amazon S3 to store uploaded media files"。这是最符合 "Accelerate application development" 的。
    * **C (AppSync + Lambda):** AppSync 是 GraphQL API。用 Lambda 上传文件到 S3？Lambda 有 6MB Payload 限制，不适合大文件上传。通常 AppSync 会生成 Presigned URL 让客户端直传，而不是把文件流经 Lambda。
    * **D 的逻辑：** Amplify 库提供了现成的 Storage 模块，一行代码实现 S3 安全上传（自动处理 Cognito 认证）。
    * **锁定 D。**

**3. ✅ 正确选项解析 (选项 D)**
* **AWS Amplify:** 专为加速移动/Web 开发设计，一站式集成 Auth (Cognito), Storage (S3), Hosting。
* **S3 Direct Upload:** 卸载应用服务器压力。

**5. 📚 核心考点:** Web 应用快速开发与重构 (Amplify)。

---

#### 📝 [259/529] ASG 缩容日志丢失 (CloudWatch Agent)

**1. 🕵️‍♂️ 题眼与约束分析**
* **现象：** ASG Scale-in (缩容) 后，实例被终止，本地日志丢失。
* **目标：** View logs after scale-in (缩容后仍能看日志)。

**2. ⚡ 秒杀思路**
* **日志持久化：**
    * 必须将日志实时流式传输到中心化存储（如 CloudWatch Logs 或 S3）。
    * **CloudWatch Agent (B):** 是将 EC2 内部日志（Application logs）推送到 CloudWatch Logs 的标准工具。即使实例死了，日志还在 CloudWatch 里。
* **选项对比：**
    * 选项 A (ALB Access Logs): 只能看请求记录，看不到“应用程序内部日志”（如代码报错、调试信息）。
    * 选项 C (Step scaling): 不解决日志丢失问题。
    * 选项 D (X-Ray): 用于链路追踪，虽然有用，但不能替代完整的文本日志文件。
    * **锁定 B。**

**3. ✅ 正确选项解析 (选项 B)**
* **CloudWatch Agent:** 实时采集日志，实现计算与日志存储分离。

**5. 📚 核心考点:** 临时实例 (Ephemeral Instance) 的日志持久化策略。

---

#### 📝 [260/529] CORS 故障排查 (API Gateway)

**1. 🕵️‍♂️ 题眼与约束分析**
* **架构：** S3/CloudFront (Static Site) $\rightarrow$ API Gateway $\rightarrow$ Lambda。
* **故障：** **CORS error** (跨域错误)。
* **排查：** CloudFront 已配置 `Access-Control-Allow-Origin: www.example.com`。
* **问题点：** 浏览器请求的是 **API Gateway**。CORS 是浏览器对**目标服务器**（API Gateway）的检查。如果 API Gateway 的响应头里没有 CORS 头，浏览器就会报错。CloudFront 的头是给静态资源的，管不到 API 请求（除非 API 也走 CloudFront，但题目说“Website calls API Gateway endpoint”，通常指直接调用）。即使 API 走 CF，源站（API GW）也必须返回正确的 CORS 头。

**2. ⚡ 秒杀思路**
* **CORS 配置位置：**
    * 必须在 **API Gateway** 上启用 CORS。它会添加 OPTIONS 方法，并配置响应头。
    * **选项 C:** Enable CORS on API Gateway... return `Access-Control-Allow-Origin: www.example.com`。这是正解。
* **排除法：**
    * A (S3 CORS): S3 是托管前端代码的，前端代码加载没问题。问题是前端代码发起的 **API 请求** 被浏览器拦截了。这需要 API 服务端配合。
    * B (WAF): WAF 是防火墙，不负责添加 CORS 响应头（虽然可以 hack，但不是标准做法）。
    * D (Lambda): 虽然 Lambda 代码也可以返回 CORS 头（Proxy Integration），但 API Gateway 层面的 "Enable CORS" 功能更常用，且能自动处理 OPTIONS 预检请求。如果 Lambda 也要做，通常是配合 API Gateway。但 C 选项明确说了在 API 端点启用，这是最直接的配置。**更重要的是**，如果 OPTIONS 请求没处理（Lambda 通常只处理 GET/POST），预检就会失败。API Gateway 的 CORS 配置会自动处理 OPTIONS。
    * **锁定 C。**

**3. ✅ 正确选项解析 (选项 C)**
* **API Gateway CORS:** 自动处理 OPTIONS 预检请求并注入 CORS 头。

**5. 📚 核心考点:** Serverless 架构中的 CORS 配置位置。

---
**小结：**
这组题目的 **WAF Rate Limit**、**PrivateLink 排错**、**S3 KMS 成本** 都是 SAP 的核心。

**恭喜你，260 题！已完成一半！**